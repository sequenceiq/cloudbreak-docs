{
    "docs": [
        {
            "location": "/", 
            "text": "Overview\n\n\nCloudbreak simplifies the provisioning, management, and monitoring of on-demand HDP clusters in virtual and cloud environments. It leverages cloud infrastructure to create host instances, and uses Apache Ambari (via Ambari Blueprints) to install and manage HDP clusters.\n\n\nUsing the Cloudbreak Web UI, REST API, or CLI, you can launch HDP clusters on public cloud infrastructure platforms such as \nMicrosoft Azure\n, \nAmazon Web Services (AWS)\n, and \nGoogle Cloud Platform (GCP)\n, and the private cloud infrastructure platform \nOpenStack\n.\n\n\nCloudbreak has two main components: the \nCloudbreak Application\n and the \nCloudbreak Deployer\n. The \nCloudbreak Application\n consists of multiple microservices (Cloudbreak, Uluwatu, Sultans, and so on). The \nCloudbreak Deployer\n helps you to deploy the Cloudbreak Application automatically with Docker support. Once the Cloudbreak Application is deployed, you can use it to provision HDP clusters in various cloud environments.\n\n\n\n\nFor an architectural overview of the Cloudbreak Deployer, the Cloudbreak Application, Apache Ambari, and other Cloudbreak components, see \nArchitecture\n.\n\n\n\n\nInstallation Options\n\n\nOn a high level, to set up Cloudbreak and provision an HDP cluster, you need to perform the following steps:\n\n\n\n\nInstall the Cloudbreak Deployer\n using one of the two available scenarios: \n\n\n(\nOption #1\n) Install the Cloudbreak Deployer on your own VM/host, or \n\n\n(\nOption #2\n) Instantiate one of the pre-built cloud images that include Cloudbreak Deployer pre-installed.\n\n\n\n\n\n\nConfigure the Cloudbreak Deployer and install the Cloudbreak Application\n. \n\nOnce you have installed Cloudbreak Deployer (called \"cbd\"), the deployer will start up several Docker containers: Cloudbreak API, Cloudbreak web UI (called \"Uluwatu\"), Identity Server, and supporting databases. You have successfully completed this step if you are able to log in to Cloudbreak web UI in your browser.\n\n\nProvision an HDP Cluster\n using the Cloudbreak Application.\n\n\n\n\n\n\n\n(Option #1) Installing the Cloudbreak Deployer\n\n\nYou can install the Cloudbreak Deployer on your own VM/host manually. \n\n\n\n\nSystem Requirements\n:\n \nRHEL / CentOS / Oracle Linux 7 (64-bit), Docker 1.9.1, 4GB RAM, 10GB disk, 2 cores recommended\n\n\n\n\nOnce Cloudbreak Deployer is installed, use it to set up\nthe Cloudbreak Application. We suggest that you install the Cloudbreak Application as close to your\ndesired HDP clusters as possible. For example, if you plan to launch clusters on AWS, install the Cloudbreak Application on AWS.\n\n\nIf you choose this installation option, follow the instructions for \ninstalling the Cloudbreak Deployer\n. Alternatively, consider using one of the \npre-built cloud images that include Cloudbreak Deployer\n pre-installed.\n\n\n\n\nIMPORTANT:\n If you plan to use Cloudbreak on Azure, you must use the \nAzure Setup\n instructions to configure the image.\n\n\n\n\n\n\n\n(Option #2) Using the Pre-Built Cloud Images\n\n\nWe provide pre-built cloud images with Cloudbreak Deployer pre-installed. The following table includes\nlinks to provider-specific instructions for configuring and launching \ncbd (Cloudbreak Deployer)\n and then clusters.\n\n\n\n\nVM Requirements:\n 4GB RAM, 10GB disk, 2 cores recommended\n\n\n\n\n\n\n\n\n\n\nCloud\n\n\nCloud Image\n\n\n\n\n\n\n\n\n\n\nAWS\n\n\nFollow the \nAWS instructions\n.\n\n\n\n\n\n\nAzure\n\n\nThere are no pre-built cloud images available for Azure. However, we give you an option to use Azure Resource Manager Templates instead. See the \nAzure Setup\n instructions.\n\n\n\n\n\n\nGCP\n\n\nFollow the \nGCP instructions\n.\n\n\n\n\n\n\nOpenStack\n\n\nFollow the \nOpenStack instructions\n.\n\n\n\n\n\n\n\n\nLearn More\n\n\nFor more information on Cloudbreak, Ambari and Ambari blueprints, see:\n\n\n\n\n\n\n\n\nResource\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nCloudbreak Project\n\n\nVisit the Hortonworks website to see Cloudbreak-related news and updates.\n\n\n\n\n\n\nCloudbreak Forums\n\n\nVisit the Cloudbreak Forums to get connected with the Cloudbreak community.\n\n\n\n\n\n\nApache Ambari Project\n\n\nLearn about the Apache Ambari Project. Apache Ambari is an operational platform for provisioning, managing, and monitoring Apache Hadoop clusters. Ambari exposes a robust set of REST APIs and a rich web interface for cluster management.\n\n\n\n\n\n\nAmbari Blueprints\n\n\nLearn about Ambari Bleuprints. Ambari Blueprints are a declarative definition of a Hadoop cluster that Ambari can use to create Hadoop clusters.", 
            "title": "Introduction"
        }, 
        {
            "location": "/#overview", 
            "text": "Cloudbreak simplifies the provisioning, management, and monitoring of on-demand HDP clusters in virtual and cloud environments. It leverages cloud infrastructure to create host instances, and uses Apache Ambari (via Ambari Blueprints) to install and manage HDP clusters.  Using the Cloudbreak Web UI, REST API, or CLI, you can launch HDP clusters on public cloud infrastructure platforms such as  Microsoft Azure ,  Amazon Web Services (AWS) , and  Google Cloud Platform (GCP) , and the private cloud infrastructure platform  OpenStack .  Cloudbreak has two main components: the  Cloudbreak Application  and the  Cloudbreak Deployer . The  Cloudbreak Application  consists of multiple microservices (Cloudbreak, Uluwatu, Sultans, and so on). The  Cloudbreak Deployer  helps you to deploy the Cloudbreak Application automatically with Docker support. Once the Cloudbreak Application is deployed, you can use it to provision HDP clusters in various cloud environments.   For an architectural overview of the Cloudbreak Deployer, the Cloudbreak Application, Apache Ambari, and other Cloudbreak components, see  Architecture .", 
            "title": "Overview"
        }, 
        {
            "location": "/#installation-options", 
            "text": "On a high level, to set up Cloudbreak and provision an HDP cluster, you need to perform the following steps:   Install the Cloudbreak Deployer  using one of the two available scenarios:   ( Option #1 ) Install the Cloudbreak Deployer on your own VM/host, or   ( Option #2 ) Instantiate one of the pre-built cloud images that include Cloudbreak Deployer pre-installed.    Configure the Cloudbreak Deployer and install the Cloudbreak Application .  \nOnce you have installed Cloudbreak Deployer (called \"cbd\"), the deployer will start up several Docker containers: Cloudbreak API, Cloudbreak web UI (called \"Uluwatu\"), Identity Server, and supporting databases. You have successfully completed this step if you are able to log in to Cloudbreak web UI in your browser.  Provision an HDP Cluster  using the Cloudbreak Application.", 
            "title": "Installation Options"
        }, 
        {
            "location": "/#option-1-installing-the-cloudbreak-deployer", 
            "text": "You can install the Cloudbreak Deployer on your own VM/host manually.    System Requirements :  \nRHEL / CentOS / Oracle Linux 7 (64-bit), Docker 1.9.1, 4GB RAM, 10GB disk, 2 cores recommended   Once Cloudbreak Deployer is installed, use it to set up\nthe Cloudbreak Application. We suggest that you install the Cloudbreak Application as close to your\ndesired HDP clusters as possible. For example, if you plan to launch clusters on AWS, install the Cloudbreak Application on AWS.  If you choose this installation option, follow the instructions for  installing the Cloudbreak Deployer . Alternatively, consider using one of the  pre-built cloud images that include Cloudbreak Deployer  pre-installed.   IMPORTANT:  If you plan to use Cloudbreak on Azure, you must use the  Azure Setup  instructions to configure the image.", 
            "title": "(Option #1) Installing the Cloudbreak Deployer"
        }, 
        {
            "location": "/#option-2-using-the-pre-built-cloud-images", 
            "text": "We provide pre-built cloud images with Cloudbreak Deployer pre-installed. The following table includes\nlinks to provider-specific instructions for configuring and launching  cbd (Cloudbreak Deployer)  and then clusters.   VM Requirements:  4GB RAM, 10GB disk, 2 cores recommended      Cloud  Cloud Image      AWS  Follow the  AWS instructions .    Azure  There are no pre-built cloud images available for Azure. However, we give you an option to use Azure Resource Manager Templates instead. See the  Azure Setup  instructions.    GCP  Follow the  GCP instructions .    OpenStack  Follow the  OpenStack instructions .", 
            "title": "(Option #2) Using the Pre-Built Cloud Images"
        }, 
        {
            "location": "/#learn-more", 
            "text": "For more information on Cloudbreak, Ambari and Ambari blueprints, see:     Resource  Description      Cloudbreak Project  Visit the Hortonworks website to see Cloudbreak-related news and updates.    Cloudbreak Forums  Visit the Cloudbreak Forums to get connected with the Cloudbreak community.    Apache Ambari Project  Learn about the Apache Ambari Project. Apache Ambari is an operational platform for provisioning, managing, and monitoring Apache Hadoop clusters. Ambari exposes a robust set of REST APIs and a rich web interface for cluster management.    Ambari Blueprints  Learn about Ambari Bleuprints. Ambari Blueprints are a declarative definition of a Hadoop cluster that Ambari can use to create Hadoop clusters.", 
            "title": "Learn More"
        }, 
        {
            "location": "/architecture/", 
            "text": "Architecture\n\n\nCloudbreak Deployer Architecture\n\n\nCloudbreak Deployer includes the following components:\n\n- \nUAA\n: OAuth identity server implementation\n\n- \nCloudbreak\n: the Cloudbreak application\n\n- \nPeriscope\n: the Periscope application\n\n- \nUluwatu\n: Cloudbreak web UI\n\n- \nSultans\n: Cloudbreak user management\n\n\nSystem Level Containers\n\n\nCloudbreak Deployer includes the following system-level containers:\n\n- \nConsul\n: Cloudbreak service registry\n\n- \nRegistrator\n: automatically registers/unregisters containers with consul  \n\n\nCloudbreak Application Architecture\n\n\nCloudbreak is built on the foundation of cloud provider APIs and Apache Ambari.\n\n\nApache Ambari\n\n\nThe goal of the Apache Ambari project is to simplify Hadoop management by developing software for provisioning, managing, and monitoring Apache Hadoop clusters. Ambari provides an intuitive, easy-to-use Hadoop management web UI backed by its RESTful APIs.\n\n\n\n\nAmbari enables System Administrators to: \n\n\n\n\nProvision a Hadoop Cluster\n:  \n\n\nAmbari provides a step-by-step wizard for installing Hadoop services across any number of hosts.\n\n\nAmbari handles configuration of Hadoop services for the cluster.\n\n\n\n\n\n\nManage a Hadoop Cluster\n:  \n\n\nAmbari provides central management for starting, stopping, and reconfiguring Hadoop services across the entire.\n   cluster.\n\n\n\n\n\n\nMonitor a Hadoop Cluster\n:  \n\n\nAmbari provides a dashboard for monitoring health and status of the Hadoop cluster.\n\n\nAmbari lets you set predefined alerts or add custom alerts.\n\n\n\n\n\n\n\n\nAmbari Blueprints\n\n\nAmbari blueprints are a declarative definition of a cluster. With a blueprint, you can specify stack, component\n layout, and configurations to materialise a Hadoop cluster instance (via a REST API) without having to use the Ambari\n  Cluster Install Wizard.\n\n\n\n\nSalt\n\n\nSalt manages complex systems at scale. Salt can be used for data-driven orchestration, remote execution for any infrastructure, configuration management for any app stack, and much more.", 
            "title": "Architecture"
        }, 
        {
            "location": "/architecture/#architecture", 
            "text": "", 
            "title": "Architecture"
        }, 
        {
            "location": "/architecture/#cloudbreak-deployer-architecture", 
            "text": "Cloudbreak Deployer includes the following components: \n-  UAA : OAuth identity server implementation \n-  Cloudbreak : the Cloudbreak application \n-  Periscope : the Periscope application \n-  Uluwatu : Cloudbreak web UI \n-  Sultans : Cloudbreak user management", 
            "title": "Cloudbreak Deployer Architecture"
        }, 
        {
            "location": "/architecture/#system-level-containers", 
            "text": "Cloudbreak Deployer includes the following system-level containers: \n-  Consul : Cloudbreak service registry \n-  Registrator : automatically registers/unregisters containers with consul", 
            "title": "System Level Containers"
        }, 
        {
            "location": "/architecture/#cloudbreak-application-architecture", 
            "text": "Cloudbreak is built on the foundation of cloud provider APIs and Apache Ambari.", 
            "title": "Cloudbreak Application Architecture"
        }, 
        {
            "location": "/architecture/#apache-ambari", 
            "text": "The goal of the Apache Ambari project is to simplify Hadoop management by developing software for provisioning, managing, and monitoring Apache Hadoop clusters. Ambari provides an intuitive, easy-to-use Hadoop management web UI backed by its RESTful APIs.   Ambari enables System Administrators to:    Provision a Hadoop Cluster :    Ambari provides a step-by-step wizard for installing Hadoop services across any number of hosts.  Ambari handles configuration of Hadoop services for the cluster.    Manage a Hadoop Cluster :    Ambari provides central management for starting, stopping, and reconfiguring Hadoop services across the entire.\n   cluster.    Monitor a Hadoop Cluster :    Ambari provides a dashboard for monitoring health and status of the Hadoop cluster.  Ambari lets you set predefined alerts or add custom alerts.", 
            "title": "Apache Ambari"
        }, 
        {
            "location": "/architecture/#ambari-blueprints", 
            "text": "Ambari blueprints are a declarative definition of a cluster. With a blueprint, you can specify stack, component\n layout, and configurations to materialise a Hadoop cluster instance (via a REST API) without having to use the Ambari\n  Cluster Install Wizard.", 
            "title": "Ambari Blueprints"
        }, 
        {
            "location": "/architecture/#salt", 
            "text": "Salt manages complex systems at scale. Salt can be used for data-driven orchestration, remote execution for any infrastructure, configuration management for any app stack, and much more.", 
            "title": "Salt"
        }, 
        {
            "location": "/onprem/", 
            "text": "Install Cloudbreak Deployer\n\n\nFollow these steps to install Cloudbreak Deployer on your operating system. \n\n\n\n\nThe instructions below are for CentOS. If you are using a differnt OS, perform equivalent steps. \n\n\n\n\nSystem Requirements\n\n\nTo run the Cloudbreak Deployer and install the Cloudbreak application, your system must meet the following requirements:\n\n\n\n\nRHEL / CentOS / Oracle Linux 7 (64-bit)\n\n\nDocker 1.9.1\n\n\nVM requirements:\n\n\n8GB RAM\n\n\n10GB disk\n\n\n2 cores\n\n\n\n\n\n\n\n\n\n\nYou can install Cloudbreak on \nMac OS X for evaluation purposes only\n. This operating system is not supported\nfor a production deployment of Cloudbreak.\n\n\n\n\nPrerequisites\n\n\nYou must satisfy the following preprequisites before installing the Cloudbreak Deployer.\n\n\nPorts\n\n\nMake sure that the following ports are open:\n\n\n\n\nSSH (22)\n\n\nCloudbreak (443)\n\n\n\n\nRoot Access\n\n\nExecute every command as \nroot\n. In order to get root privileges execute:\n\n\nsudo -i\n\n\n\n\nSystem Updates\n\n\nEnsure that your system is up-to-date and reboot it if necessary (for example, if there was a kernel update):\n\n\nyum -y update\n\n\n\n\nIptables\n\n\nInstall iptables-services. Without iptables-services installed the 'iptables save' command will not be available:\n\n\nyum -y install iptables-services net-tools\n\n\n\n\nThen, configure permissive iptables on your machine:\n\n\niptables --flush INPUT \n \\\niptables --flush FORWARD \n \\\nservice iptables save\n\n\n\n\nDocker Service\n\n\nConfigure a custom Docker repository for installing the correct version of Docker:\n\n\ncat \n /etc/yum.repos.d/docker.repo \nEOF\n\n[dockerrepo]\nname=Docker Repository\nbaseurl=https://yum.dockerproject.org/repo/main/centos/7\nenabled=1\ngpgcheck=1\ngpgkey=https://yum.dockerproject.org/gpg\nEOF\n\n\n\n\nNext, install the Docker service:\n\n\nyum install -y docker-engine-1.9.1 docker-engine-selinux-1.9.1\nsystemctl start docker\nsystemctl enable docker\n\n\n\n\nCloudbreak Deployer Installation\n\n\nInstall Cloudbreak Deployer\n\n\nInstall the Cloudbreak Deployer and unzip the platform-specific single binary to your PATH. For example:\n\n\nyum -y install unzip tar\ncurl -Ls s3.amazonaws.com/public-repo-1.hortonworks.com/HDP/cloudbreak/cloudbreak-deployer_1.16.1_$(uname)_x86_64.tgz | sudo tar -xz -C /bin cbd\ncbd --version\n\n\n\n\nOnce the Cloudbreak Deployer is installed, you can set up the Cloudbreak application.\n\n\nInitialize Your Profile\n\n\nInitialize \ncbd\n by using:\n\n\nmkdir cloudbreak-deployment\ncd cloudbreak-deployment\n\n\n\n\nFirst, initialize \ncbd\n by creating a \nProfile\n file with the following content:\n\n\nexport UAA_DEFAULT_SECRET='[SECRET]'\nexport UAA_DEFAULT_USER_PW='[PASSWORD]'\n\n\n\n\nBy default the \ncbd\n tool tries to guess \nPUBLIC_IP\n to bind Cloudbreak UI to it. But if \ncbd\n cannot get the IP address during the initialization, set the appropriate value also in your \nProfile\n.\n\n\nGenerate Your Profile\n\n\nGenerate configurations by executing:\n\n\nrm *.yml\ncbd generate\n\n\n\n\nThis creates the following configuration files:\n\n\n\n\nThe \ndocker-compose.yml\n file that describes the configurations of all the Docker containers required for the Cloudbreak deployment.\n\n\nThe \nuaa.yml\n file that holds the configurations of the identity server used to authenticate users to Cloudbreak.\n\n\n\n\nStart Cloudbreak Application\n\n\nTo start the Cloudbreak application, use the following command:\n\n\ncbd pull\ncbd start\n\n\n\n\nThis will start all the Docker containers and initialize the Cloudbreak application. It will take a few minutes for all the services to start.\n\n\n\n\nThe first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.\n\n\n\n\nAfter the \ncbd start\n command finishes, use this command to check the logs of the Cloudbreak application:\n\n\ncbd logs cloudbreak\n\n\n\n\nYou should see a message like this in the log: \nStarted CloudbreakApplication in 36.823 seconds\n. Cloudbreak normally takes less than a minute to start. \n\n\nTroubleshooting\n\n\nIf you face permission or connection issues, disable \nSELinux\n:\n\n\n\n\nSet the \nSELINUX=disabled\n in \n/etc/selinux/config\n.\n\n\nReboot the machine.\n\n\nEnsure the SELinux is not turned on afterwards:\n\n\n\n\nsetenforce 0 \n sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/ selinux/config\n\n\n\n\nNext Steps\n\n\nAfter you have installed Cloudbreak Deployer, perform cloud provider specific configurations and then provision a cluster. See \ncloud provider specific\n steps:\n\n\n\n\nAWS\n\n\nAzure\n\n\nGCP\n\n\nOpenStack\n\n\n\n\n\n\nNote:\n AWS and OpenStack Setup sections contain provider-specific and other additional \nProfile\n settings.", 
            "title": "Installation"
        }, 
        {
            "location": "/onprem/#install-cloudbreak-deployer", 
            "text": "Follow these steps to install Cloudbreak Deployer on your operating system.    The instructions below are for CentOS. If you are using a differnt OS, perform equivalent steps.", 
            "title": "Install Cloudbreak Deployer"
        }, 
        {
            "location": "/onprem/#system-requirements", 
            "text": "To run the Cloudbreak Deployer and install the Cloudbreak application, your system must meet the following requirements:   RHEL / CentOS / Oracle Linux 7 (64-bit)  Docker 1.9.1  VM requirements:  8GB RAM  10GB disk  2 cores      You can install Cloudbreak on  Mac OS X for evaluation purposes only . This operating system is not supported\nfor a production deployment of Cloudbreak.", 
            "title": "System Requirements"
        }, 
        {
            "location": "/onprem/#prerequisites", 
            "text": "You must satisfy the following preprequisites before installing the Cloudbreak Deployer.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/onprem/#ports", 
            "text": "Make sure that the following ports are open:   SSH (22)  Cloudbreak (443)", 
            "title": "Ports"
        }, 
        {
            "location": "/onprem/#root-access", 
            "text": "Execute every command as  root . In order to get root privileges execute:  sudo -i", 
            "title": "Root Access"
        }, 
        {
            "location": "/onprem/#system-updates", 
            "text": "Ensure that your system is up-to-date and reboot it if necessary (for example, if there was a kernel update):  yum -y update", 
            "title": "System Updates"
        }, 
        {
            "location": "/onprem/#iptables", 
            "text": "Install iptables-services. Without iptables-services installed the 'iptables save' command will not be available:  yum -y install iptables-services net-tools  Then, configure permissive iptables on your machine:  iptables --flush INPUT   \\\niptables --flush FORWARD   \\\nservice iptables save", 
            "title": "Iptables"
        }, 
        {
            "location": "/onprem/#docker-service", 
            "text": "Configure a custom Docker repository for installing the correct version of Docker:  cat   /etc/yum.repos.d/docker.repo  EOF \n[dockerrepo]\nname=Docker Repository\nbaseurl=https://yum.dockerproject.org/repo/main/centos/7\nenabled=1\ngpgcheck=1\ngpgkey=https://yum.dockerproject.org/gpg\nEOF  Next, install the Docker service:  yum install -y docker-engine-1.9.1 docker-engine-selinux-1.9.1\nsystemctl start docker\nsystemctl enable docker", 
            "title": "Docker Service"
        }, 
        {
            "location": "/onprem/#cloudbreak-deployer-installation", 
            "text": "", 
            "title": "Cloudbreak Deployer Installation"
        }, 
        {
            "location": "/onprem/#install-cloudbreak-deployer_1", 
            "text": "Install the Cloudbreak Deployer and unzip the platform-specific single binary to your PATH. For example:  yum -y install unzip tar\ncurl -Ls s3.amazonaws.com/public-repo-1.hortonworks.com/HDP/cloudbreak/cloudbreak-deployer_1.16.1_$(uname)_x86_64.tgz | sudo tar -xz -C /bin cbd\ncbd --version  Once the Cloudbreak Deployer is installed, you can set up the Cloudbreak application.", 
            "title": "Install Cloudbreak Deployer"
        }, 
        {
            "location": "/onprem/#initialize-your-profile", 
            "text": "Initialize  cbd  by using:  mkdir cloudbreak-deployment\ncd cloudbreak-deployment  First, initialize  cbd  by creating a  Profile  file with the following content:  export UAA_DEFAULT_SECRET='[SECRET]'\nexport UAA_DEFAULT_USER_PW='[PASSWORD]'  By default the  cbd  tool tries to guess  PUBLIC_IP  to bind Cloudbreak UI to it. But if  cbd  cannot get the IP address during the initialization, set the appropriate value also in your  Profile .", 
            "title": "Initialize Your Profile"
        }, 
        {
            "location": "/onprem/#generate-your-profile", 
            "text": "Generate configurations by executing:  rm *.yml\ncbd generate  This creates the following configuration files:   The  docker-compose.yml  file that describes the configurations of all the Docker containers required for the Cloudbreak deployment.  The  uaa.yml  file that holds the configurations of the identity server used to authenticate users to Cloudbreak.", 
            "title": "Generate Your Profile"
        }, 
        {
            "location": "/onprem/#start-cloudbreak-application", 
            "text": "To start the Cloudbreak application, use the following command:  cbd pull\ncbd start  This will start all the Docker containers and initialize the Cloudbreak application. It will take a few minutes for all the services to start.   The first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.   After the  cbd start  command finishes, use this command to check the logs of the Cloudbreak application:  cbd logs cloudbreak  You should see a message like this in the log:  Started CloudbreakApplication in 36.823 seconds . Cloudbreak normally takes less than a minute to start.", 
            "title": "Start Cloudbreak Application"
        }, 
        {
            "location": "/onprem/#troubleshooting", 
            "text": "If you face permission or connection issues, disable  SELinux :   Set the  SELINUX=disabled  in  /etc/selinux/config .  Reboot the machine.  Ensure the SELinux is not turned on afterwards:   setenforce 0   sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/ selinux/config", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/onprem/#next-steps", 
            "text": "After you have installed Cloudbreak Deployer, perform cloud provider specific configurations and then provision a cluster. See  cloud provider specific  steps:   AWS  Azure  GCP  OpenStack    Note:  AWS and OpenStack Setup sections contain provider-specific and other additional  Profile  settings.", 
            "title": "Next Steps"
        }, 
        {
            "location": "/releasenotes/", 
            "text": "Release Notes\n\n\nThe Release Notes document describes new features and fixes incorporated in this version of Cloudbreak.\n\n\nNew Features\n\n\nThis release includes the following features:\n\n\n\n\n\n\n\n\nFeature\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nFlex Subscription\n\n\nIntroduces support for enabling a Hortonworks Flex Support Subscription for Cloudbreak clusters and the Cloudbreak node. For information on how to enable Flex Subscription in Cloudbreak, refer to \nFlex Subscription\n. If you are looking for general information about Flex Support Subscriptions, visit the Hortonworks Support page at \nhttps://hortonworks.com/services/support/enterprise/\n.\n\n\n\n\n\n\n\n\nFixes \n Changes\n\n\nThis release include the following changes:\n\n\n\n\nRefer to the \nChange Log\n for a full list of changes.\n\n\n\n\nTechnical Preview\n\n\nThis release includes the following Technical Preview features and improvements:\n\n\n\n\n\n\n\n\nFeature\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nCustom Images\n\n\nTechnical Preview\n Ability to set custom images. See \nCloud Images\n for more information.\n\n\n\n\n\n\nAWS: Spot Pricing\n\n\nTechnical Preview\n Support for configuring Spot Price with resource templates.\n\n\n\n\n\n\nMesos\n\n\nTechnical Preview\n Support for Mesos cloud provider. See \nMesos\n for more information.\n\n\n\n\n\n\nKerberos\n\n\nTechnical Preview\n Support for enabling Kerberos on the HDP clusters deployed by Cloudbreak. See \nKerberos\n for more information.\n\n\n\n\n\n\nPlatforms\n\n\nTechnical Preview\n Support for defining Platforms to relate different configurations together. See \nPlatforms\n for more information.\n\n\n\n\n\n\nAmbari Database\n\n\nTechnical Preview\n Support for using an external database for Ambari. See \nAmbari Database\n for more information.", 
            "title": "Release Notes"
        }, 
        {
            "location": "/releasenotes/#release-notes", 
            "text": "The Release Notes document describes new features and fixes incorporated in this version of Cloudbreak.", 
            "title": "Release Notes"
        }, 
        {
            "location": "/releasenotes/#new-features", 
            "text": "This release includes the following features:     Feature  Description      Flex Subscription  Introduces support for enabling a Hortonworks Flex Support Subscription for Cloudbreak clusters and the Cloudbreak node. For information on how to enable Flex Subscription in Cloudbreak, refer to  Flex Subscription . If you are looking for general information about Flex Support Subscriptions, visit the Hortonworks Support page at  https://hortonworks.com/services/support/enterprise/ .", 
            "title": "New Features"
        }, 
        {
            "location": "/releasenotes/#fixes-changes", 
            "text": "This release include the following changes:   Refer to the  Change Log  for a full list of changes.", 
            "title": "Fixes &amp; Changes"
        }, 
        {
            "location": "/releasenotes/#technical-preview", 
            "text": "This release includes the following Technical Preview features and improvements:     Feature  Description      Custom Images  Technical Preview  Ability to set custom images. See  Cloud Images  for more information.    AWS: Spot Pricing  Technical Preview  Support for configuring Spot Price with resource templates.    Mesos  Technical Preview  Support for Mesos cloud provider. See  Mesos  for more information.    Kerberos  Technical Preview  Support for enabling Kerberos on the HDP clusters deployed by Cloudbreak. See  Kerberos  for more information.    Platforms  Technical Preview  Support for defining Platforms to relate different configurations together. See  Platforms  for more information.    Ambari Database  Technical Preview  Support for using an external database for Ambari. See  Ambari Database  for more information.", 
            "title": "Technical Preview"
        }, 
        {
            "location": "/issues/", 
            "text": "Known issues\n\n\nUpgrade to 1.16.1\n\n\nIf you upgrade Cloudbreak to 1.16.1 and you don't have the \nUAA_DEFAULT_SECRET\n specified in the Profile, Cloudbreak deployer will generate one automatically. Furthermore, if you have existing clusters, Cloudbreak will use this new secret to decrypt the database records; however, those were encrypted with the old secret so the old secret needs to be provided in the Profile. \n\n\nWorkaround\n: If you have an existing cluster without the \nUAA_DEFAULT_SECRET\n in your Profile, you must extend the Profile before starting Cloudbreak 1.16.1.\n\n\nexport UAA_DEFAULT_SECRET=cbsecret2015\n\n\nThis issue will be fixed in an upcoming release. \n\n\nDecommission\n\n\n\n\nAMBARI-15294\n In case of downscaling if the selected host group contains an HBase RegionServer it's not guaranteed that all regions will be safely moved to another RegionServer which will remain as part of the cluster. If you choose to scale down such a host group Cloudbreak won't track the region movement process. It is recommended to put the RegionServers in a different host group in your blueprint than the ones you'll be scaling.\n\n\n\n\nCloudbreak Shell\n\n\n\n\nEAR-5997\n NullPointerException will be thrown from CloudbreakShell during execution of \nstack create\n command if the template creation commands are executed after credential selection.\n\n\n\n\nExample:\n\n\ncredential select --name my-aws-credential\n...\ntemplate create --AWS --name my-aws-template --description aws-template --instanceType m3.large --volumeType ephemeral --volumeCount 1 --volumeSize 32 --topologyId 1 --encrypted false\n...\nstack create --AWS --name my-aws-cluster --region eu-west-1\n\n\n\n\nWorkaround: template creation commands should be executed before the credential selection command\n\n\ntemplate create --AWS --name my-aws-template --description aws-template --instanceType m3.large --volumeType ephemeral --volumeCount 1 --volumeSize 32 --topologyId 1 --encrypted false\n...\ncredential select --name my-aws-credential\n...\nstack create --AWS --name my-aws-cluster --region eu-west-1", 
            "title": "Known Issues"
        }, 
        {
            "location": "/issues/#known-issues", 
            "text": "", 
            "title": "Known issues"
        }, 
        {
            "location": "/issues/#upgrade-to-1161", 
            "text": "If you upgrade Cloudbreak to 1.16.1 and you don't have the  UAA_DEFAULT_SECRET  specified in the Profile, Cloudbreak deployer will generate one automatically. Furthermore, if you have existing clusters, Cloudbreak will use this new secret to decrypt the database records; however, those were encrypted with the old secret so the old secret needs to be provided in the Profile.   Workaround : If you have an existing cluster without the  UAA_DEFAULT_SECRET  in your Profile, you must extend the Profile before starting Cloudbreak 1.16.1.  export UAA_DEFAULT_SECRET=cbsecret2015  This issue will be fixed in an upcoming release.", 
            "title": "Upgrade to 1.16.1"
        }, 
        {
            "location": "/issues/#decommission", 
            "text": "AMBARI-15294  In case of downscaling if the selected host group contains an HBase RegionServer it's not guaranteed that all regions will be safely moved to another RegionServer which will remain as part of the cluster. If you choose to scale down such a host group Cloudbreak won't track the region movement process. It is recommended to put the RegionServers in a different host group in your blueprint than the ones you'll be scaling.", 
            "title": "Decommission"
        }, 
        {
            "location": "/issues/#cloudbreak-shell", 
            "text": "EAR-5997  NullPointerException will be thrown from CloudbreakShell during execution of  stack create  command if the template creation commands are executed after credential selection.   Example:  credential select --name my-aws-credential\n...\ntemplate create --AWS --name my-aws-template --description aws-template --instanceType m3.large --volumeType ephemeral --volumeCount 1 --volumeSize 32 --topologyId 1 --encrypted false\n...\nstack create --AWS --name my-aws-cluster --region eu-west-1  Workaround: template creation commands should be executed before the credential selection command  template create --AWS --name my-aws-template --description aws-template --instanceType m3.large --volumeType ephemeral --volumeCount 1 --volumeSize 32 --topologyId 1 --encrypted false\n...\ncredential select --name my-aws-credential\n...\nstack create --AWS --name my-aws-cluster --region eu-west-1", 
            "title": "Cloudbreak Shell"
        }, 
        {
            "location": "/changelog/", 
            "text": "Change Log\n\n\nThe Change Log summarizes the changes in Cloudbreak.\n\n\n[v1.16.0]\n\n\nAdded\n\n\n\n\nAdded SmartSense and Flex subscription integration\n\n\n\n\n[v1.15.0]\n\n\nAdded\n\n\n\n\nAzure custom role support for credential creation\n\n\n\n\nChanged\n\n\n\n\nability to query more information about the stack by queryparameters\n\n\n\n\n[v1.14.4]\n\n\nFixed\n\n\n\n\nfix settings generation\n\n\nfix unable to create Azure cluster with WASB\n\n\npreserve Knox settings when switching credentials\n\n\nautomatically create /var/run/knox after restart\n\n\n\n\nAdded\n\n\n\n\nAzure Private IP support\n\n\nadd missing settings block for etl-edw blueprint\n\n\nshow all instance metadata information on shell \"stack metadata\"\n\n\nadd proper error handling for repair flow\n\n\n\n\nChanged\n\n\n\n\nupdate HDP version (2.2.0.1 -\n 2.5.5.0 and 2.6.0.0 -\n 2.6.0.3)\n\n\nupdate Ambari version (2.5.0.0 -\n 2.5.0.3)\n\n\ndisable Hive credential provider\n\n\nAzure static IP allocation method instead of dynamic\n\n\nAzure deallocate VM-s instead of just stopping them on cluster stop\n\n\nconform to more strict Salt-api calls (since 2016.11.4)\n\n\nuse redhat6 repo on amazonlinux\n\n\n\n\n[v1.14.0]\n\n\nAdded\n\n\n\n\nnew Azure connector based on Azure Java SDK\n\n\nAzure interactive credential creation\n\n\nnew alerting system implemented based on prometheus\n\n\n\n\nChanged\n\n\n\n\nability to specify multiple rdsconfig-s per cluster\n\n\n\n\n[v1.6.3]\n\n\nChanged\n\n\n\n\nUpgraded a dependent component in order to address a network configuration issue.\n\n\nUpdated traefik to v1.1.2\n\n\nUpdated Google Cloud SDK to 1.22.0\n\n\n\n\n[v1.6.2]\n\n\nFixed\n\n\n\n\nreturn login error if user has multiple accounts in LDAP/AD\n\n\nextra logging when creating the Ambari client\n\n\navoid deploy failures, due to concurrency in Salt highstate\n\n\nincorrect error message collection from nodes during Salt highstate\n\n\nreduce host name length on Azure in order to be sure that the fully qualified hostname is under 64 chars\n\n\ndo not overwrite manually changed kerberos config\n\n\n'securitygroup create' shell command caused a validation error due to missing provider value\n\n\nautocreate default security groups for every provider\n\n\nfix bower retry in web dockerfile to avoid UI build fails\n\n\nCloudbreak does not work with CentOS on AWS\n\n\nShiro config of Zepplein is always overwritten by Cloudbreak\n\n\nfix cluster sync when a new service is added to Ambari through the wizard\n\n\nrename all open port security group to denote unsecure\n\n\nremove all port open security group as default\n\n\n\n\nAdded\n\n\n\n\nAzure VMs supporting private deployments (when VMs have private ip only)\n\n\ndo not use the same host names for every cluster on Azure\n\n\nconfigurable stack name prefix length in Azure host names\n\n\nset up default HDP version\n\n\nimplement existing MIT KDC\n\n\nexisting AD support\n\n\nsupport exsisting security group on AWS\n\n\nseparate security groups per provider\n\n\nability to specify image id on API to launch a cluster from that base AMI\n\n\n\n\nChanged\n\n\n\n\nOS parameter is optional when providing the HDP repo\n\n\nmodularize integration test Makefile to sh scripts\n\n\n\n\n[v1.6.1]\n\n\nFixed\n\n\n\n\ncannot send invite e-mails from Auth (aka Sultans) when smtp authentictaion is not enabled\n\n\nrecipe shell commands was not aligned with UI and with the implementation\n\n\navoid duplicated privateids for instances (they must be unique)\n\n\nreserve ports on OS for well known Hadoop services\n\n\ndo not fail when there is no default VPC on AWS\n\n\nreserve TCP/UDP ports on OS for well-known Hadoop services\n\n\ninvalid hostmetadata count after sync when a node from master hostgroup died\n\n\nshell fix to avoid error when creating cluster using templates with encrypted EBS\n\n\nfix concurrent removal of alerts in Autoscale (aka Periscope)\n\n\nensure that the gcs-connector.sh recipe runs only one time\n\n\nfix multiple salt-minion start\n\n\nshort names for OpenStack VMs to avoid MySQL / Hive failures\n\n\nfix uluwatu missing template volume type in some cases\n\n\navoid timeouts when IPV6 is disabled https://github.com/saltstack/salt/issues/32719\n\n\ndo not allow cluster reset when external DB is used for Ambari\n\n\nfix smtp related indentations in application.yml\n\n\nintroducing resource definiton cache, to avoid read the same definition from disk multiple times\n\n\ninvalid hdp repo config (update to 2.5 and support cnetos6 on AWS)\n\n\ndisplay AWS autoscaling group errors\n\n\nsporadic ssh connectivity issue from on gcp\n\n\nno transaction for cluster update\n\n\nrenamed s3role to instanceprofile on UI\n\n\navoid alphabetical order of recipes by filename\n\n\nstop cluster is not possible due to invalid spot price check\n\n\nsporadic classpath issue, since StackServiceComponentDescriptorMapFactory returns wrong object type\n\n\n\n\nAdded\n\n\n\n\nOpenStack Liberty and Mitaka support\n\n\nimplement Availibility Zones for OpenStack\n\n\ndynamic load of custom provider definitions\n\n\nlog every recipe by default (/var/log/recipses)\n\n\neventlog about recipe execution\n\n\nability to restart cluster installation in case of failed recipe\n\n\n\n\nChanged\n\n\n\n\nambari client with sources and extra logging\n\n\nremove unnecessary admin user\n\n\nremove cloudbreak log highlighting\n\n\nremove unused timeout value from recipes\n\n\nimproved logging for saltbootstrap\n\n\nevery recipe runs only once by default\n\n\n\n\n[v1.6.0]\n\n\nFixed\n\n\n\n\nproper handling of upstart config to avoid concurrency between sysv and upstart during ambari agent / server start\n\n\nuse m3 for dry-run check because it can be started in ec2-classic\n\n\nconsider auto scaling activity history in auto scaling group status checker\n\n\neliminate criticals reported by Sonar\n\n\nability to create bigger than 999 GB size volumes on Azure\n\n\nfixed javascript test for nodecount\n\n\nregion is not a required field when posting a new stack\n\n\n\n\nAdded\n\n\n\n\nARM template JSON validation\n\n\nadded property to set static shared volume(s) in BYOS clusters\n\n\ngenerate salt password per stack\n\n\nadded Hibernate field encryptor to encryt sensitive data in DB\n\n\nability to start GCP clusterts in a NATed environment without public IP address\n\n\nAmbari and HDP versions are added to the /stack API call's response\n\n\nwhen deploying a new subnet in an existing VPC on AWS, the CIDR range is automatically calculated when not specified explicitly on the API\n\n\n\n\nChanged\n\n\n\n\nCloudbreak dev version uses latest image from image catalog\n\n\ncleanup unnecessary pillar matchers\n\n\nupdate default blueprints to add hive clients to worker nodes\n\n\nAPI cleanup, remove invalid required fields from swagger\n\n\nupdated Ambari version to 2.4.1.0\n\n\n\n\n[v1.5.0]\n\n\nFixed\n\n\n\n\nClusterBootstrapperTest randomly fails\n\n\nslider does not work with ssl on python 2.7.9+\n\n\nfix Ambari address on UI for clusters that provisioned by an older version of Cloudbreak\n\n\ncredential visibility on cluster details view\n\n\n\"Keystone Version\" dropdown layouts\n\n\n\n\nAdded\n\n\n\n\nadded HDP version field to RDS config\n\n\nability to configure remote database for Ambari\n\n\nstacks/clusters are associated with Cloudbreak version\n\n\nnew resource to configure LDAP service for Knox\n\n\nsupport of Google's spot instances\n\n\nsupport for c4 instance types in AWS\n\n\nenable auto recovery for HDP services on failure via blueprint\n\n\nability to specify multiple subnets for the same VPC on AWS\n\n\nability to configure default regions\n\n\n\n\nChanged\n\n\n\n\nreinstate recipes on Uluwatu UI\n\n\nincrease Ambari password length and fix error message\n\n\nautomatic blueprint update during startup\n\n\non OpenStack stack name contains stack ID\n\n\ndisable upgrade of saltstack\n\n\nremove unecessary \nrequire\n flags from API documentation\n\n\nimprove security of salt communication\n\n\n\n\n[v1.4.0] - 2016-08-12\n\n\nFixed\n\n\n\n\nremove invalid auto scaling group history check\n\n\nfix sync to avoid node count corruption of instance groups\n\n\nHDP on AWS can return 502 Bad Gateway while accessing Ambari\n\n\nfix Ambari server ip selection on AWS\n\n\nfix enable auto scaling with different user\n\n\n\n\nAdded\n\n\n\n\nnew RDS config resource\n\n\nshell commands for RDS config operations\n\n\nconfigurable image catalog\n\n\nallow dynamically change Ambari version\n\n\nadded \ncanada\n region to Azure\n\n\nadd basic auth to Zeppelin, Zeppelin is secured with the same password like Ambari\n\n\nability to configure a custom domain for the clusters with the CB_HOST_DISCOVERY_CUSTOM_DOMAIN env variable\n\n\n\n\nChanged\n\n\n\n\nupdate images for on-the-fly ambari update\n\n\nincrease poll timeout for ARM\n\n\ndisable automated map/reduce smoke test\n\n\nparallel command execution in Ambari\n\n\nupdate to Smartsense 1.3.0\n\n\nadd admin user to \nhadoop\n and \nhdfs\n groups after Ambari install\n\n\nuse only Cloudbreak address to connect Cloudbreak\n\n\n\n\n[v1.3.2]\n\n\nFixed\n\n\n\n\nAmbari restart\n\n\navoid duplicated alarmas\n\n\nbefore upscale the sync won't change the stack state\n\n\nupscale / downscale fix with Ambari 2.4\n\n\n\n\nAdded\n\n\n\n\nreverse proxy for UI components\n\n\nnew supported volume type on aws: ST1\n\n\nSpark reverse proxy settings\n\n\nSpark jobhistory server reverse proxy settings\n\n\ncreate admin user for Ambari views\n\n\nadded group name to AWS instance Name tags\n\n\nadd etl-edw default blueprint\n\n\nconfigure Hive RDS through Cloudbreak\n\n\nconfigurable default SmartSense configuration and installation\n\n\nadd SmartSense server to a single noded hostgroup if possible\n\n\ngenerate SmartSense id as credential attribute\n\n\nset SmartSense capture schedule on hosts by recipe\n\n\n\n\nChanged\n\n\n\n\nupdate to Ambari 2.4.0.0\n\n\nuse OpenJDK instead of Oracle JDK\n\n\nuse Ambari password as default service password\n\n\nmake Sultans base path configurable with '/sl' as default value\n\n\ncreate individual root path for Cloudbreak and Periscope\n\n\nset DNS TTL for AWS clients to \n= 60s\n\n\nrewrite url if ambari sessionid appears in cookies\n\n\nremove MYSQL_SERVER component from blueprint if there is rds config present\n\n\nhandle AWS account id as String during SmartSense id generation\n\n\nupdate proxy users hosts to avoid unauthorized connection for super-user in Oozie\n\n\nset ONLY_STACK_DEFAULTS_APPLY as default since the new recommendation strategy does not work for Falcon and Ozzie\n\n\nshow blueprint name on review panel and hide hostroup panel by default\n\n\nshow only the previously selected network on the review panel\n\n\n\n\nRemoved\n\n\n\n\nSpark and Zeppelin nginx proxy settings\n\n\n\n\n[v1.3.0] - 2016-06-06\n\n\nFixed\n\n\n\n\ndelete cluster containers only if orchestrator type is container\n\n\nshow reason of failed commands when using the shell\n\n\nlogin when password contains special characters\n\n\ntextarea placeholder on Internet Explorer 11\n\n\nHDP repo verification on Uluwatu\n\n\nwrong instance metadata status during cluster sync\n\n\nmanage platforms close button on UI\n\n\nnull pointer during router creation on non existing Openstack network\n\n\n\n\nAdded\n\n\n\n\nuse salt bootstrap instead of cloudbreak bootstrap\n\n\nmissing gateway port to stack response\n\n\nenable spot price instances\n\n\nAWS cluster creation with existing key pair\n\n\nAWS existing SSH key pair could be configured by credential command\n\n\nnew description and output for CFN stack\n\n\nadd ssh port into instance metadata\n\n\nseamless s3 connection\n\n\ncustom CIDR validator for subnet\n\n\ncustom tag to CloudFormation stack created by Cloudbreak\n\n\nstart termination flow stops other running flows on the same stack\n\n\nOpenstack API facing option\n\n\n\n\nChanged\n\n\n\n\nopenstack network shell command improvement for the new network types\n\n\nability to select where to put ambari server\n\n\nreorganize kerberos setup in Salt\n\n\nusing private address if only private address is available\n\n\nalways use ports on Openstack even there is no floating ip assigned\n\n\nfloating IP shall not be mandatory, and do not create separate ports\n\n\nfollow HBase port changes\n\n\nmove variant from advanced option to the basic options page\n\n\nSpring update\n\n\nelastic ips are managed by CloudFormation\n\n\nsync starts automatically at startup\n\n\nread nginx SSL port from parameter instead of static 443\n\n\nsync to handle instances that are stopped on the provider side\n\n\nOpenstack metadata collection handles manually terminated instances\n\n\ncleaned up Openstack resources in case of existing subnet\n\n\n\n\nRemoved\n\n\n\n\nrecipe and ssd config were removed\n\n\ndocker properties removed from UI\n\n\n\n\n[v1.2.6] - 2016-05-19\n\n\nChanged\n\n\n\n\nuse lates cloud images with ambari-agent:2.2.1-v20\n\n\nmap public ips to vms in case of existing vpc\n\n\n\n\n[v1.2.5] - 2016-04-07\n\n\nFixed\n\n\n\n\nslow lazy format on Azure\n\n\nmounted disks are not visible in containers\n\n\n\n\nAdded\n\n\n\n\nassume role without adding the keys into cbd Profile\n\n\nability to create cluster without public ip\n\n\nhigh availability blueprint validator\n\n\nsupport for older gcp projectids\n\n\n\n\n[v1.2.4] - 2016-03-22\n\n\nFixed\n\n\n\n\nazure storage location\n\n\nopenstack create network form\n\n\nazure create network form\n\n\ngcp disk type\n\n\n\n\nAdded\n\n\n\n\nGCP subnetsupport  to shell\n\n\n\n\nChanged\n\n\n\n\nuse the provided public network id for allocation floating ips\n\n\nallow 24 attached volumes for aws\n\n\ncleaned up openstack resources in case of existing subnet\n\n\n\n\n[v1.2.3] - 2016-03-22\n\n\nFixed\n\n\n\n\nsudo right of CB user\n\n\n\n\nAdded\n\n\n\n\nAzure default network\n\n\n\n\n[v1.2.2] - 2016-03-21\n\n\nFixed\n\n\n\n\ncredential validation in case of Mesos/Marathon\n\n\n\n\n[v1.2.1] - 2016-03-21\n\n\nFixed\n\n\n\n\nlive migration operations\n\n\n\n\n[v1.2.0] - 2016-03-18\n\n\nFixed\n\n\n\n\nconsul recursor now exculdes both docker ip and bridge ip to avoid recursive dns recursor chain\n\n\ndocs fixed about getting default credentials (cbd login)\n\n\nupdates cb-shell to 0.5.37 to fix ssl issues\n\n\n\n\nAdded\n\n\n\n\nCommand \ncbd azure configure-arm\n will create your arm application which can used by cloudbreak\n\n\nCommand \ncbd azure deploy-dash\n will deploy a dash application in your Azure account\n\n\nCommand \ncbd start\n will execute the migration by default. If SKIP_DB_MIGRATION_ON_START envvar set to true in Profile, the migration will be skipped\n\n\nUsing Dns SRV record in our services instead of ambassador\n\n\nUsing docker linking system in third party services instead of ambassador\n\n\nIntegration tests are added, where cbd binary is called, not only sourced functions\n\n\nDocker based CentOS integration test make target added\n\n\nUaa db migration\n\n\nSMTP default parameters added: \nCLOUDBREAK_SMTP_AUTH\n and \nCLOUDBREAK_SMTP_STARTTLS_ENABLE\n and \nCLOUDBREAK_SMTP_TYPE\n\n\nLocal development Uluwatu configuration by ULUWATU_VOLUME_HOST environment variable\n\n\nLocal development Sultans configuration by SULTANS_VOLUME_HOST environment variable\n\n\ninstall script for fixed version and install-latest for latest release added\n\n\nEach snapshot artifact is uploaded as http://public-repo-1.hortonworks.com/HDP/cloudbreak/cbd-snapshot-$(uname).tgz\n\n\nConfiguration ability to enable or disable ssh fingerprint verification of virtual machines on GCP and AWS\n\n\n\n\nRemoved\n\n\n\n\nFull removal of ambassador\n\n\n\n\nChanged\n\n\n\n\ncbd start\n doesnt start if compose yaml regeneration is needed\n\n\ncbd generate\n is less verbose, diff doesnt shown\n\n\ncbd doctor\n shows diff if generate would change\n\n\ncbd regenerate\n creates backup files if changes detected\n\n\nsequenceiq/uaadb:1.0.1 is used instead of postgres:9.4.1\n\n\n\n\n[v1.0.3] - 2015-09-03\n\n\nFixed\n\n\n\n\nAuthentication error with \ncloudbreak-shell\n and \ncloudbreak-shell-quiet\n is fixed\n\n\nCommand \ncbd update \nbranch\n checks for artifact\n\n\n\n\nAdded\n\n\n\n\nbinary version of gnu-sed 4.2.2 is now included, to solve lot of osx/busybox issues\n\n\nconsul recursor test are added\n\n\n\n\nChanged\n\n\n\n\n\n\nsequenceiq/cloudbreak image updated to 1.0.3\n\n\n\n\n\n\ndebug() function made multiline capable. Use \\n in messages\n\n\n\n\nrefactor bridge ip discovery to run helper docker command only once\n\n\nconsul recursor handling refactored to be more robust\n\n\n\n\n[v1.0.2] - 2015-08-25\n\n\nAdded\n\n\n\n\nDOCKER_CONSUL_OPTIONS\n config option to provide arbitrary consul option\n\n\n\n\nChanged\n\n\n\n\nFixed docker version checker to be 1.8.1 compatible. (docker added --format option)\n\n\nsequenceiq/cloudbreak image updated to 1.0.2\n\n\nconsul image changed from sequenceiq/consul to gliderlabs/consul\n\n\nconsul image updated to 0.5.2 (from 0.5.0)\n\n\nconsul discovers host dns settings, and uses the configured nameserver as recursor\n\n\n\n\n[v1.0.0] - 2015-07-23\n\n\nFixed\n\n\n\n\nGA Release\n\n\n\n\n[v0.5.8] - 2015-07-23\n\n\nFixed\n\n\n\n\nFix CircleCI release. CircleCI doesnt allow --rm on docker run\n\n\n\n\n[v0.5.7] - 2015-07-23\n\n\nFixed\n\n\n\n\nFix make release dependency\n\n\nFix CHANGELOG generation at \nmake release-next-ver\n avoid inserting extra -e\n\n\n\n\n[v0.5.6] - 2015-07-23\n\n\nAdded\n\n\n\n\nRelease artifacts are published at public-repo-1.hortonworks.com/HDP/cloudbreak/\n\n\n\n\n[v0.5.5] - 2015-07-10\n\n\nAdded\n\n\n\n\nCommand \npull-parallel\n added for quicker/simultaneous image pull\n\n\nRelease process includes upload to public-repo s3 bucket\n\n\n\n\nChanged\n\n\n\n\nLicense changed from MIT to Apache v2\n\n\nrelease artifact includes additional files: license/readme/notes\n\n\n\n\n[v0.5.4] - 2015-07-03\n\n\nAdded\n\n\n\n\nNew \ncbd-cleanup\n command for removing old images or exited containers\n\n\nBaywatch default parameters added: \nCB_BAYWATCH_ENABLED\n and\nCB_BAYWATCH_EXTERN_LOCATION\n\n\nLogs are saved via lospout\n\n\nTLS client certificate needed by Cloudbreak is generated with \ncbd generate\n\n\nCommand \naws delete-role\n added\n\n\nCommand \naws generate-role\n added\n\n\nCommand \naws show-role\n added\n\n\nCommand \ncloudbreak-shell\n added\n\n\nCommand \ncloudbreak-shell-quiet\n added\n\n\nCommand \nlocal-dev\n added\n\n\nCommand \ntoken\n added\n\n\n\n\nChanged\n\n\n\n\nAWS authentication env varibale is fixed to use the correct AWS_SECRET_ACCESS_KEY (instead the old AWS_SECRET_KEY)\n\n\nUsing sequenceiq/ambassadord:0.5.0 docker image instead of progrium/ambassadord:latest\n\n\n\n\n[v0.5.3] - 2015-06-03\n\n\nFixed\n\n\n\n\nOne-liner installer fixed, to work if previous cbd exists on path.\n\n\ncbd update\n upstream changes on go-bahser broke the selfupdate functionality\n\n\nIn some environment cloudbreak starts really slow. See: \ndetails\n, see: \ncommit\n\n\n\n\nAdded\n\n\n\n\nNew release proposal can be done by \nmake release-next-ver\n\n\n\n\n[v0.5.2] - 2015-05-21\n\n\nChanged\n\n\n\n\nCommand \ndoctor\n hints to run boot2docker shellinit if env is unset\n\n\nCommand \ninit\n in case of OSX, DOCKER_XXX envs are initialized in local profile (Profile)\n\n\nDefault docker images are updated to:\n\n\nsequenceiq/cloudbreak:0.5.93\n\n\nsequenceiq/cbdb:0.5.92\n\n\nsequenceiq/uluwatu:0.5.28\n\n\nsequenceiq/sultans:0.5.3\n\n\nsequenceiq/periscope:0.5.5\n\n\n\n\n\n\n\n\n[v0.5.1] - 2015-05-18\n\n\nFixed\n\n\n\n\nIssue #55: Sed handles more robust the issue with: curl includes an extra CR char in header fields.\n\n\n\n\nRemoved\n\n\n\n\ndeployer doesnt specify cloud specific image defaults. If left empty, they fall back\n  to defaults specified in \njava code\n\n\nCB_AZURE_IMAGE_URI\n\n\nCB_AWS_AMI_MAP\n\n\nCB_OPENSTACK_IMAGE\n\n\nCB_GCP_SOURCE_IMAGE_PATH\n\n\n\n\n\n\n\n\nChanged\n\n\n\n\nCommand \nlogs\n got usage example for specifying services as filter\n\n\nDefault docker images are updated to:\n\n\nsequenceiq/cloudbreak:0.5.49\n\n\nsequenceiq/uluwatu:0.5.16\n\n\nsequenceiq/sutans:0.5.2\n\n\n\n\n\n\n\n\n[v0.5.0] - 2015-05-08\n\n\nFixed\n\n\n\n\nCommand \npull\n generates yaml files in case they are missing #31\n\n\n\n\nAdded\n\n\n\n\nCommand \nlogin\n Shows Uluwatu login url and credentials\n\n\nCommand \nregenerate\n deletes and generates docker-compose.yml and uaa.yml\n\n\nCommand \ndelete\n added: deletes yamls and dbs\n\n\nCommand \ncloudbreak-shell\n added, right now it internale use DEBUG=1 fn fn-call\n\n\nCommand \nversion\n does correct \nSemantic Versioning\n check to advise an upgrade\n\n\nCommand \ngenerate\n checks and shows if Profile change would result in yaml change.\n\n\nCommand \nstart\n: prints uluwatu url and credential hint\n\n\nCommand \ndoctor\n: fixes boot2docker date/time if not the same as on the host\n\n\nInternal command: \nbrowse\n added to be able to automatically open a browser to a specified url.\n\n\nMini Getting Started guide added into README\n\n\nmake dev-debug\n installs a special cbd on local OSX, which doesnt includes *.bash scrips, only refers them\n   by path. No need to \nmake dev\n to test small changes in bash scripts.\n\n\nLoad AWS key and AWS id from Profile\n\n\nCommand \ninit\n helps to guess the PUBLIC_IP in public clouds: google, amazon\n\n\n\n\nChanged\n\n\n\n\nCommand \ncbd env export\n adds export to the begining of each line\n\n\ncbd logs accepts optional [services] parameter\n\n\ndocker-compose uses \ncbreak_\n prefix for container naming instead of the directory name\n\n\nCommand \ngenerate\n prints out some more usefull info\n\n\nuaa.yml generation wont overwrite, just instruct to move existing file (like docker-compose.yml generation)\n\n\nCommand \ninit\n hint fixed on linux.\n\n\nCommand \ninit\n advise to run \ngenerate\n if it finds a Profile\n\n\nCommand \ninit\n set PRIVATE_IP the same as PUBLIC_IP for boot2docker\n\n\nCommand \nmigrate\n is introduced for db migration see \nMigrate the databases\n section of README\n\n\nCommand \nstartdb\n starts the cbdb and pcdb database containers only\n\n\nDatabases are not deleted after boot2docker restart\n\n\nImport ULU_HOST_ADDRESS and ULU_SULTANS_ADDRESS from Profile\n\n\n\n\n[v0.1.0] - 2015-04-16\n\n\nFixed\n\n\n\n\nSelfupdate updates the actual running binary intead of the fixed /us/local/bin/cbd\n\n\nSMTP default port is 25, to fix number conversion exception\n\n\n\n\nAdded\n\n\n\n\nCommand \ninit\n creates Profile\n\n\nInstall cbd to a directory which is available on $PATH\n\n\nDocker based test for the one-liner install from README.md: \nmake install-test\n\n\n\n\nRemoved\n\n\n\n\nupdate-snap\n command removed, replaced by parametrized \nupdate\n\n\n\n\nChanged\n\n\n\n\nCloudbreak/Persicope/Uluwatu/Sultans Dcoker images upgraded to 0.4.x\n\n\nUse the built in 'checksum' function instead of the external 'shasum' to generate secrets\n\n\nCommand \nupdate\n by default updates from latest Github release, parameter can point to branch on CircleCI\n\n\nDOCKER_XXX env varibles are inherited, so they not needed in Profile\n\n\ngenerate\n and compose specific commands are only available when \nProfile\n exists\n\n\ngenerate\n command genertes docker-compose.yml \nand\n uaa.yml\n\n\nPRIVATE_IP\n env var defaults to bridge IP (only PUBLC_IP is required in Profile)\n\n\nuse \nsulans-bin\n docker image istead of sultans\n\n\n\n\n[v0.0.9] - 2015-04-14\n\n\nFixed\n\n\n\n\nBash 4.3 is included in the binary, extracted into .deps/bin upon start\n\n\n\n\n[v0.0.8] - 2015-04-13\n\n\nFixed\n\n\n\n\nFixing deps module, golang fn: checksum added\n\n\nCircleCI mdule defines required jq\n\n\nFixing PATH issue for binary deps\n\n\n\n\nAdded\n\n\n\n\nuaadb start added\n\n\nidentity server start added\n\n\nmake dev\n added to mac based development\n\n\npull\n command added\n\n\nlogs\n command added\n\n\n\n\nChanged\n\n\n\n\nDocker containers are managed by \ndocker-compose\n\n\n\n\n[v0.0.7] - 2015-03-26\n\n\nAdded\n\n\n\n\nmake tests\n runs unit tests\n\n\ndocker unit tests are added\n\n\nstart command added: WIP consul, registrator starts\n\n\nkill command addd: stops and removes cloudbreak specific containers\n\n\nSKIP_XXX skips the container start\n\n\n\n\nChanged\n\n\n\n\nenv command namespace is always exported, not only in DEBUG mode\n\n\nenv export: machine friendly config list\n\n\nenv show: human readable config list\n\n\ncircle runs unit tests\n\n\nsnapshot binaries include branch name in version string\n\n\n\n\n[v0.0.6] - 2015-03-25\n\n\nFixed\n\n\n\n\nremoved dos2unix dependency for the update command\n\n\n\n\nAdded\n\n\n\n\ndoctor command added\n\n\ndocker-check-version command added\n\n\ncci-latest accepts branch as parameter, needed for PR testing\n\n\nexport fn command in DEBUG mode\n\n\nexport env command in DEBUG mode\n\n\ndoctor: add instruction about setting DOCKER_XXX env vars in Profile\n\n\ninfo() function added to print green text to STDOUT\n\n\n\n\nChanged\n\n\n\n\nHOME env var is also inherited (boot2docker version failed)\n\n\nrelease process fully automatized\n\n\n\n\n[v0.0.5] - 2015-03-23\n\n\n\n\nupdate\n command works without dos2unix\n\n\n\n\n[v0.0.4] - 2015-03-23\n\n\nFixed\n\n\n\n\ndebug function fixed\n\n\nDEBUG, TRACE and CBD_DEFAULT_PROFILE env vars are inherited\n\n\n\n\nAdded\n\n\n\n\nProfile handling added with docs\n\n\nOne-liner install added\n\n\nDocs: install and update process described\n\n\nDocs: release process described with sample git commands\n\n\nPrint version number in debug mode\n\n\nupdate-snap\n downloads binary from latest os specific CircleCI binary artifact.\n\n\n\n\nChanged\n\n\n\n\nTool specific library renamed from cloudbreak.bash to deployer.bash\n\n\n\n\n[v0.0.3] - 2015-03-19\n\n\nFixed\n\n\n\n\nmake release\n creates binary with X.X.X version when on release branch otherwise X.X.X-gitrev\n\n\n\n\nAdded\n\n\n\n\nDocs: release process described\n\n\n\n\n[v0.0.2] - 2015-03-19\n\n\nAdded\n\n\nAdded\n- selfupdate command\n- gray debug to stderr\n\n\n[v0.0.1] - 2015-03-18\n\n\nAdded\n\n\n\n\nhelp command added\n\n\nversion command added\n\n\nAdded --version\n\n\nCircleCI build\n\n\nLinux/Darwin binary releases on github", 
            "title": "Change Log"
        }, 
        {
            "location": "/changelog/#change-log", 
            "text": "The Change Log summarizes the changes in Cloudbreak.", 
            "title": "Change Log"
        }, 
        {
            "location": "/changelog/#v1160", 
            "text": "", 
            "title": "[v1.16.0]"
        }, 
        {
            "location": "/changelog/#added", 
            "text": "Added SmartSense and Flex subscription integration", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#v1150", 
            "text": "", 
            "title": "[v1.15.0]"
        }, 
        {
            "location": "/changelog/#added_1", 
            "text": "Azure custom role support for credential creation", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed", 
            "text": "ability to query more information about the stack by queryparameters", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v1144", 
            "text": "", 
            "title": "[v1.14.4]"
        }, 
        {
            "location": "/changelog/#fixed", 
            "text": "fix settings generation  fix unable to create Azure cluster with WASB  preserve Knox settings when switching credentials  automatically create /var/run/knox after restart", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_2", 
            "text": "Azure Private IP support  add missing settings block for etl-edw blueprint  show all instance metadata information on shell \"stack metadata\"  add proper error handling for repair flow", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_1", 
            "text": "update HDP version (2.2.0.1 -  2.5.5.0 and 2.6.0.0 -  2.6.0.3)  update Ambari version (2.5.0.0 -  2.5.0.3)  disable Hive credential provider  Azure static IP allocation method instead of dynamic  Azure deallocate VM-s instead of just stopping them on cluster stop  conform to more strict Salt-api calls (since 2016.11.4)  use redhat6 repo on amazonlinux", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v1140", 
            "text": "", 
            "title": "[v1.14.0]"
        }, 
        {
            "location": "/changelog/#added_3", 
            "text": "new Azure connector based on Azure Java SDK  Azure interactive credential creation  new alerting system implemented based on prometheus", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_2", 
            "text": "ability to specify multiple rdsconfig-s per cluster", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v163", 
            "text": "", 
            "title": "[v1.6.3]"
        }, 
        {
            "location": "/changelog/#changed_3", 
            "text": "Upgraded a dependent component in order to address a network configuration issue.  Updated traefik to v1.1.2  Updated Google Cloud SDK to 1.22.0", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v162", 
            "text": "", 
            "title": "[v1.6.2]"
        }, 
        {
            "location": "/changelog/#fixed_1", 
            "text": "return login error if user has multiple accounts in LDAP/AD  extra logging when creating the Ambari client  avoid deploy failures, due to concurrency in Salt highstate  incorrect error message collection from nodes during Salt highstate  reduce host name length on Azure in order to be sure that the fully qualified hostname is under 64 chars  do not overwrite manually changed kerberos config  'securitygroup create' shell command caused a validation error due to missing provider value  autocreate default security groups for every provider  fix bower retry in web dockerfile to avoid UI build fails  Cloudbreak does not work with CentOS on AWS  Shiro config of Zepplein is always overwritten by Cloudbreak  fix cluster sync when a new service is added to Ambari through the wizard  rename all open port security group to denote unsecure  remove all port open security group as default", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_4", 
            "text": "Azure VMs supporting private deployments (when VMs have private ip only)  do not use the same host names for every cluster on Azure  configurable stack name prefix length in Azure host names  set up default HDP version  implement existing MIT KDC  existing AD support  support exsisting security group on AWS  separate security groups per provider  ability to specify image id on API to launch a cluster from that base AMI", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_4", 
            "text": "OS parameter is optional when providing the HDP repo  modularize integration test Makefile to sh scripts", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v161", 
            "text": "", 
            "title": "[v1.6.1]"
        }, 
        {
            "location": "/changelog/#fixed_2", 
            "text": "cannot send invite e-mails from Auth (aka Sultans) when smtp authentictaion is not enabled  recipe shell commands was not aligned with UI and with the implementation  avoid duplicated privateids for instances (they must be unique)  reserve ports on OS for well known Hadoop services  do not fail when there is no default VPC on AWS  reserve TCP/UDP ports on OS for well-known Hadoop services  invalid hostmetadata count after sync when a node from master hostgroup died  shell fix to avoid error when creating cluster using templates with encrypted EBS  fix concurrent removal of alerts in Autoscale (aka Periscope)  ensure that the gcs-connector.sh recipe runs only one time  fix multiple salt-minion start  short names for OpenStack VMs to avoid MySQL / Hive failures  fix uluwatu missing template volume type in some cases  avoid timeouts when IPV6 is disabled https://github.com/saltstack/salt/issues/32719  do not allow cluster reset when external DB is used for Ambari  fix smtp related indentations in application.yml  introducing resource definiton cache, to avoid read the same definition from disk multiple times  invalid hdp repo config (update to 2.5 and support cnetos6 on AWS)  display AWS autoscaling group errors  sporadic ssh connectivity issue from on gcp  no transaction for cluster update  renamed s3role to instanceprofile on UI  avoid alphabetical order of recipes by filename  stop cluster is not possible due to invalid spot price check  sporadic classpath issue, since StackServiceComponentDescriptorMapFactory returns wrong object type", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_5", 
            "text": "OpenStack Liberty and Mitaka support  implement Availibility Zones for OpenStack  dynamic load of custom provider definitions  log every recipe by default (/var/log/recipses)  eventlog about recipe execution  ability to restart cluster installation in case of failed recipe", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_5", 
            "text": "ambari client with sources and extra logging  remove unnecessary admin user  remove cloudbreak log highlighting  remove unused timeout value from recipes  improved logging for saltbootstrap  every recipe runs only once by default", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v160", 
            "text": "", 
            "title": "[v1.6.0]"
        }, 
        {
            "location": "/changelog/#fixed_3", 
            "text": "proper handling of upstart config to avoid concurrency between sysv and upstart during ambari agent / server start  use m3 for dry-run check because it can be started in ec2-classic  consider auto scaling activity history in auto scaling group status checker  eliminate criticals reported by Sonar  ability to create bigger than 999 GB size volumes on Azure  fixed javascript test for nodecount  region is not a required field when posting a new stack", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_6", 
            "text": "ARM template JSON validation  added property to set static shared volume(s) in BYOS clusters  generate salt password per stack  added Hibernate field encryptor to encryt sensitive data in DB  ability to start GCP clusterts in a NATed environment without public IP address  Ambari and HDP versions are added to the /stack API call's response  when deploying a new subnet in an existing VPC on AWS, the CIDR range is automatically calculated when not specified explicitly on the API", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_6", 
            "text": "Cloudbreak dev version uses latest image from image catalog  cleanup unnecessary pillar matchers  update default blueprints to add hive clients to worker nodes  API cleanup, remove invalid required fields from swagger  updated Ambari version to 2.4.1.0", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v150", 
            "text": "", 
            "title": "[v1.5.0]"
        }, 
        {
            "location": "/changelog/#fixed_4", 
            "text": "ClusterBootstrapperTest randomly fails  slider does not work with ssl on python 2.7.9+  fix Ambari address on UI for clusters that provisioned by an older version of Cloudbreak  credential visibility on cluster details view  \"Keystone Version\" dropdown layouts", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_7", 
            "text": "added HDP version field to RDS config  ability to configure remote database for Ambari  stacks/clusters are associated with Cloudbreak version  new resource to configure LDAP service for Knox  support of Google's spot instances  support for c4 instance types in AWS  enable auto recovery for HDP services on failure via blueprint  ability to specify multiple subnets for the same VPC on AWS  ability to configure default regions", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_7", 
            "text": "reinstate recipes on Uluwatu UI  increase Ambari password length and fix error message  automatic blueprint update during startup  on OpenStack stack name contains stack ID  disable upgrade of saltstack  remove unecessary  require  flags from API documentation  improve security of salt communication", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v140-2016-08-12", 
            "text": "", 
            "title": "[v1.4.0] - 2016-08-12"
        }, 
        {
            "location": "/changelog/#fixed_5", 
            "text": "remove invalid auto scaling group history check  fix sync to avoid node count corruption of instance groups  HDP on AWS can return 502 Bad Gateway while accessing Ambari  fix Ambari server ip selection on AWS  fix enable auto scaling with different user", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_8", 
            "text": "new RDS config resource  shell commands for RDS config operations  configurable image catalog  allow dynamically change Ambari version  added  canada  region to Azure  add basic auth to Zeppelin, Zeppelin is secured with the same password like Ambari  ability to configure a custom domain for the clusters with the CB_HOST_DISCOVERY_CUSTOM_DOMAIN env variable", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_8", 
            "text": "update images for on-the-fly ambari update  increase poll timeout for ARM  disable automated map/reduce smoke test  parallel command execution in Ambari  update to Smartsense 1.3.0  add admin user to  hadoop  and  hdfs  groups after Ambari install  use only Cloudbreak address to connect Cloudbreak", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v132", 
            "text": "", 
            "title": "[v1.3.2]"
        }, 
        {
            "location": "/changelog/#fixed_6", 
            "text": "Ambari restart  avoid duplicated alarmas  before upscale the sync won't change the stack state  upscale / downscale fix with Ambari 2.4", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_9", 
            "text": "reverse proxy for UI components  new supported volume type on aws: ST1  Spark reverse proxy settings  Spark jobhistory server reverse proxy settings  create admin user for Ambari views  added group name to AWS instance Name tags  add etl-edw default blueprint  configure Hive RDS through Cloudbreak  configurable default SmartSense configuration and installation  add SmartSense server to a single noded hostgroup if possible  generate SmartSense id as credential attribute  set SmartSense capture schedule on hosts by recipe", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_9", 
            "text": "update to Ambari 2.4.0.0  use OpenJDK instead of Oracle JDK  use Ambari password as default service password  make Sultans base path configurable with '/sl' as default value  create individual root path for Cloudbreak and Periscope  set DNS TTL for AWS clients to  = 60s  rewrite url if ambari sessionid appears in cookies  remove MYSQL_SERVER component from blueprint if there is rds config present  handle AWS account id as String during SmartSense id generation  update proxy users hosts to avoid unauthorized connection for super-user in Oozie  set ONLY_STACK_DEFAULTS_APPLY as default since the new recommendation strategy does not work for Falcon and Ozzie  show blueprint name on review panel and hide hostroup panel by default  show only the previously selected network on the review panel", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#removed", 
            "text": "Spark and Zeppelin nginx proxy settings", 
            "title": "Removed"
        }, 
        {
            "location": "/changelog/#v130-2016-06-06", 
            "text": "", 
            "title": "[v1.3.0] - 2016-06-06"
        }, 
        {
            "location": "/changelog/#fixed_7", 
            "text": "delete cluster containers only if orchestrator type is container  show reason of failed commands when using the shell  login when password contains special characters  textarea placeholder on Internet Explorer 11  HDP repo verification on Uluwatu  wrong instance metadata status during cluster sync  manage platforms close button on UI  null pointer during router creation on non existing Openstack network", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_10", 
            "text": "use salt bootstrap instead of cloudbreak bootstrap  missing gateway port to stack response  enable spot price instances  AWS cluster creation with existing key pair  AWS existing SSH key pair could be configured by credential command  new description and output for CFN stack  add ssh port into instance metadata  seamless s3 connection  custom CIDR validator for subnet  custom tag to CloudFormation stack created by Cloudbreak  start termination flow stops other running flows on the same stack  Openstack API facing option", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_10", 
            "text": "openstack network shell command improvement for the new network types  ability to select where to put ambari server  reorganize kerberos setup in Salt  using private address if only private address is available  always use ports on Openstack even there is no floating ip assigned  floating IP shall not be mandatory, and do not create separate ports  follow HBase port changes  move variant from advanced option to the basic options page  Spring update  elastic ips are managed by CloudFormation  sync starts automatically at startup  read nginx SSL port from parameter instead of static 443  sync to handle instances that are stopped on the provider side  Openstack metadata collection handles manually terminated instances  cleaned up Openstack resources in case of existing subnet", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#removed_1", 
            "text": "recipe and ssd config were removed  docker properties removed from UI", 
            "title": "Removed"
        }, 
        {
            "location": "/changelog/#v126-2016-05-19", 
            "text": "", 
            "title": "[v1.2.6] - 2016-05-19"
        }, 
        {
            "location": "/changelog/#changed_11", 
            "text": "use lates cloud images with ambari-agent:2.2.1-v20  map public ips to vms in case of existing vpc", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v125-2016-04-07", 
            "text": "", 
            "title": "[v1.2.5] - 2016-04-07"
        }, 
        {
            "location": "/changelog/#fixed_8", 
            "text": "slow lazy format on Azure  mounted disks are not visible in containers", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_11", 
            "text": "assume role without adding the keys into cbd Profile  ability to create cluster without public ip  high availability blueprint validator  support for older gcp projectids", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#v124-2016-03-22", 
            "text": "", 
            "title": "[v1.2.4] - 2016-03-22"
        }, 
        {
            "location": "/changelog/#fixed_9", 
            "text": "azure storage location  openstack create network form  azure create network form  gcp disk type", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_12", 
            "text": "GCP subnetsupport  to shell", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_12", 
            "text": "use the provided public network id for allocation floating ips  allow 24 attached volumes for aws  cleaned up openstack resources in case of existing subnet", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v123-2016-03-22", 
            "text": "", 
            "title": "[v1.2.3] - 2016-03-22"
        }, 
        {
            "location": "/changelog/#fixed_10", 
            "text": "sudo right of CB user", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_13", 
            "text": "Azure default network", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#v122-2016-03-21", 
            "text": "", 
            "title": "[v1.2.2] - 2016-03-21"
        }, 
        {
            "location": "/changelog/#fixed_11", 
            "text": "credential validation in case of Mesos/Marathon", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#v121-2016-03-21", 
            "text": "", 
            "title": "[v1.2.1] - 2016-03-21"
        }, 
        {
            "location": "/changelog/#fixed_12", 
            "text": "live migration operations", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#v120-2016-03-18", 
            "text": "", 
            "title": "[v1.2.0] - 2016-03-18"
        }, 
        {
            "location": "/changelog/#fixed_13", 
            "text": "consul recursor now exculdes both docker ip and bridge ip to avoid recursive dns recursor chain  docs fixed about getting default credentials (cbd login)  updates cb-shell to 0.5.37 to fix ssl issues", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_14", 
            "text": "Command  cbd azure configure-arm  will create your arm application which can used by cloudbreak  Command  cbd azure deploy-dash  will deploy a dash application in your Azure account  Command  cbd start  will execute the migration by default. If SKIP_DB_MIGRATION_ON_START envvar set to true in Profile, the migration will be skipped  Using Dns SRV record in our services instead of ambassador  Using docker linking system in third party services instead of ambassador  Integration tests are added, where cbd binary is called, not only sourced functions  Docker based CentOS integration test make target added  Uaa db migration  SMTP default parameters added:  CLOUDBREAK_SMTP_AUTH  and  CLOUDBREAK_SMTP_STARTTLS_ENABLE  and  CLOUDBREAK_SMTP_TYPE  Local development Uluwatu configuration by ULUWATU_VOLUME_HOST environment variable  Local development Sultans configuration by SULTANS_VOLUME_HOST environment variable  install script for fixed version and install-latest for latest release added  Each snapshot artifact is uploaded as http://public-repo-1.hortonworks.com/HDP/cloudbreak/cbd-snapshot-$(uname).tgz  Configuration ability to enable or disable ssh fingerprint verification of virtual machines on GCP and AWS", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#removed_2", 
            "text": "Full removal of ambassador", 
            "title": "Removed"
        }, 
        {
            "location": "/changelog/#changed_13", 
            "text": "cbd start  doesnt start if compose yaml regeneration is needed  cbd generate  is less verbose, diff doesnt shown  cbd doctor  shows diff if generate would change  cbd regenerate  creates backup files if changes detected  sequenceiq/uaadb:1.0.1 is used instead of postgres:9.4.1", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v103-2015-09-03", 
            "text": "", 
            "title": "[v1.0.3] - 2015-09-03"
        }, 
        {
            "location": "/changelog/#fixed_14", 
            "text": "Authentication error with  cloudbreak-shell  and  cloudbreak-shell-quiet  is fixed  Command  cbd update  branch  checks for artifact", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_15", 
            "text": "binary version of gnu-sed 4.2.2 is now included, to solve lot of osx/busybox issues  consul recursor test are added", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_14", 
            "text": "sequenceiq/cloudbreak image updated to 1.0.3    debug() function made multiline capable. Use \\n in messages   refactor bridge ip discovery to run helper docker command only once  consul recursor handling refactored to be more robust", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v102-2015-08-25", 
            "text": "", 
            "title": "[v1.0.2] - 2015-08-25"
        }, 
        {
            "location": "/changelog/#added_16", 
            "text": "DOCKER_CONSUL_OPTIONS  config option to provide arbitrary consul option", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_15", 
            "text": "Fixed docker version checker to be 1.8.1 compatible. (docker added --format option)  sequenceiq/cloudbreak image updated to 1.0.2  consul image changed from sequenceiq/consul to gliderlabs/consul  consul image updated to 0.5.2 (from 0.5.0)  consul discovers host dns settings, and uses the configured nameserver as recursor", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v100-2015-07-23", 
            "text": "", 
            "title": "[v1.0.0] - 2015-07-23"
        }, 
        {
            "location": "/changelog/#fixed_15", 
            "text": "GA Release", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#v058-2015-07-23", 
            "text": "", 
            "title": "[v0.5.8] - 2015-07-23"
        }, 
        {
            "location": "/changelog/#fixed_16", 
            "text": "Fix CircleCI release. CircleCI doesnt allow --rm on docker run", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#v057-2015-07-23", 
            "text": "", 
            "title": "[v0.5.7] - 2015-07-23"
        }, 
        {
            "location": "/changelog/#fixed_17", 
            "text": "Fix make release dependency  Fix CHANGELOG generation at  make release-next-ver  avoid inserting extra -e", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#v056-2015-07-23", 
            "text": "", 
            "title": "[v0.5.6] - 2015-07-23"
        }, 
        {
            "location": "/changelog/#added_17", 
            "text": "Release artifacts are published at public-repo-1.hortonworks.com/HDP/cloudbreak/", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#v055-2015-07-10", 
            "text": "", 
            "title": "[v0.5.5] - 2015-07-10"
        }, 
        {
            "location": "/changelog/#added_18", 
            "text": "Command  pull-parallel  added for quicker/simultaneous image pull  Release process includes upload to public-repo s3 bucket", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_16", 
            "text": "License changed from MIT to Apache v2  release artifact includes additional files: license/readme/notes", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v054-2015-07-03", 
            "text": "", 
            "title": "[v0.5.4] - 2015-07-03"
        }, 
        {
            "location": "/changelog/#added_19", 
            "text": "New  cbd-cleanup  command for removing old images or exited containers  Baywatch default parameters added:  CB_BAYWATCH_ENABLED  and CB_BAYWATCH_EXTERN_LOCATION  Logs are saved via lospout  TLS client certificate needed by Cloudbreak is generated with  cbd generate  Command  aws delete-role  added  Command  aws generate-role  added  Command  aws show-role  added  Command  cloudbreak-shell  added  Command  cloudbreak-shell-quiet  added  Command  local-dev  added  Command  token  added", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_17", 
            "text": "AWS authentication env varibale is fixed to use the correct AWS_SECRET_ACCESS_KEY (instead the old AWS_SECRET_KEY)  Using sequenceiq/ambassadord:0.5.0 docker image instead of progrium/ambassadord:latest", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v053-2015-06-03", 
            "text": "", 
            "title": "[v0.5.3] - 2015-06-03"
        }, 
        {
            "location": "/changelog/#fixed_18", 
            "text": "One-liner installer fixed, to work if previous cbd exists on path.  cbd update  upstream changes on go-bahser broke the selfupdate functionality  In some environment cloudbreak starts really slow. See:  details , see:  commit", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_20", 
            "text": "New release proposal can be done by  make release-next-ver", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#v052-2015-05-21", 
            "text": "", 
            "title": "[v0.5.2] - 2015-05-21"
        }, 
        {
            "location": "/changelog/#changed_18", 
            "text": "Command  doctor  hints to run boot2docker shellinit if env is unset  Command  init  in case of OSX, DOCKER_XXX envs are initialized in local profile (Profile)  Default docker images are updated to:  sequenceiq/cloudbreak:0.5.93  sequenceiq/cbdb:0.5.92  sequenceiq/uluwatu:0.5.28  sequenceiq/sultans:0.5.3  sequenceiq/periscope:0.5.5", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v051-2015-05-18", 
            "text": "", 
            "title": "[v0.5.1] - 2015-05-18"
        }, 
        {
            "location": "/changelog/#fixed_19", 
            "text": "Issue #55: Sed handles more robust the issue with: curl includes an extra CR char in header fields.", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#removed_3", 
            "text": "deployer doesnt specify cloud specific image defaults. If left empty, they fall back\n  to defaults specified in  java code  CB_AZURE_IMAGE_URI  CB_AWS_AMI_MAP  CB_OPENSTACK_IMAGE  CB_GCP_SOURCE_IMAGE_PATH", 
            "title": "Removed"
        }, 
        {
            "location": "/changelog/#changed_19", 
            "text": "Command  logs  got usage example for specifying services as filter  Default docker images are updated to:  sequenceiq/cloudbreak:0.5.49  sequenceiq/uluwatu:0.5.16  sequenceiq/sutans:0.5.2", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v050-2015-05-08", 
            "text": "", 
            "title": "[v0.5.0] - 2015-05-08"
        }, 
        {
            "location": "/changelog/#fixed_20", 
            "text": "Command  pull  generates yaml files in case they are missing #31", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_21", 
            "text": "Command  login  Shows Uluwatu login url and credentials  Command  regenerate  deletes and generates docker-compose.yml and uaa.yml  Command  delete  added: deletes yamls and dbs  Command  cloudbreak-shell  added, right now it internale use DEBUG=1 fn fn-call  Command  version  does correct  Semantic Versioning  check to advise an upgrade  Command  generate  checks and shows if Profile change would result in yaml change.  Command  start : prints uluwatu url and credential hint  Command  doctor : fixes boot2docker date/time if not the same as on the host  Internal command:  browse  added to be able to automatically open a browser to a specified url.  Mini Getting Started guide added into README  make dev-debug  installs a special cbd on local OSX, which doesnt includes *.bash scrips, only refers them\n   by path. No need to  make dev  to test small changes in bash scripts.  Load AWS key and AWS id from Profile  Command  init  helps to guess the PUBLIC_IP in public clouds: google, amazon", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_20", 
            "text": "Command  cbd env export  adds export to the begining of each line  cbd logs accepts optional [services] parameter  docker-compose uses  cbreak_  prefix for container naming instead of the directory name  Command  generate  prints out some more usefull info  uaa.yml generation wont overwrite, just instruct to move existing file (like docker-compose.yml generation)  Command  init  hint fixed on linux.  Command  init  advise to run  generate  if it finds a Profile  Command  init  set PRIVATE_IP the same as PUBLIC_IP for boot2docker  Command  migrate  is introduced for db migration see  Migrate the databases  section of README  Command  startdb  starts the cbdb and pcdb database containers only  Databases are not deleted after boot2docker restart  Import ULU_HOST_ADDRESS and ULU_SULTANS_ADDRESS from Profile", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v010-2015-04-16", 
            "text": "", 
            "title": "[v0.1.0] - 2015-04-16"
        }, 
        {
            "location": "/changelog/#fixed_21", 
            "text": "Selfupdate updates the actual running binary intead of the fixed /us/local/bin/cbd  SMTP default port is 25, to fix number conversion exception", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_22", 
            "text": "Command  init  creates Profile  Install cbd to a directory which is available on $PATH  Docker based test for the one-liner install from README.md:  make install-test", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#removed_4", 
            "text": "update-snap  command removed, replaced by parametrized  update", 
            "title": "Removed"
        }, 
        {
            "location": "/changelog/#changed_21", 
            "text": "Cloudbreak/Persicope/Uluwatu/Sultans Dcoker images upgraded to 0.4.x  Use the built in 'checksum' function instead of the external 'shasum' to generate secrets  Command  update  by default updates from latest Github release, parameter can point to branch on CircleCI  DOCKER_XXX env varibles are inherited, so they not needed in Profile  generate  and compose specific commands are only available when  Profile  exists  generate  command genertes docker-compose.yml  and  uaa.yml  PRIVATE_IP  env var defaults to bridge IP (only PUBLC_IP is required in Profile)  use  sulans-bin  docker image istead of sultans", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v009-2015-04-14", 
            "text": "", 
            "title": "[v0.0.9] - 2015-04-14"
        }, 
        {
            "location": "/changelog/#fixed_22", 
            "text": "Bash 4.3 is included in the binary, extracted into .deps/bin upon start", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#v008-2015-04-13", 
            "text": "", 
            "title": "[v0.0.8] - 2015-04-13"
        }, 
        {
            "location": "/changelog/#fixed_23", 
            "text": "Fixing deps module, golang fn: checksum added  CircleCI mdule defines required jq  Fixing PATH issue for binary deps", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_23", 
            "text": "uaadb start added  identity server start added  make dev  added to mac based development  pull  command added  logs  command added", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_22", 
            "text": "Docker containers are managed by  docker-compose", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v007-2015-03-26", 
            "text": "", 
            "title": "[v0.0.7] - 2015-03-26"
        }, 
        {
            "location": "/changelog/#added_24", 
            "text": "make tests  runs unit tests  docker unit tests are added  start command added: WIP consul, registrator starts  kill command addd: stops and removes cloudbreak specific containers  SKIP_XXX skips the container start", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_23", 
            "text": "env command namespace is always exported, not only in DEBUG mode  env export: machine friendly config list  env show: human readable config list  circle runs unit tests  snapshot binaries include branch name in version string", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v006-2015-03-25", 
            "text": "", 
            "title": "[v0.0.6] - 2015-03-25"
        }, 
        {
            "location": "/changelog/#fixed_24", 
            "text": "removed dos2unix dependency for the update command", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_25", 
            "text": "doctor command added  docker-check-version command added  cci-latest accepts branch as parameter, needed for PR testing  export fn command in DEBUG mode  export env command in DEBUG mode  doctor: add instruction about setting DOCKER_XXX env vars in Profile  info() function added to print green text to STDOUT", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_24", 
            "text": "HOME env var is also inherited (boot2docker version failed)  release process fully automatized", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v005-2015-03-23", 
            "text": "update  command works without dos2unix", 
            "title": "[v0.0.5] - 2015-03-23"
        }, 
        {
            "location": "/changelog/#v004-2015-03-23", 
            "text": "", 
            "title": "[v0.0.4] - 2015-03-23"
        }, 
        {
            "location": "/changelog/#fixed_25", 
            "text": "debug function fixed  DEBUG, TRACE and CBD_DEFAULT_PROFILE env vars are inherited", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_26", 
            "text": "Profile handling added with docs  One-liner install added  Docs: install and update process described  Docs: release process described with sample git commands  Print version number in debug mode  update-snap  downloads binary from latest os specific CircleCI binary artifact.", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#changed_25", 
            "text": "Tool specific library renamed from cloudbreak.bash to deployer.bash", 
            "title": "Changed"
        }, 
        {
            "location": "/changelog/#v003-2015-03-19", 
            "text": "", 
            "title": "[v0.0.3] - 2015-03-19"
        }, 
        {
            "location": "/changelog/#fixed_26", 
            "text": "make release  creates binary with X.X.X version when on release branch otherwise X.X.X-gitrev", 
            "title": "Fixed"
        }, 
        {
            "location": "/changelog/#added_27", 
            "text": "Docs: release process described", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#v002-2015-03-19", 
            "text": "", 
            "title": "[v0.0.2] - 2015-03-19"
        }, 
        {
            "location": "/changelog/#added_28", 
            "text": "Added\n- selfupdate command\n- gray debug to stderr", 
            "title": "Added"
        }, 
        {
            "location": "/changelog/#v001-2015-03-18", 
            "text": "", 
            "title": "[v0.0.1] - 2015-03-18"
        }, 
        {
            "location": "/changelog/#added_29", 
            "text": "help command added  version command added  Added --version  CircleCI build  Linux/Darwin binary releases on github", 
            "title": "Added"
        }, 
        {
            "location": "/aws/", 
            "text": "AWS Images\n\n\nWe have pre-built Cloudbreak Deployer cloud images for AWS with the Cloudbreak Deployer pre-installed. Go to your \nAWS Management Console\n to launch the latest Cloudbreak Deployer image in your region.  \n\n\n\n\nAs an alternative to using the pre-built cloud images for AWS, you can install Cloudbreak Deployer on your own VM. For more information, see the \ninstallation instructions\n.\n\n\n\n\nPrerequisites\n\n\nPorts\n\n\nMake sure that you have opened the following ports on your \nsecurity group\n:\n\n\n\n\nSSH (22)\n\n\nCloudbreak (443)\n\n\n\n\nCloudbreak Deployer AWS Image Details\n\n\nVM Requirements\n\n\nWhen selecting an instance type, consider these minimum and recomended requirements:  \n\n\n\n\n8GB RAM, 10GB disk, 2 cores. \n\n\nThe minimum instance type which is suitable for Cloudbreak is \nm3.large\n.\n\n\n\n\nTo learn about all requirements, see \nSystem Requirements\n.\n\n\nCloudbreak Deployer Setup on AWS\n\n\nBefore getting started with Cloudbreak Deployer, you should know that:\n\n\n\n\nThe default SSH username for the EC2 instances is \ncloudbreak\n.\n\n\nCloudbreak Deployer location on your EC2 instance is \n/var/lib/cloudbreak-deployment\n. This is the\n  \ncbd\n root folder.\n\n\nYou must execute all \ncbd\n actions from the \ncbd\n root folder as a \ncloudbreak\n user.\n\n\n\n\nIn the previous step, you should have already set up a VM with Cloudbreak Doployer either \nusing the AWS Cloud Images\n or by \ninstalling the\nCloudbreak Deployer\n manually on your own VM.\n\n\nNow you need to \nconnect to the previously created \ncbd\n VM\n.\n\n\nCloudbreak Deployment Directory\n\n\nTo navigate to the \ncloudbreak-deployment\n directory, run:\n\n\ncd /var/lib/cloudbreak-deployment/\n\n\n\n\nThis directory contains configuration files and the supporting binaries for Cloudbreak Deployer.\n\n\nInitialize Your Profile\n\n\nFirst, initialize deployer by creating a \nProfile\n file with the following content:\n\n\nexport UAA_DEFAULT_SECRET='[SECRET]'\nexport UAA_DEFAULT_USER_PW='[PASSWORD]'\n\n\n\n\nBy default the \ncbd\n tool tries to guess \nPUBLIC_IP\n to bind Cloudbreak UI to it. But if \ncbd\n cannot get the IP address during the initialization, set the appropriate value also in your \nProfile\n.\n\n\nStart Cloudbreak Deployer\n\n\nTo start the Cloudbreak application use the following command:\n\n\ncbd start\n\n\n\n\nThis will start all the Docker containers and initialize the application.\n\n\n\n\nThe first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.\n\n\n\n\nThe \ncbd start\n command includes the \ncbd generate\n command which applies the following steps:\n\n\n\n\nCreates the \ndocker-compose.yml\n file that describes the configuration of all the Docker containers needed for the Cloudbreak deployment.\n\n\nCreates the \nuaa.yml\n file that holds the configuration of the identity server used to authenticate users to Cloudbreak.\n\n\n\n\nValidate that Cloudbreak Deployer Has Started\n\n\nAfter the \ncbd start\n command finishes, check the following:\n\n\n\n\n\n\nPre-installed Cloudbreak Deployer version and health:\n   \ncbd doctor\n\n\n\n\nIf you need to run \ncbd update\n, refer to \nCloudbreak Deployer Update\n.\n\n\n\n\n\n\n\n\nCloudbreak Application logs:\n   \ncbd logs cloudbreak\n\n  You should see a message like this in the log: \nStarted CloudbreakApplication in 36.823 seconds\n. Cloudbreak normally takes less than a minute to start.\n\n\n\n\n\n\nConfigure Role-based Credentials\n\n\nThere are two ways to create AWS credentials in Cloudbreak:\n\n\nKey-based:\n This requires your AWS access key and secret key pair. Cloudbreak will use these keys to launch the resources. For starters, this is a simpler option that does not require additional configuration. You will provide the keys later when you \nprovision an HDP cluster\n.\n\n\nRole-based:\n This requires a valid \nIAM role\n with \"AssumeRole\" policy. Cloudbreak will assume this role to get temporary access and the access/secret key pair.\n\n\nTo configure role-based credentials, start your instance with an \"AssumeRole\" policy. For more information, see \nUsing Instance Profiles\n and \nUsing an IAM Role to Grant Permissions to Applications Running on Amazon EC2 Instances\n.\n\n\nAlternatively, you can set your AWS keys of an IAM user with an\"AssumeRole\" policy in the \nProfile\n file:\n\n\nexport AWS_ACCESS_KEY_ID=AKIA**************W7SA\nexport AWS_SECRET_ACCESS_KEY=RWCT4Cs8******************/*skiOkWD\n\n\n\n\n\nIf you want to use instance profile, do not set these variables. If you want to use Cloudbreak with Role ARNs instead of keys, make sure that the instance profile role can assume roles on AWS.   \n\n\n\n\nOptional Configurations\n\n\nYou can perform the following optional configurations:\n\n\nSet Custom Tags\n\n\nIn order to differentiate launched instances, we give you the option to use custom tags on your AWS resources deployed by Cloudbreak. You can use the tagging mechanism with the following variables. \n\n\nIf you want just one custom tag on your Cloudformation resources, set this variable :\n\n\nexport CB_AWS_DEFAULT_CF_TAG=whatever\n\n\n\n\nThen the name of the tag will be \nCloudbreakId\n and the value will be \nwhatever\n.\n\n\nIf you need more specific tagging, set this variable:\n\n\nexport CB_AWS_CUSTOM_CF_TAGS=myveryspecifictag:veryspecific\n\n\n\n\nThen the name of the tag will be \nmyveryspecifictag\n and the value will be \nveryspecific\n. You can specify a list of tags here with a comma separated list; for example: \ntag1:value1,tag2:value2,tag3:value3\n.\n\n\nCluster Provisioning Prerequisites\n\n\nIAM Role Setup\n\n\n\n\nIf you want to use your Aws Access Key and your Secret Access Key to authenticate to Amazon then please use the \nKey based authentication\n and you do not need to setup an IAM Role.\n\n\n\n\nCloudbreak works by connecting your AWS account through so called \nCredentials\n, and then uses these credentials to \ncreate resources on your behalf.\n\n\n\n\nIMPORTANT\n Cloudbreak deployment uses two different AWS accounts for two different purposes:\n\n\n\n\n\n\nThe account belonging to the \nCloudbreak webapp\n itself, acts as a \nthird party\n, that creates resources on the \naccount of the \nend user\n. This account is configured at server-deployment time.\n\n\nThe account belonging to the \nend user\n who uses the UI or the Shell to create clusters. This account is configured\n when setting up credentials.\n\n\n\n\nThese accounts are usually \nthe same\n when the end user is the same who deployed the Cloudbreak server, but it allows\n Cloudbreak to act as a SaaS project as well if needed.\n\n\nCredentials use \nIAM Roles\n to give access to the \nthird party to act on behalf of the end user without giving full access to your resources.\nThis IAM Role will be \nassumed\n later by an IAM user.\n\n\nAWS IAM Policy that grants permission to assume a role\n\n\nYou cannot assume a role with root account\n, so you need to \ncreate an IAM user\n with an attached \nInline\n \npolicy\n and \nthen set the \nAccess key and Secret Access key\n in the \n\nProfile\n file (check \nthis description\n out).\n\n\nThe \nsts-assume-role\n IAM user \npolicy\n must be configured to have \npermission to assume roles on all resources. Here it is the policy to configure the \nsts:AssumeRole\n for all \n\nResource\n:\n\n\n{\n\u2002\u2002\nVersion\n: \n2012-10-17\n,\n\u2002\u2002\nStatement\n: [\n\u2002\u2002\u2002\u2002{\n\u2002\u2002\u2002\u2002\u2002\u2002\nSid\n: \nStmt1400068149000\n,\n\u2002\u2002\u2002\u2002\u2002\u2002\nEffect\n: \nAllow\n,\n\u2002\u2002\u2002\u2002\u2002\u2002\nAction\n: [\n\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\nsts:AssumeRole\n\n\u2002\u2002\u2002\u2002\u2002\u2002],\n\u2002\u2002\u2002\u2002\u2002\u2002\nResource\n: [\n\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\n*\n\n\u2002\u2002\u2002\u2002\u2002\u2002]\n\u2002\u2002\u2002\u2002}\n\u2002\u2002]\n}\n\n\n\n\nTo connect your (\nend user\n) AWS account with a credential in Cloudbreak you'll have to create an IAM role on your \nAWS account that is configured to allow the third-party account to access and create resources on your behalf.\nThe easiest way to do this is with \ncbd\n commands (but it can also be done manually from the \nAWS Console\n):\n\n\ncbd aws generate-role  - Generates an AWS IAM role for Cloudbreak provisioning on AWS\ncbd aws show-role      - Show assumers and policies for an AWS role\ncbd aws delete-role    - Deletes an AWS IAM role, removes all inline policies\n\n\n\n\nThe \ngenerate-role\n command creates a role that is assumable by the Cloudbreak Deployer AWS account and has a broad policy setup.\nThis command creates a role with the name \ncbreak-deployer\n by default. If you'd like to create role with a different\n name or multiple roles, you need to add this line to your \nProfile\n:\n\n\nexport AWS_ROLE_NAME=my-cloudbreak-role\n\n\n\n\nYou can check the generated role on your AWS console, under IAM roles:\n\n\n\nFull size \nhere\n.\n\n\nGenerate a New SSH Key\n\n\nAll the instances created by Cloudbreak are configured to allow key-based SSH,\nso you'll need to provide an SSH public key that can be used later to SSH onto the instances in the clusters you'll create with Cloudbreak.\nYou can use one of your existing keys or you can generate a new one.\n\n\nTo generate a new SSH keypair:\n\n\nssh-keygen -t rsa -b 4096 -C \nyour_email@example.com\n\n# Creates a new ssh key, using the provided email as a label\n# Generating public/private rsa key pair.\n\n\n\n\n# Enter file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]\nYou'll be asked to enter a passphrase, but you can leave it empty.\n\n# Enter passphrase (empty for no passphrase): [Type a passphrase]\n# Enter same passphrase again: [Type passphrase again]\n\n\n\n\nAfter you enter a passphrase the keypair is generated. The output should look something like below. \n\n\n# Your identification has been saved in /Users/you/.ssh/id_rsa.\n# Your public key has been saved in /Users/you/.ssh/id_rsa.pub.\n# The key fingerprint is:\n# 01:0f:f4:3b:ca:85:sd:17:sd:7d:sd:68:9d:sd:a2:sd your_email@example.com\n\n\n\n\nLater you'll need to pass the \n.pub\n file's contents to Cloudbreak and use the private part to SSH to the instances\n\n\nCluster Provisioning via Browser\n\n\nYou can log into the Cloudbreak application at \nhttps://\nPublic_IP\n/\n.\n\n\nThe main goal of the Cloudbreak UI is to easily create clusters on your own cloud provider account.\nThis description details the AWS setup - if you'd like to use a different cloud provider check out its manual.\n\n\nThis document explains the four steps that need to be followed to create Cloudbreak clusters from the UI:\n\n\n\n\nconnect your AWS account with Cloudbreak\n\n\ncreate some template resources on the UI that describe the infrastructure of your clusters\n\n\ncreate a blueprint that describes the HDP services in your clusters\n\n\nlaunch the cluster itself based on these resources\n\n\n\n\n\n\nIMPORTANT\n Make sure that you have sufficient qouta (CPU, network, etc) for the requested cluster size\n\n\n\n\nSetting up AWS Credentials\n\n\nCloudbreak works by connecting your AWS account through so called \nCredentials\n, and then uses these credentials to \ncreate resources on your behalf. The credentials can be configured on the \nmanage credentials\n panel on the \nCloudbreak Dashboard.\n\n\nTo create a new AWS credential follow these steps:\n\n\n\n\nSelect the credential type. For instance, select the \nRole Based\n\n\nFill out the new credential \nName\n\n\nOnly alphanumeric and lowercase characters (min 5, max 100 characters) can be applied\n\n\n\n\n\n\nCopy your AWS IAM role's Amazon Resource Name (ARN) to the \nIAM Role ARN\n field\n\n\nCopy your SSH public key to the \nSSH public key\n field\n\n\nThe SSH public key must be in OpenSSH format and it's private keypair can be used later to \nSSH onto every \ninstance\n of every cluster you'll create with this credential.\n\n\nThe \nSSH username\n for the EC2 instances is \ncloudbreak\n.\n\n\n\n\n\n\n\n\n\n\nAny other parameter is optional here.\n\n\nPublic in account\n means that all the users belonging to your account will be able to use this credential to create \nclusters, but cannot delete it.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nInfrastructure Templates\n\n\nAfter your AWS account is linked to Cloudbreak you can start creating resource templates that describe your clusters' infrastructure:\n\n\n\n\ntemplates\n\n\nnetworks\n\n\nsecurity groups\n\n\n\n\nWhen you create one of the above resources, \nCloudbreak does not make any requests to AWS. Resources are only created\n on AWS after the \ncreate cluster\n button has pushed.\n These templates are saved to Cloudbreak's database and can be \n reused with multiple clusters to describe the infrastructure.\n\n\nTemplates\n\n\nTemplates describe the \ninstances of your cluster\n - the instance type and the attached volumes. A typical setup is\n to combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple\n large disks to the datanodes or have memory optimized instances for Spark nodes.\n\n\nThe instance templates can be configured on the \nmanage templates\n panel on the Cloudbreak Dashboard.\n\n\nThere are some optional configurations here as well:\n\n\n\n\nSpot price (USD)\n If specified Cloudbreak will request spot price instances (which might take a while or never be \nfulfilled by Amazon). \nThis option is \nnot supported\n by the default RedHat images\n.\n\n\nEBS encryption\n is supported for all volume types. If this option is checked then all the attached disks \nwill be encrypted\n by Amazon using the AWS KMS master keys.\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to use this resource to create clusters, but cannot delete it.\n\n\n\n\nNetworks\n\n\nYour clusters can be created in their own \nVirtual Private Cloud (VPC)\n or in one of your already existing VPCs.\nIf you choose an existing VPC it is possible to create a new subnet within the VPC or use an already existing one.\nThe subnet's IP range must be defined in the \nSubnet (CIDR)\n field using the general CIDR notation.\n\n\nDefault AWS Network\n\n\nIf you don't want to create or use your custom VPC, you can use the \ndefault-aws-network\n for all your\nCloudbreak clusters. It will create a new VPC with a \n10.0.0.0/16\n subnet every time a cluster is created.\n\n\nCustom AWS Network\n\n\nIf you'd like to deploy a cluster to a custom VPC you'll have to \ncreate a new network\n template on the \nmanage\nnetworks\n panel.\n\n\nYou have the following options:\n\n\n\n\nCreate a new VPC and a new subnet\n: Every time a cluster is created with this kind of network setup a new VPC and a new subnet with the specified IP range will be created for the instances on AWS.\n\n\nCreate a new subnet in an existing VPC\n:  Use this kind of network setup if you already have a VPC on AWS where you'd like to put the Cloudbreak created cluster but you'd like to have a separate subnet for it. This setup is only supported for basic VPCs, where an Internet Gateway is configured and instances can have public IP addresses to access the Internet. If you have a specific VPC setup (VGW, NAT, private subnets, etc..) then only the third option can be used.\n\n\nUse an existing subnet in an existing VPC\n:  Use this kind of network setup if you have an existing VPC with one or more subnets on AWS and you'd like to start the instances of a cluster in one - or more - of those subnets. Use this setup if you have a specific VPC setup: you should first create the subnet(s) directly through AWS and provide their IDs here. The subnets could be even in different availability zones and you can set a single or a comma separated list of subnets in the 'Subnet Identifier' field. There are only two requirements for the subnets:\n\n\ninstances in the subnet should be able to reach the Internet to download yum packages (it can be done through a Virtual Gateway, a NAT instance, an Internet Gateway or any other setup)\n\n\nthe VM where Cloudbreak is deployed must be able to reach the instances in the cluster on port 443. (It\u2019s in the same subnet, or through a router from another subnet)\n\n\nNOTE\n: instances in the subnet doesn't need to have public IP addresses in this case\n\n\n\n\n\n\n\n\nYou can configure the \nSubnet Identifier\n and the \nInternet Gateway Identifier\n (IGW) of your VPC.\n\n\n\n\nIMPORTANT:\n The subnet CIDR cannot overlap each other in a VPC. So you have to create different network\ntemplates for every each clusters.\n\n\n\n\nTo create a new subnet within the VPC, provide the ID of the subnet which is in the existing VPC and your cluster\nwill be launched into that subnet. \nFor example\n you can create 3 different clusters with 3 different network\ntemplates for multiple subnets \n10.0.0.0/24\n, \n10.0.1.0/24\n, \n10.0.2.0/24\n with the same VPC and IGW identifiers.\n\n\n\n\nIMPORTANT:\n Make sure the define subnet here doesn't overlap with any of your already deployed subnet in\nthe VPC, because the validation only happens after the cluster creation starts.\n\n\nIn case of existing subnet make sure you have enough room within your network space for the new instances.\n\n\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to use this network template\nto create clusters, but cannot delete it.\n\n\n\n\nNOTE:\n The VPCs, IGWs and subnet are created on AWS only after the the cluster provisioning starts with the selected\nnetwork template.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nSecurity groups\n\n\nSecurity group templates are very similar to the \nsecurity groups on the AWS Console\n.\n\nThey describe the allowed inbound traffic to the instances in the cluster.\n\nCurrently only one security group template can be selected for a Cloudbreak cluster and all the instances have a \npublic IP address so all the instances in the cluster will belong to the same security group.\nThis may change in a later release.\n\n\nDefault Security Group\n\n\nYou can also use the two pre-defined security groups in Cloudbreak.\n\n\nonly-ssh-and-ssl:\n all ports are locked down except for SSH and the selected Ambari Server HTTPS (you can't access Hadoop services outside of the VPC):\n\n\n\n\nSSH (22)\n\n\nHTTPS (443)\n\n\n\n\nCustom Security Group\n\n\nYou can define your own security group by adding all the ports, protocols and CIDR range you'd like to use. The rules\n defined here doesn't need to contain the internal rules, those are automatically added by Cloudbreak to the security group on AWS.\n\n\nHadoop services :\n\n Ambari (8080)\n\n Consul (8500)\n\n NN (50070)\n\n RM Web (8088)\n\n Scheduler (8030RM)\n\n IPC (8050RM)\n\n Job history server (19888)\n\n HBase master (60000)\n\n HBase master web (60010)\n\n HBase RS (16020)\n\n HBase RS info (60030)\n\n Falcon (15000)\n\n Storm (8744)\n\n Hive metastore (9083)\n\n Hive server (10000)\n\n Hive server HTTP (10001)\n\n Accumulo master (9999)\n\n Accumulo Tserver (9997)\n\n Atlas (21000)\n\n KNOX (8443)\n\n Oozie (11000)\n\n Spark HS (18080)\n\n NM Web (8042)\n\n Zeppelin WebSocket (9996)\n\n Zeppelin UI (9995)\n\n Kibana (3080)\n* Elasticsearch (9200)\n\n\n\n\nIMPORTANT\n 443, 9443, and 22 ports needs to be there in every security group otherwise Cloudbreak won't be able to communicate with the provisioned cluster.\n\n\n\n\nUse existing security group\n\n\nUse this kind of security group if you have an existing security group and you'd like to apply same rules to each host group in a cluster.\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to use this security group \ntemplate to create clusters, but cannot delete it.\n\n\n\n\nNOTE:\n The security groups are created on AWS only after the cluster provisioning starts with the selected security group template.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nDefining Cluster Services\n\n\nBlueprints\n\n\nBlueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are \nused by Ambari\n.\n\n\nYou can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file, URL (an \nexample blueprint\n) or the \nwhole JSON can be written in the \nJSON text\n box.\n\n\nThe host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.\n\n\n\n\nNOTE:\n It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will \nfill that with a default value.\n\n\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to use this blueprint to \ncreate clusters, but cannot delete or modify it.\n\n\n\n\nFull size \nhere\n.\n\n\nA blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications.\n\nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations...etc. that won't be applicable to the Cloudbreak cluster\n\n\nCluster Deployment\n\n\nAfter all the cluster resources are configured you can deploy a new HDP cluster.\n\n\nHere is a \nbasic flow for cluster creation on Cloudbreak Web UI\n:\n\n\n\n\nStart by selecting a previously created AWS credential in the header.\n\n\nOpen \ncreate cluster\n\n\n\n\nConfigure Cluster\n tab\n\n\n\n\nFill out the new cluster \nname\n\n\nCluster name must start with a lowercase alphabetic character then you can apply lowercase alphanumeric and \n   hyphens only (min 5, max 40 characters)\n\n\n\n\n\n\nSelect a \nRegion\n where you like your cluster be provisioned\n\n\nClick on the \nSetup Network and Security\n button\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to see the created cluster on\n the UI, but cannot delete or modify it.\n\n\n\n\n\n\n\n\nSetup Network and Security\n tab\n\n\n\n\nSelect one of the security groups\n\n\nClick on the \nChoose Blueprint\n button\n\n\nIf \nEnable security\n is checked as well, Cloudbreak will install Key Distribution Center (KDC) and the cluster will \nbe Kerberized. See more about it in the \nKerberos\n section of this documentation.\n\n\n\n\n\n\n\n\nChoose Blueprint\n tab\n\n\n\n\nSelect one of the blueprint\n\n\nAfter you've selected a \nBlueprint\n, you should be able to configure:\n\n\nthe templates\n\n\nthe securitygroups\n\n\nthe number of nodes for all of the host groups in the blueprint\n\n\n\n\n\n\nYou need to select where you want to install the Ambari server to. Only 1 host group can be selected.\n   If you want to install the Ambari server to a separate node, you need to extend your blueprint with a new host group\n   which contains only 1 service: HDFS_CLIENT and select this host group for the Ambari server. Note: this host group cannot be scaled so \n   it is not advised to select a 'slave' host group for this purpose.\n\n\nClick on the \nReview and Launch\n button\n\n\n\n\nReview and Launch\n tab\n\n\n\n\nAfter the \ncreate and start cluster\n button has clicked Cloudbreak will start to create the cluster's resources on \n your AWS account.\n\n\n\n\nCloudbreak uses \nCloudFormation\n to create the resources - you can check out the resources created by Cloudbreak on \nthe AWS Console CloudFormation page.\n\n\n\nFull size \nhere\n.\n\n\nBesides these you can check the progress on the Cloudbreak Web UI itself if you open the new cluster's \nEvent History\n.\n\n\n\nFull size \nhere\n.\n\n\nAdvanced Options\n\n\nThere are some advanced features when deploying a new cluster, these are the following:\n\n\nAmbari Username\n This user will be used as admin user in Ambari. You can log in using this username on the Ambari UI.\n\n\nAmbari Password\n The password associated with the Ambari username. This password will be also the default password for all required passwords which are not specified in the blueprint. E.g: hive DB password.\n\n\nAvailability Zone\n You can restrict the instances to a \nspecific availability zone\n. It may be useful if you're using\n reserved instances.\n\n\nUse dedicated instances\n You can use \ndedicated instances\n on EC2\n\n\nMinimum cluster size\n The provisioning strategy in case the cloud provider cannot allocate all the requested nodes.\n\n\nValidate blueprint\n This is selected by default. Cloudbreak validates the Ambari blueprint in this case.\n\n\nCustom Image\n If you enable this, you can override the default image for provision.\n\n\nConfig recommendation strategy\n Strategy for how configuration recommendations will be applied. Recommended \nconfigurations gathered by the response of the stack advisor. \n\n\n\n\nNEVER_APPLY\n               Configuration recommendations are ignored with this option.\n\n\nONLY_STACK_DEFAULTS_APPLY\n Applies only on the default configurations for all included services.\n\n\nALWAYS_APPLY\n              Applies on all configuration properties.\n\n\n\n\nInstance Profile\n Cluster will be able to communicate with AWS api without any configuration.\n\n\n\n\nDisable Instance Profile attaching by default\n                       Cluster will not be able to communicate with AWS api.\n\n\nCreate Instance Profile and attach to the instances\n                 The Cloudformation template will create a new role and assign to every instance.\n\n\nDefine Existing Instance Profile and attach to the instances\n        Cluster will use the predefined instance role. You should define the role ARN in the \nRole for Instance Profile\n box.\n\n\n\n\nHostgroup Configuration\n During the hostgroup config we support different security groups per hostgroup.\n\n\nConfigure Ambari Database\n In case you have an existing DB (like RDS) you can reuse it\n\n\nCluster Termination\n\n\nYou can terminate running or stopped clusters with the \nterminate\n button in the cluster details.\n\n\n\n\nIMPORTANT:\n Always use Cloudbreak to terminate the cluster. If that fails for some reason, try to delete the \nCloudFormation stack first. Instances are started in an Auto Scaling Group so they may be restarted if you terminate an instance manually!\n\n\n\n\nSometimes Cloudbreak cannot synchronize its state with the cluster state at the cloud provider and the cluster can't\n be terminated. In this case the \nForced termination\n option can help to terminate the cluster at the Cloudbreak \n side. \nIf it has happened:\n\n\n\n\nYou should check the related resources at the AWS CloudFormation\n\n\nIf it is needed you need to manually remove resources from there\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nInteractive mode / Cloudbreak Shell\n\n\nThe goal with the Cloudbreak Shell (Cloudbreak CLI) was to provide an interactive command line tool which supports:\n\n\n\n\nall functionality available through the REST API or Cloudbreak Web UI\n\n\nmakes possible complete automation of management task via scripts\n\n\ncontext aware command availability\n\n\ntab completion\n\n\nrequired/optional parameter support\n\n\nhint command to guide you on the usual path\n\n\n\n\nStart Cloudbreak Shell\n\n\nTo start the Cloudbreak CLI use the following commands:\n\n\n\n\nOpen your \ncloudbreak-deployment\n directory if it is needed. For example:\n\n\n\n\n   cd cloudbreak-deployment\n\n\n\n\n\n\nStart the \ncbd\n from here if it is needed\n\n\n\n\n   cbd start\n\n\n\n\n\n\nIn the root of your \ncloudbreak-deployment\n folder apply:\n\n\n\n\n   cbd util cloudbreak-shell\n\n\n\n\n\n\nAt the very first time it will take for a while, because of need to download all the necessary docker images.\n\n\n\n\nThis will launch the Cloudbreak shell inside a Docker container then it is ready to use.\n\n\n\nFull size \nhere\n.\n\n\n\n\nIMPORTANT You have to copy all your files into the \ncbd\n working directory, what you would like to use in shell.\n For \nexample if your \ncbd\n working directory is \n~/cloudbreak-deployment\n then copy your \nblueprint JSON, public ssh key \nfile...etc.\n to here. You can refer to these files with their names from the shell.\n\n\n\n\nAutocomplete and Hints\n\n\nCloudbreak Shell helps you with \nhint messages\n from the very beginning, for example:\n\n\ncloudbreak-shell\nhint\nHint: Add a blueprint with the 'blueprint create' command or select an existing one with 'blueprint select'\ncloudbreak-shell\n\n\n\n\n\nBeyond this you can use the \nautocompletion (double-TAB)\n as well:\n\n\ncloudbreak-shell\ncredential create --\ncredential create --AWS          credential create --AZURE        credential create --EC2          credential create --GCP          credential create --OPENSTACK\n\n\n\n\nCluster Provisioning via CLI\n\n\nSetting up AWS Credential\n\n\nCloudbreak works by connecting your AWS account through so called Credentials, and then uses these credentials to \ncreate resources on your behalf. Credentials can be configured with the following command for example:\n\n\ncredential create --AWS --name my-aws-credential --description \nsample description\n --roleArn \narn:aws:iam::***********:role/userrole --sshKeyString \nssh-rsa AAAAB****etc\n\n\n\n\n\n\n\nNOTE:\n  Cloudbreak \ndoes not set your cloud user details\n - we work around the concept of \nIAM\n - \non Amazon (or other cloud providers)\n. You should have already a valid IAM role. You can \nfind further details \nhere\n.\n\n\n\n\nAlternatives to provide \nSSH Key\n:\n\n\n\n\nyou can upload your public key from an url: \n\u2014sshKeyUrl\n \n\n\nor you can add the path of your public key: \n\u2014sshKeyPath\n\n\n\n\nYou can check whether the credential was created successfully\n\n\ncredential list\n\n\n\n\nYou can switch between your existing credentials\n\n\ncredential select --name my-aws-credential\n\n\n\n\nInfrastructure Templates\n\n\nAfter your AWS account is linked to Cloudbreak you can start creating resource templates that describe your clusters' infrastructure:\n\n\n\n\nsecurity groups\n\n\nnetworks\n\n\ntemplates\n\n\n\n\nWhen you create one of the above resources, \nCloudbreak does not make any requests to AWS. Resources are only created\n on AWS after the \ncluster create\n has applied.\n These templates are saved to Cloudbreak's database and can be \n reused with multiple clusters to describe the infrastructure.\n\n\nTemplates\n\n\nTemplates describe the \ninstances of your cluster\n - the instance type and the attached volumes. A typical setup is\n to combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple\n large disks to the datanodes or have memory optimized instances for Spark nodes.\n\n\nA template can be used repeatedly to create identical copies of the same stack (or to use as a foundation to start a \nnew stack). Templates can be configured with the following command for example:\n\n\ntemplate create --AWS --name my-aws-template --description \nsample description\n --instanceType m4.large --volumeSize \n100 --volumeCount 2\n\n\n\n\nOther available option here is \n--publicInAccount\n. If it is true, all the users belonging to your account will be able\n to use this template to create clusters, but cannot delete it.\n\n\nYou can check whether the template was created successfully\n\n\ntemplate list\n\n\n\n\nNetworks\n\n\nYour clusters can be created in their own \nVirtual Private Cloud (VPC)\n or in one of your already existing VPCs. If \nyou choose an existing VPC it is possible to create a new subnet within the VPC or use an already existing one. The \nsubnet's IP range must be defined in the \nSubnet (CIDR)\n field using the general CIDR notation.\n\n\nDefault AWS Network\n\n\nIf you don't want to create or use your custom VPC, you can use the \ndefault-aws-network\n for all your Cloudbreak \nclusters. It will create a new VPC with a \n10.0.0.0/16\n subnet every time a cluster is created.\n\n\nCustom AWS Network\n\n\nIf you'd like to deploy a cluster to a custom VPC you'll have to \ncreate a new network\n template, to create a new \nsubnet within the VPC, provide the ID of the subnet which is in the existing VPC.\n\n\nA network also can be used repeatedly to create identical copies of the same stack (or to use as a foundation to \nstart a new stack).\n\n\n\n\nIMPORTANT\n The subnet CIDR cannot overlap each other in a VPC. So you have to create different network templates \nfor every each clusters.\nFor example you can create 3 different clusters with 3 different network templates for multiple subnets 10.0.0.0/24,\n 10.0.1.0/24, 10.0.2.0/24 with the same VPC and IGW identifiers.\n\n\n\n\nnetwork create --AWS --name my-aws-network --subnet 10.0.0.0/16\n\n\n\n\nOther available options:\n\n\n--vpcID\n your existing vpc on amazon\n\n\n--internetGatewayID\n your amazon internet gateway of the given VPC\n\n\n--publicInAccount\n If it is true, all the users belonging to your account will be able to use this network to create \nclusters, but cannot delete it.\n\n\nYou can check whether the network was created successfully\n\n\nnetwork list\n\n\n\n\nDefining Cluster Services\n\n\nBlueprints\n\n\nBlueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are \nused by Ambari\n.\n\n\nYou can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file or URL (an \nexample blueprint\n).\n\n\nThe host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.\n\n\n\n\nNOTE:\n It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will fill that with a default value.\n\n\n\n\nblueprint create --name my-blueprint --description \nsample description\n --file \nthe path of the blueprint\n\n\n\n\n\nOther available options:\n\n\n--url\n the url of the blueprint\n\n\n--publicInAccount\n If it is true, all the users belonging to your account will be able to use this blueprint to create \nclusters, but cannot delete it.\n\n\nYou can check whether the blueprint was created successfully\n\n\nblueprint list\n\n\n\n\nA blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications.\n\nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations..etc. that won't be applicable to the Cloudbreak cluster.\n\n\nMetadata Show\n\n\nYou can check the stack metadata with\n\n\nstack metadata --name myawsstack --instancegroup master\n\n\n\n\nOther available options:\n\n\n--id\n In this case you can select a stack with id.\n\n\n--outputType\n In this case you can modify the outputformat of the command (RAW or JSON). \n\n\nCluster Deployment\n\n\nAfter all the cluster resources are configured you can deploy a new HDP cluster. The following sub-sections show you a \nbasic flow for cluster creation with Cloudbreak Shell\n.\n\n\nSelect Credential\n\n\nSelect one of your previously created AWS credential:\n\n\ncredential select --name my-aws-credential\n\n\n\n\nSelect Blueprint\n\n\nSelect one of your previously created blueprint which fits your needs:\n\n\nblueprint select --name multi-node-hdfs-yarn\n\n\n\n\nConfigure Instance Groups\n\n\nYou must configure instance groups before provisioning. An instance group define a group of nodes with a specified \ntemplate. Usually we create instance groups for host groups in the blueprint. For Ambari server only 1 host group can be specified.\nIf you want to install the Ambari server to a separate node, you need to extend your blueprint with a new host group\nwhich contains only 1 service: HDFS_CLIENT and select this host group for the Ambari server. Note: this host group cannot be scaled so \nit is not advised to select a 'slave' host group for this purpose.\n\n\ninstancegroup configure --instanceGroup master --nodecount 1 --templateName minviable-aws --securityGroupName all-services-port --ambariServer true\ninstancegroup configure --instanceGroup slave_1 --nodecount 1 --templateName minviable-aws --securityGroupName all-services-port --ambariServer false\n\n\n\n\nOther available option:\n\n\n--templateId\n Id of the template\n\n\nSelect Network\n\n\nSelect one of your previously created network which fits your needs or a default one:\n\n\nnetwork select --name default-aws-network\n\n\n\n\nCreate Stack / Create Cloud Infrastructure\n\n\nStack means the running cloud infrastructure that is created based on the instance groups configured earlier \n(\ncredential\n, \ninstancegroups\n, \nnetwork\n, \nsecuritygroup\n). Same as in case of the API or UI the new cluster will \nuse your templates and by using CloudFormation will launch your cloud stack. Use the following command to create a \nstack to be used with your Hadoop cluster:\n\n\nstack create --AWS --name myawsstack --region us-east-1\n\n\n\n\nThe infrastructure is created asynchronously, the state of the stack can be checked with the stack \nshow command\n. If \nit reports AVAILABLE, it means that the virtual machines and the corresponding infrastructure is running at the cloud provider.\n\n\nOther available option is:\n\n\n--wait\n - in this case the create command will return only after the process has finished. \n\n--instanceProfileStrategy\n - strategy for seamless S3 connection. (CREATE, USE_EXISTING)\n\n--instanceProfile\n - If you selected 'USE_EXISTING' strategy then you should define the Instance Profile role which will be assigned to instances.\n\n\nCreate a Hadoop Cluster / Cloud Provisioning\n\n\nYou are almost done! One more command and your Hadoop cluster is starting!\n Cloud provisioning is done once the \ncluster is up and running. The new cluster will use your selected blueprint and install your custom Hadoop cluster \nwith the selected components and services.\n\n\ncluster create --description \nmy first cluster\n\n\n\n\n\nOther available option is \n--wait\n - in this case the create command will return only after the process has finished. \n\n\nYou are done!\n You have several opportunities to check the progress during the infrastructure creation then \nprovisioning:\n\n\n\n\nCloudbreak uses \nCloudFormation\n to create the resources - you can check out the resources created by Cloudbreak on\n the AWS Console CloudFormation page.\n\n\n\n\nFor example:\n\n\n\nFull size \nhere\n.\n\n\n\n\nIf stack then cluster creation have successfully done, you can check the Ambari Web UI. However you need to know the \nAmbari IP (for example: \nhttp://52.8.110.95:8080\n): \n\n\nYou can get the IP from the CLI as a result (\nambariServerIp 52.8.110.95\n) of the following command:\n\n\n\n\n\n\n\n\n         cluster show\n\n\n\n\nFor example:\n\n\n\nFull size \nhere\n.\n\n\n\n\nBesides these you can check the entire progress and the Ambari IP as well on the Cloudbreak Web UI itself. Open the \nnew cluster's \ndetails\n and its \nEvent History\n here.\n\n\n\n\nFor example:\n\n\n\nFull size \nhere\n.\n\n\nStop Cluster\n\n\nYou have the ability to \nstop your existing stack then its cluster\n if you want to suspend the work on it.\n\n\nSelect a stack for example with its name:\n\n\nstack select --name my-stack\n\n\n\n\nOther available option to define a stack is its \n--id\n.\n\n\nEvery time you should stop the \ncluster\n first then the \nstack\n. So apply following commands to stop the previously \nselected stack:\n\n\ncluster stop\nstack stop\n\n\n\n\nRestart Cluster\n\n\nSelect your stack that you would like to restart\n after this you can apply:\n\n\nstack start\n\n\n\n\nAfter the stack has successfully restarted, you can \nrestart the related cluster as well\n:\n\n\ncluster start\n\n\n\n\nUpscale Cluster\n\n\nIf you need more instances to your infrastructure, you can \nupscale your selected stack\n:\n\n\nstack node --ADD --instanceGroup host_group_slave_1 --adjustment 6\n\n\n\n\nOther available option is \n--withClusterUpScale\n - this indicates also a cluster upscale after the stack upscale. You\n can upscale the related cluster separately if you want to do this:\n\n\ncluster node --ADD --hostgroup host_group_slave_1 --adjustment 6\n\n\n\n\nDownscale Cluster\n\n\nYou also can reduce the number of instances in your infrastructure. \nAfter you selected your stack\n:\n\n\ncluster node --REMOVE  --hostgroup host_group_slave_1 --adjustment -2\n\n\n\n\nOther available option is \n--withStackDownScale\n - this indicates also a stack downscale after the cluster downscale.\n You can downscale the related stack separately if you want to do this:\n\n\nstack node --REMOVE  --instanceGroup host_group_slave_1 --adjustment -2\n\n\n\n\nCluster Termination\n\n\nYou can terminate running or stopped clusters with\n\n\nstack delete --name myawsstack\n\n\n\n\nOther available option is \n--wait\n - in this case the terminate command will return only after the process has finished. \n\n\n\n\nIMPORTANT:\n Always use Cloudbreak to terminate the cluster. If that fails for some reason, try to delete the \nCloudFormation stack first. Instances are started in an Auto Scaling Group so they may be restarted if you terminate an instance manually!\n\n\n\n\nSometimes Cloudbreak cannot synchronize its state with the cluster state at the cloud provider and the cluster can't\n be terminated. In this case the \nForced termination\n option on the Cloudbreak Web UI can help to terminate the cluster\n  at the Cloudbreak side. \nIf it has happened:\n\n\n\n\nYou should check the related resources at the AWS CloudFormation\n\n\nIf it is needed you need to manually remove resources from there\n\n\n\n\nSilent Mode\n\n\nWith Cloudbreak Shell you can execute script files as well. A script file contains shell commands and can \nbe executed with the \nscript\n cloudbreak shell command\n\n\nscript \nyour script file\n\n\n\n\n\nor with the \ncbd util cloudbreak-shell-quiet\n command\n\n\ncbd util cloudbreak-shell-quiet \n example.sh\n\n\n\n\n\n\nIMPORTANT:\n You have to copy all your files into the \ncbd\n working directory, what you would like to use in shell.\n For example if your \ncbd\n working directory is ~/cloudbreak-deployment then copy your script file to here.\n\n\n\n\nExample\n\n\nThe following example creates a Hadoop cluster with \nhdp-small-default\n blueprint on M4Xlarge instances with 2X100G \nattached disks on \ndefault-aws-network\n network using \nall-services-port\n security group. You should copy your ssh \npublic key file into your \ncbd\n working directory with name \nid_rsa.pub\n and paste your AWS credentials in the parts with \n...\n highlight.\n\n\ncredential create --AWS --description description --name my-aws-credential --roleArn \narn role\n --sshKeyPath id_rsa.pub\ncredential select --name my-aws-credential\ntemplate create --AWS --name awstemplate --description aws-template --instanceType m4.xlarge --volumeSize 100 \n--volumeCount 2\nblueprint select --name hdp-small-default\ninstancegroup configure --instanceGroup host_group_master_1 --nodecount 1 --templateName awstemplate --securityGroupName all-services-port --ambariServer true\ninstancegroup configure --instanceGroup host_group_master_2 --nodecount 1 --templateName awstemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_master_3 --nodecount 1 --templateName awstemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_client_1  --nodecount 1 --templateName awstemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_slave_1 --nodecount 3 --templateName awstemplate --securityGroupName all-services-port --ambariServer false\nnetwork select --name default-aws-network\nstack create --AWS --name my-first-stack --region us-east-1 --wait true\ncluster create --description \nMy first cluster\n --wait true\n\n\n\n\nCongratulations!\n Your cluster should now be up and running on this way as well. To learn more about Cloudbreak and \nprovisioning, we have some \ninteresting insights\n for you.", 
            "title": "AWS"
        }, 
        {
            "location": "/aws/#aws-images", 
            "text": "We have pre-built Cloudbreak Deployer cloud images for AWS with the Cloudbreak Deployer pre-installed. Go to your  AWS Management Console  to launch the latest Cloudbreak Deployer image in your region.     As an alternative to using the pre-built cloud images for AWS, you can install Cloudbreak Deployer on your own VM. For more information, see the  installation instructions .", 
            "title": "AWS Images"
        }, 
        {
            "location": "/aws/#prerequisites", 
            "text": "", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/aws/#ports", 
            "text": "Make sure that you have opened the following ports on your  security group :   SSH (22)  Cloudbreak (443)", 
            "title": "Ports"
        }, 
        {
            "location": "/aws/#cloudbreak-deployer-aws-image-details", 
            "text": "", 
            "title": "Cloudbreak Deployer AWS Image Details"
        }, 
        {
            "location": "/aws/#vm-requirements", 
            "text": "When selecting an instance type, consider these minimum and recomended requirements:     8GB RAM, 10GB disk, 2 cores.   The minimum instance type which is suitable for Cloudbreak is  m3.large .   To learn about all requirements, see  System Requirements .", 
            "title": "VM Requirements"
        }, 
        {
            "location": "/aws/#cloudbreak-deployer-setup-on-aws", 
            "text": "Before getting started with Cloudbreak Deployer, you should know that:   The default SSH username for the EC2 instances is  cloudbreak .  Cloudbreak Deployer location on your EC2 instance is  /var/lib/cloudbreak-deployment . This is the\n   cbd  root folder.  You must execute all  cbd  actions from the  cbd  root folder as a  cloudbreak  user.   In the previous step, you should have already set up a VM with Cloudbreak Doployer either  using the AWS Cloud Images  or by  installing the\nCloudbreak Deployer  manually on your own VM.  Now you need to  connect to the previously created  cbd  VM .", 
            "title": "Cloudbreak Deployer Setup on AWS"
        }, 
        {
            "location": "/aws/#cloudbreak-deployment-directory", 
            "text": "To navigate to the  cloudbreak-deployment  directory, run:  cd /var/lib/cloudbreak-deployment/  This directory contains configuration files and the supporting binaries for Cloudbreak Deployer.", 
            "title": "Cloudbreak Deployment Directory"
        }, 
        {
            "location": "/aws/#initialize-your-profile", 
            "text": "First, initialize deployer by creating a  Profile  file with the following content:  export UAA_DEFAULT_SECRET='[SECRET]'\nexport UAA_DEFAULT_USER_PW='[PASSWORD]'  By default the  cbd  tool tries to guess  PUBLIC_IP  to bind Cloudbreak UI to it. But if  cbd  cannot get the IP address during the initialization, set the appropriate value also in your  Profile .", 
            "title": "Initialize Your Profile"
        }, 
        {
            "location": "/aws/#start-cloudbreak-deployer", 
            "text": "To start the Cloudbreak application use the following command:  cbd start  This will start all the Docker containers and initialize the application.   The first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.   The  cbd start  command includes the  cbd generate  command which applies the following steps:   Creates the  docker-compose.yml  file that describes the configuration of all the Docker containers needed for the Cloudbreak deployment.  Creates the  uaa.yml  file that holds the configuration of the identity server used to authenticate users to Cloudbreak.", 
            "title": "Start Cloudbreak Deployer"
        }, 
        {
            "location": "/aws/#validate-that-cloudbreak-deployer-has-started", 
            "text": "After the  cbd start  command finishes, check the following:    Pre-installed Cloudbreak Deployer version and health:\n    cbd doctor   If you need to run  cbd update , refer to  Cloudbreak Deployer Update .     Cloudbreak Application logs:\n    cbd logs cloudbreak \n  You should see a message like this in the log:  Started CloudbreakApplication in 36.823 seconds . Cloudbreak normally takes less than a minute to start.", 
            "title": "Validate that Cloudbreak Deployer Has Started"
        }, 
        {
            "location": "/aws/#configure-role-based-credentials", 
            "text": "There are two ways to create AWS credentials in Cloudbreak:  Key-based:  This requires your AWS access key and secret key pair. Cloudbreak will use these keys to launch the resources. For starters, this is a simpler option that does not require additional configuration. You will provide the keys later when you  provision an HDP cluster .  Role-based:  This requires a valid  IAM role  with \"AssumeRole\" policy. Cloudbreak will assume this role to get temporary access and the access/secret key pair.  To configure role-based credentials, start your instance with an \"AssumeRole\" policy. For more information, see  Using Instance Profiles  and  Using an IAM Role to Grant Permissions to Applications Running on Amazon EC2 Instances .  Alternatively, you can set your AWS keys of an IAM user with an\"AssumeRole\" policy in the  Profile  file:  export AWS_ACCESS_KEY_ID=AKIA**************W7SA\nexport AWS_SECRET_ACCESS_KEY=RWCT4Cs8******************/*skiOkWD   If you want to use instance profile, do not set these variables. If you want to use Cloudbreak with Role ARNs instead of keys, make sure that the instance profile role can assume roles on AWS.", 
            "title": "Configure Role-based Credentials"
        }, 
        {
            "location": "/aws/#optional-configurations", 
            "text": "You can perform the following optional configurations:", 
            "title": "Optional Configurations"
        }, 
        {
            "location": "/aws/#set-custom-tags", 
            "text": "In order to differentiate launched instances, we give you the option to use custom tags on your AWS resources deployed by Cloudbreak. You can use the tagging mechanism with the following variables.   If you want just one custom tag on your Cloudformation resources, set this variable :  export CB_AWS_DEFAULT_CF_TAG=whatever  Then the name of the tag will be  CloudbreakId  and the value will be  whatever .  If you need more specific tagging, set this variable:  export CB_AWS_CUSTOM_CF_TAGS=myveryspecifictag:veryspecific  Then the name of the tag will be  myveryspecifictag  and the value will be  veryspecific . You can specify a list of tags here with a comma separated list; for example:  tag1:value1,tag2:value2,tag3:value3 .", 
            "title": "Set Custom Tags"
        }, 
        {
            "location": "/aws/#cluster-provisioning-prerequisites", 
            "text": "", 
            "title": "Cluster Provisioning Prerequisites"
        }, 
        {
            "location": "/aws/#iam-role-setup", 
            "text": "If you want to use your Aws Access Key and your Secret Access Key to authenticate to Amazon then please use the  Key based authentication  and you do not need to setup an IAM Role.   Cloudbreak works by connecting your AWS account through so called  Credentials , and then uses these credentials to \ncreate resources on your behalf.   IMPORTANT  Cloudbreak deployment uses two different AWS accounts for two different purposes:    The account belonging to the  Cloudbreak webapp  itself, acts as a  third party , that creates resources on the \naccount of the  end user . This account is configured at server-deployment time.  The account belonging to the  end user  who uses the UI or the Shell to create clusters. This account is configured\n when setting up credentials.   These accounts are usually  the same  when the end user is the same who deployed the Cloudbreak server, but it allows\n Cloudbreak to act as a SaaS project as well if needed.  Credentials use  IAM Roles  to give access to the \nthird party to act on behalf of the end user without giving full access to your resources.\nThis IAM Role will be  assumed  later by an IAM user.  AWS IAM Policy that grants permission to assume a role  You cannot assume a role with root account , so you need to  create an IAM user  with an attached  Inline  \npolicy  and  then set the \nAccess key and Secret Access key  in the  Profile  file (check  this description  out).  The  sts-assume-role  IAM user  policy  must be configured to have \npermission to assume roles on all resources. Here it is the policy to configure the  sts:AssumeRole  for all  Resource :  {\n\u2002\u2002 Version :  2012-10-17 ,\n\u2002\u2002 Statement : [\n\u2002\u2002\u2002\u2002{\n\u2002\u2002\u2002\u2002\u2002\u2002 Sid :  Stmt1400068149000 ,\n\u2002\u2002\u2002\u2002\u2002\u2002 Effect :  Allow ,\n\u2002\u2002\u2002\u2002\u2002\u2002 Action : [\n\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002 sts:AssumeRole \n\u2002\u2002\u2002\u2002\u2002\u2002],\n\u2002\u2002\u2002\u2002\u2002\u2002 Resource : [\n\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002 * \n\u2002\u2002\u2002\u2002\u2002\u2002]\n\u2002\u2002\u2002\u2002}\n\u2002\u2002]\n}  To connect your ( end user ) AWS account with a credential in Cloudbreak you'll have to create an IAM role on your \nAWS account that is configured to allow the third-party account to access and create resources on your behalf.\nThe easiest way to do this is with  cbd  commands (but it can also be done manually from the  AWS Console ):  cbd aws generate-role  - Generates an AWS IAM role for Cloudbreak provisioning on AWS\ncbd aws show-role      - Show assumers and policies for an AWS role\ncbd aws delete-role    - Deletes an AWS IAM role, removes all inline policies  The  generate-role  command creates a role that is assumable by the Cloudbreak Deployer AWS account and has a broad policy setup.\nThis command creates a role with the name  cbreak-deployer  by default. If you'd like to create role with a different\n name or multiple roles, you need to add this line to your  Profile :  export AWS_ROLE_NAME=my-cloudbreak-role  You can check the generated role on your AWS console, under IAM roles:  Full size  here .", 
            "title": "IAM Role Setup"
        }, 
        {
            "location": "/aws/#generate-a-new-ssh-key", 
            "text": "All the instances created by Cloudbreak are configured to allow key-based SSH,\nso you'll need to provide an SSH public key that can be used later to SSH onto the instances in the clusters you'll create with Cloudbreak.\nYou can use one of your existing keys or you can generate a new one.  To generate a new SSH keypair:  ssh-keygen -t rsa -b 4096 -C  your_email@example.com \n# Creates a new ssh key, using the provided email as a label\n# Generating public/private rsa key pair.  # Enter file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]\nYou'll be asked to enter a passphrase, but you can leave it empty.\n\n# Enter passphrase (empty for no passphrase): [Type a passphrase]\n# Enter same passphrase again: [Type passphrase again]  After you enter a passphrase the keypair is generated. The output should look something like below.   # Your identification has been saved in /Users/you/.ssh/id_rsa.\n# Your public key has been saved in /Users/you/.ssh/id_rsa.pub.\n# The key fingerprint is:\n# 01:0f:f4:3b:ca:85:sd:17:sd:7d:sd:68:9d:sd:a2:sd your_email@example.com  Later you'll need to pass the  .pub  file's contents to Cloudbreak and use the private part to SSH to the instances", 
            "title": "Generate a New SSH Key"
        }, 
        {
            "location": "/aws/#cluster-provisioning-via-browser", 
            "text": "You can log into the Cloudbreak application at  https:// Public_IP / .  The main goal of the Cloudbreak UI is to easily create clusters on your own cloud provider account.\nThis description details the AWS setup - if you'd like to use a different cloud provider check out its manual.  This document explains the four steps that need to be followed to create Cloudbreak clusters from the UI:   connect your AWS account with Cloudbreak  create some template resources on the UI that describe the infrastructure of your clusters  create a blueprint that describes the HDP services in your clusters  launch the cluster itself based on these resources    IMPORTANT  Make sure that you have sufficient qouta (CPU, network, etc) for the requested cluster size", 
            "title": "Cluster Provisioning via Browser"
        }, 
        {
            "location": "/aws/#setting-up-aws-credentials", 
            "text": "Cloudbreak works by connecting your AWS account through so called  Credentials , and then uses these credentials to \ncreate resources on your behalf. The credentials can be configured on the  manage credentials  panel on the \nCloudbreak Dashboard.  To create a new AWS credential follow these steps:   Select the credential type. For instance, select the  Role Based  Fill out the new credential  Name  Only alphanumeric and lowercase characters (min 5, max 100 characters) can be applied    Copy your AWS IAM role's Amazon Resource Name (ARN) to the  IAM Role ARN  field  Copy your SSH public key to the  SSH public key  field  The SSH public key must be in OpenSSH format and it's private keypair can be used later to  SSH onto every \ninstance  of every cluster you'll create with this credential.  The  SSH username  for the EC2 instances is  cloudbreak .      Any other parameter is optional here.  Public in account  means that all the users belonging to your account will be able to use this credential to create \nclusters, but cannot delete it.    Full size  here .", 
            "title": "Setting up AWS Credentials"
        }, 
        {
            "location": "/aws/#infrastructure-templates", 
            "text": "After your AWS account is linked to Cloudbreak you can start creating resource templates that describe your clusters' infrastructure:   templates  networks  security groups   When you create one of the above resources,  Cloudbreak does not make any requests to AWS. Resources are only created\n on AWS after the  create cluster  button has pushed.  These templates are saved to Cloudbreak's database and can be \n reused with multiple clusters to describe the infrastructure.", 
            "title": "Infrastructure Templates"
        }, 
        {
            "location": "/aws/#templates", 
            "text": "Templates describe the  instances of your cluster  - the instance type and the attached volumes. A typical setup is\n to combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple\n large disks to the datanodes or have memory optimized instances for Spark nodes.  The instance templates can be configured on the  manage templates  panel on the Cloudbreak Dashboard.  There are some optional configurations here as well:   Spot price (USD)  If specified Cloudbreak will request spot price instances (which might take a while or never be \nfulfilled by Amazon).  This option is  not supported  by the default RedHat images .  EBS encryption  is supported for all volume types. If this option is checked then all the attached disks  will be encrypted  by Amazon using the AWS KMS master keys.  If  Public in account  is checked all the users belonging to your account will be able to use this resource to create clusters, but cannot delete it.", 
            "title": "Templates"
        }, 
        {
            "location": "/aws/#networks", 
            "text": "Your clusters can be created in their own  Virtual Private Cloud (VPC)  or in one of your already existing VPCs.\nIf you choose an existing VPC it is possible to create a new subnet within the VPC or use an already existing one.\nThe subnet's IP range must be defined in the  Subnet (CIDR)  field using the general CIDR notation.  Default AWS Network  If you don't want to create or use your custom VPC, you can use the  default-aws-network  for all your\nCloudbreak clusters. It will create a new VPC with a  10.0.0.0/16  subnet every time a cluster is created.  Custom AWS Network  If you'd like to deploy a cluster to a custom VPC you'll have to  create a new network  template on the  manage\nnetworks  panel.  You have the following options:   Create a new VPC and a new subnet : Every time a cluster is created with this kind of network setup a new VPC and a new subnet with the specified IP range will be created for the instances on AWS.  Create a new subnet in an existing VPC :  Use this kind of network setup if you already have a VPC on AWS where you'd like to put the Cloudbreak created cluster but you'd like to have a separate subnet for it. This setup is only supported for basic VPCs, where an Internet Gateway is configured and instances can have public IP addresses to access the Internet. If you have a specific VPC setup (VGW, NAT, private subnets, etc..) then only the third option can be used.  Use an existing subnet in an existing VPC :  Use this kind of network setup if you have an existing VPC with one or more subnets on AWS and you'd like to start the instances of a cluster in one - or more - of those subnets. Use this setup if you have a specific VPC setup: you should first create the subnet(s) directly through AWS and provide their IDs here. The subnets could be even in different availability zones and you can set a single or a comma separated list of subnets in the 'Subnet Identifier' field. There are only two requirements for the subnets:  instances in the subnet should be able to reach the Internet to download yum packages (it can be done through a Virtual Gateway, a NAT instance, an Internet Gateway or any other setup)  the VM where Cloudbreak is deployed must be able to reach the instances in the cluster on port 443. (It\u2019s in the same subnet, or through a router from another subnet)  NOTE : instances in the subnet doesn't need to have public IP addresses in this case     You can configure the  Subnet Identifier  and the  Internet Gateway Identifier  (IGW) of your VPC.   IMPORTANT:  The subnet CIDR cannot overlap each other in a VPC. So you have to create different network\ntemplates for every each clusters.   To create a new subnet within the VPC, provide the ID of the subnet which is in the existing VPC and your cluster\nwill be launched into that subnet.  For example  you can create 3 different clusters with 3 different network\ntemplates for multiple subnets  10.0.0.0/24 ,  10.0.1.0/24 ,  10.0.2.0/24  with the same VPC and IGW identifiers.   IMPORTANT:  Make sure the define subnet here doesn't overlap with any of your already deployed subnet in\nthe VPC, because the validation only happens after the cluster creation starts.  In case of existing subnet make sure you have enough room within your network space for the new instances.   If  Public in account  is checked all the users belonging to your account will be able to use this network template\nto create clusters, but cannot delete it.   NOTE:  The VPCs, IGWs and subnet are created on AWS only after the the cluster provisioning starts with the selected\nnetwork template.    Full size  here .", 
            "title": "Networks"
        }, 
        {
            "location": "/aws/#security-groups", 
            "text": "Security group templates are very similar to the  security groups on the AWS Console . They describe the allowed inbound traffic to the instances in the cluster. \nCurrently only one security group template can be selected for a Cloudbreak cluster and all the instances have a \npublic IP address so all the instances in the cluster will belong to the same security group.\nThis may change in a later release.  Default Security Group  You can also use the two pre-defined security groups in Cloudbreak.  only-ssh-and-ssl:  all ports are locked down except for SSH and the selected Ambari Server HTTPS (you can't access Hadoop services outside of the VPC):   SSH (22)  HTTPS (443)   Custom Security Group  You can define your own security group by adding all the ports, protocols and CIDR range you'd like to use. The rules\n defined here doesn't need to contain the internal rules, those are automatically added by Cloudbreak to the security group on AWS.  Hadoop services :  Ambari (8080)  Consul (8500)  NN (50070)  RM Web (8088)  Scheduler (8030RM)  IPC (8050RM)  Job history server (19888)  HBase master (60000)  HBase master web (60010)  HBase RS (16020)  HBase RS info (60030)  Falcon (15000)  Storm (8744)  Hive metastore (9083)  Hive server (10000)  Hive server HTTP (10001)  Accumulo master (9999)  Accumulo Tserver (9997)  Atlas (21000)  KNOX (8443)  Oozie (11000)  Spark HS (18080)  NM Web (8042)  Zeppelin WebSocket (9996)  Zeppelin UI (9995)  Kibana (3080)\n* Elasticsearch (9200)   IMPORTANT  443, 9443, and 22 ports needs to be there in every security group otherwise Cloudbreak won't be able to communicate with the provisioned cluster.   Use existing security group  Use this kind of security group if you have an existing security group and you'd like to apply same rules to each host group in a cluster.  If  Public in account  is checked all the users belonging to your account will be able to use this security group \ntemplate to create clusters, but cannot delete it.   NOTE:  The security groups are created on AWS only after the cluster provisioning starts with the selected security group template.    Full size  here .", 
            "title": "Security groups"
        }, 
        {
            "location": "/aws/#defining-cluster-services", 
            "text": "", 
            "title": "Defining Cluster Services"
        }, 
        {
            "location": "/aws/#blueprints", 
            "text": "Blueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are  used by Ambari .  You can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file, URL (an  example blueprint ) or the \nwhole JSON can be written in the  JSON text  box.  The host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.   NOTE:  It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will \nfill that with a default value.   If  Public in account  is checked all the users belonging to your account will be able to use this blueprint to \ncreate clusters, but cannot delete or modify it.   Full size  here .  A blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications. \nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations...etc. that won't be applicable to the Cloudbreak cluster", 
            "title": "Blueprints"
        }, 
        {
            "location": "/aws/#cluster-deployment", 
            "text": "After all the cluster resources are configured you can deploy a new HDP cluster.  Here is a  basic flow for cluster creation on Cloudbreak Web UI :   Start by selecting a previously created AWS credential in the header.  Open  create cluster   Configure Cluster  tab   Fill out the new cluster  name  Cluster name must start with a lowercase alphabetic character then you can apply lowercase alphanumeric and \n   hyphens only (min 5, max 40 characters)    Select a  Region  where you like your cluster be provisioned  Click on the  Setup Network and Security  button  If  Public in account  is checked all the users belonging to your account will be able to see the created cluster on\n the UI, but cannot delete or modify it.     Setup Network and Security  tab   Select one of the security groups  Click on the  Choose Blueprint  button  If  Enable security  is checked as well, Cloudbreak will install Key Distribution Center (KDC) and the cluster will \nbe Kerberized. See more about it in the  Kerberos  section of this documentation.     Choose Blueprint  tab   Select one of the blueprint  After you've selected a  Blueprint , you should be able to configure:  the templates  the securitygroups  the number of nodes for all of the host groups in the blueprint    You need to select where you want to install the Ambari server to. Only 1 host group can be selected.\n   If you want to install the Ambari server to a separate node, you need to extend your blueprint with a new host group\n   which contains only 1 service: HDFS_CLIENT and select this host group for the Ambari server. Note: this host group cannot be scaled so \n   it is not advised to select a 'slave' host group for this purpose.  Click on the  Review and Launch  button   Review and Launch  tab   After the  create and start cluster  button has clicked Cloudbreak will start to create the cluster's resources on \n your AWS account.   Cloudbreak uses  CloudFormation  to create the resources - you can check out the resources created by Cloudbreak on \nthe AWS Console CloudFormation page.  Full size  here .  Besides these you can check the progress on the Cloudbreak Web UI itself if you open the new cluster's  Event History .  Full size  here .", 
            "title": "Cluster Deployment"
        }, 
        {
            "location": "/aws/#advanced-options", 
            "text": "There are some advanced features when deploying a new cluster, these are the following:  Ambari Username  This user will be used as admin user in Ambari. You can log in using this username on the Ambari UI.  Ambari Password  The password associated with the Ambari username. This password will be also the default password for all required passwords which are not specified in the blueprint. E.g: hive DB password.  Availability Zone  You can restrict the instances to a  specific availability zone . It may be useful if you're using\n reserved instances.  Use dedicated instances  You can use  dedicated instances  on EC2  Minimum cluster size  The provisioning strategy in case the cloud provider cannot allocate all the requested nodes.  Validate blueprint  This is selected by default. Cloudbreak validates the Ambari blueprint in this case.  Custom Image  If you enable this, you can override the default image for provision.  Config recommendation strategy  Strategy for how configuration recommendations will be applied. Recommended \nconfigurations gathered by the response of the stack advisor.    NEVER_APPLY                Configuration recommendations are ignored with this option.  ONLY_STACK_DEFAULTS_APPLY  Applies only on the default configurations for all included services.  ALWAYS_APPLY               Applies on all configuration properties.   Instance Profile  Cluster will be able to communicate with AWS api without any configuration.   Disable Instance Profile attaching by default                        Cluster will not be able to communicate with AWS api.  Create Instance Profile and attach to the instances                  The Cloudformation template will create a new role and assign to every instance.  Define Existing Instance Profile and attach to the instances         Cluster will use the predefined instance role. You should define the role ARN in the  Role for Instance Profile  box.   Hostgroup Configuration  During the hostgroup config we support different security groups per hostgroup.  Configure Ambari Database  In case you have an existing DB (like RDS) you can reuse it", 
            "title": "Advanced Options"
        }, 
        {
            "location": "/aws/#cluster-termination", 
            "text": "You can terminate running or stopped clusters with the  terminate  button in the cluster details.   IMPORTANT:  Always use Cloudbreak to terminate the cluster. If that fails for some reason, try to delete the \nCloudFormation stack first. Instances are started in an Auto Scaling Group so they may be restarted if you terminate an instance manually!   Sometimes Cloudbreak cannot synchronize its state with the cluster state at the cloud provider and the cluster can't\n be terminated. In this case the  Forced termination  option can help to terminate the cluster at the Cloudbreak \n side.  If it has happened:   You should check the related resources at the AWS CloudFormation  If it is needed you need to manually remove resources from there    Full size  here .", 
            "title": "Cluster Termination"
        }, 
        {
            "location": "/aws/#interactive-mode-cloudbreak-shell", 
            "text": "The goal with the Cloudbreak Shell (Cloudbreak CLI) was to provide an interactive command line tool which supports:   all functionality available through the REST API or Cloudbreak Web UI  makes possible complete automation of management task via scripts  context aware command availability  tab completion  required/optional parameter support  hint command to guide you on the usual path", 
            "title": "Interactive mode / Cloudbreak Shell"
        }, 
        {
            "location": "/aws/#start-cloudbreak-shell", 
            "text": "To start the Cloudbreak CLI use the following commands:   Open your  cloudbreak-deployment  directory if it is needed. For example:      cd cloudbreak-deployment   Start the  cbd  from here if it is needed      cbd start   In the root of your  cloudbreak-deployment  folder apply:      cbd util cloudbreak-shell   At the very first time it will take for a while, because of need to download all the necessary docker images.   This will launch the Cloudbreak shell inside a Docker container then it is ready to use.  Full size  here .   IMPORTANT You have to copy all your files into the  cbd  working directory, what you would like to use in shell.  For \nexample if your  cbd  working directory is  ~/cloudbreak-deployment  then copy your  blueprint JSON, public ssh key \nfile...etc.  to here. You can refer to these files with their names from the shell.", 
            "title": "Start Cloudbreak Shell"
        }, 
        {
            "location": "/aws/#autocomplete-and-hints", 
            "text": "Cloudbreak Shell helps you with  hint messages  from the very beginning, for example:  cloudbreak-shell hint\nHint: Add a blueprint with the 'blueprint create' command or select an existing one with 'blueprint select'\ncloudbreak-shell   Beyond this you can use the  autocompletion (double-TAB)  as well:  cloudbreak-shell credential create --\ncredential create --AWS          credential create --AZURE        credential create --EC2          credential create --GCP          credential create --OPENSTACK", 
            "title": "Autocomplete and Hints"
        }, 
        {
            "location": "/aws/#cluster-provisioning-via-cli", 
            "text": "", 
            "title": "Cluster Provisioning via CLI"
        }, 
        {
            "location": "/aws/#setting-up-aws-credential", 
            "text": "Cloudbreak works by connecting your AWS account through so called Credentials, and then uses these credentials to \ncreate resources on your behalf. Credentials can be configured with the following command for example:  credential create --AWS --name my-aws-credential --description  sample description  --roleArn \narn:aws:iam::***********:role/userrole --sshKeyString  ssh-rsa AAAAB****etc    NOTE:   Cloudbreak  does not set your cloud user details  - we work around the concept of  IAM  -  on Amazon (or other cloud providers) . You should have already a valid IAM role. You can \nfind further details  here .   Alternatives to provide  SSH Key :   you can upload your public key from an url:  \u2014sshKeyUrl    or you can add the path of your public key:  \u2014sshKeyPath   You can check whether the credential was created successfully  credential list  You can switch between your existing credentials  credential select --name my-aws-credential", 
            "title": "Setting up AWS Credential"
        }, 
        {
            "location": "/aws/#infrastructure-templates_1", 
            "text": "After your AWS account is linked to Cloudbreak you can start creating resource templates that describe your clusters' infrastructure:   security groups  networks  templates   When you create one of the above resources,  Cloudbreak does not make any requests to AWS. Resources are only created\n on AWS after the  cluster create  has applied.  These templates are saved to Cloudbreak's database and can be \n reused with multiple clusters to describe the infrastructure.", 
            "title": "Infrastructure Templates"
        }, 
        {
            "location": "/aws/#templates_1", 
            "text": "Templates describe the  instances of your cluster  - the instance type and the attached volumes. A typical setup is\n to combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple\n large disks to the datanodes or have memory optimized instances for Spark nodes.  A template can be used repeatedly to create identical copies of the same stack (or to use as a foundation to start a \nnew stack). Templates can be configured with the following command for example:  template create --AWS --name my-aws-template --description  sample description  --instanceType m4.large --volumeSize \n100 --volumeCount 2  Other available option here is  --publicInAccount . If it is true, all the users belonging to your account will be able\n to use this template to create clusters, but cannot delete it.  You can check whether the template was created successfully  template list", 
            "title": "Templates"
        }, 
        {
            "location": "/aws/#networks_1", 
            "text": "Your clusters can be created in their own  Virtual Private Cloud (VPC)  or in one of your already existing VPCs. If \nyou choose an existing VPC it is possible to create a new subnet within the VPC or use an already existing one. The \nsubnet's IP range must be defined in the  Subnet (CIDR)  field using the general CIDR notation.  Default AWS Network  If you don't want to create or use your custom VPC, you can use the  default-aws-network  for all your Cloudbreak \nclusters. It will create a new VPC with a  10.0.0.0/16  subnet every time a cluster is created.  Custom AWS Network  If you'd like to deploy a cluster to a custom VPC you'll have to  create a new network  template, to create a new \nsubnet within the VPC, provide the ID of the subnet which is in the existing VPC.  A network also can be used repeatedly to create identical copies of the same stack (or to use as a foundation to \nstart a new stack).   IMPORTANT  The subnet CIDR cannot overlap each other in a VPC. So you have to create different network templates \nfor every each clusters.\nFor example you can create 3 different clusters with 3 different network templates for multiple subnets 10.0.0.0/24,\n 10.0.1.0/24, 10.0.2.0/24 with the same VPC and IGW identifiers.   network create --AWS --name my-aws-network --subnet 10.0.0.0/16  Other available options:  --vpcID  your existing vpc on amazon  --internetGatewayID  your amazon internet gateway of the given VPC  --publicInAccount  If it is true, all the users belonging to your account will be able to use this network to create \nclusters, but cannot delete it.  You can check whether the network was created successfully  network list", 
            "title": "Networks"
        }, 
        {
            "location": "/aws/#defining-cluster-services_1", 
            "text": "", 
            "title": "Defining Cluster Services"
        }, 
        {
            "location": "/aws/#blueprints_1", 
            "text": "Blueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are  used by Ambari .  You can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file or URL (an  example blueprint ).  The host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.   NOTE:  It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will fill that with a default value.   blueprint create --name my-blueprint --description  sample description  --file  the path of the blueprint   Other available options:  --url  the url of the blueprint  --publicInAccount  If it is true, all the users belonging to your account will be able to use this blueprint to create \nclusters, but cannot delete it.  You can check whether the blueprint was created successfully  blueprint list  A blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications. \nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations..etc. that won't be applicable to the Cloudbreak cluster.", 
            "title": "Blueprints"
        }, 
        {
            "location": "/aws/#metadata-show", 
            "text": "You can check the stack metadata with  stack metadata --name myawsstack --instancegroup master  Other available options:  --id  In this case you can select a stack with id.  --outputType  In this case you can modify the outputformat of the command (RAW or JSON).", 
            "title": "Metadata Show"
        }, 
        {
            "location": "/aws/#cluster-deployment_1", 
            "text": "After all the cluster resources are configured you can deploy a new HDP cluster. The following sub-sections show you a  basic flow for cluster creation with Cloudbreak Shell .", 
            "title": "Cluster Deployment"
        }, 
        {
            "location": "/aws/#select-credential", 
            "text": "Select one of your previously created AWS credential:  credential select --name my-aws-credential", 
            "title": "Select Credential"
        }, 
        {
            "location": "/aws/#select-blueprint", 
            "text": "Select one of your previously created blueprint which fits your needs:  blueprint select --name multi-node-hdfs-yarn", 
            "title": "Select Blueprint"
        }, 
        {
            "location": "/aws/#configure-instance-groups", 
            "text": "You must configure instance groups before provisioning. An instance group define a group of nodes with a specified \ntemplate. Usually we create instance groups for host groups in the blueprint. For Ambari server only 1 host group can be specified.\nIf you want to install the Ambari server to a separate node, you need to extend your blueprint with a new host group\nwhich contains only 1 service: HDFS_CLIENT and select this host group for the Ambari server. Note: this host group cannot be scaled so \nit is not advised to select a 'slave' host group for this purpose.  instancegroup configure --instanceGroup master --nodecount 1 --templateName minviable-aws --securityGroupName all-services-port --ambariServer true\ninstancegroup configure --instanceGroup slave_1 --nodecount 1 --templateName minviable-aws --securityGroupName all-services-port --ambariServer false  Other available option:  --templateId  Id of the template", 
            "title": "Configure Instance Groups"
        }, 
        {
            "location": "/aws/#select-network", 
            "text": "Select one of your previously created network which fits your needs or a default one:  network select --name default-aws-network", 
            "title": "Select Network"
        }, 
        {
            "location": "/aws/#create-stack-create-cloud-infrastructure", 
            "text": "Stack means the running cloud infrastructure that is created based on the instance groups configured earlier \n( credential ,  instancegroups ,  network ,  securitygroup ). Same as in case of the API or UI the new cluster will \nuse your templates and by using CloudFormation will launch your cloud stack. Use the following command to create a \nstack to be used with your Hadoop cluster:  stack create --AWS --name myawsstack --region us-east-1  The infrastructure is created asynchronously, the state of the stack can be checked with the stack  show command . If \nit reports AVAILABLE, it means that the virtual machines and the corresponding infrastructure is running at the cloud provider.  Other available option is:  --wait  - in this case the create command will return only after the process has finished.  --instanceProfileStrategy  - strategy for seamless S3 connection. (CREATE, USE_EXISTING) --instanceProfile  - If you selected 'USE_EXISTING' strategy then you should define the Instance Profile role which will be assigned to instances.", 
            "title": "Create Stack / Create Cloud Infrastructure"
        }, 
        {
            "location": "/aws/#create-a-hadoop-cluster-cloud-provisioning", 
            "text": "You are almost done! One more command and your Hadoop cluster is starting!  Cloud provisioning is done once the \ncluster is up and running. The new cluster will use your selected blueprint and install your custom Hadoop cluster \nwith the selected components and services.  cluster create --description  my first cluster   Other available option is  --wait  - in this case the create command will return only after the process has finished.   You are done!  You have several opportunities to check the progress during the infrastructure creation then \nprovisioning:   Cloudbreak uses  CloudFormation  to create the resources - you can check out the resources created by Cloudbreak on\n the AWS Console CloudFormation page.   For example:  Full size  here .   If stack then cluster creation have successfully done, you can check the Ambari Web UI. However you need to know the \nAmbari IP (for example:  http://52.8.110.95:8080 ):   You can get the IP from the CLI as a result ( ambariServerIp 52.8.110.95 ) of the following command:              cluster show  For example:  Full size  here .   Besides these you can check the entire progress and the Ambari IP as well on the Cloudbreak Web UI itself. Open the \nnew cluster's  details  and its  Event History  here.   For example:  Full size  here .", 
            "title": "Create a Hadoop Cluster / Cloud Provisioning"
        }, 
        {
            "location": "/aws/#stop-cluster", 
            "text": "You have the ability to  stop your existing stack then its cluster  if you want to suspend the work on it.  Select a stack for example with its name:  stack select --name my-stack  Other available option to define a stack is its  --id .  Every time you should stop the  cluster  first then the  stack . So apply following commands to stop the previously \nselected stack:  cluster stop\nstack stop", 
            "title": "Stop Cluster"
        }, 
        {
            "location": "/aws/#restart-cluster", 
            "text": "Select your stack that you would like to restart  after this you can apply:  stack start  After the stack has successfully restarted, you can  restart the related cluster as well :  cluster start", 
            "title": "Restart Cluster"
        }, 
        {
            "location": "/aws/#upscale-cluster", 
            "text": "If you need more instances to your infrastructure, you can  upscale your selected stack :  stack node --ADD --instanceGroup host_group_slave_1 --adjustment 6  Other available option is  --withClusterUpScale  - this indicates also a cluster upscale after the stack upscale. You\n can upscale the related cluster separately if you want to do this:  cluster node --ADD --hostgroup host_group_slave_1 --adjustment 6", 
            "title": "Upscale Cluster"
        }, 
        {
            "location": "/aws/#downscale-cluster", 
            "text": "You also can reduce the number of instances in your infrastructure.  After you selected your stack :  cluster node --REMOVE  --hostgroup host_group_slave_1 --adjustment -2  Other available option is  --withStackDownScale  - this indicates also a stack downscale after the cluster downscale.\n You can downscale the related stack separately if you want to do this:  stack node --REMOVE  --instanceGroup host_group_slave_1 --adjustment -2", 
            "title": "Downscale Cluster"
        }, 
        {
            "location": "/aws/#cluster-termination_1", 
            "text": "You can terminate running or stopped clusters with  stack delete --name myawsstack  Other available option is  --wait  - in this case the terminate command will return only after the process has finished.    IMPORTANT:  Always use Cloudbreak to terminate the cluster. If that fails for some reason, try to delete the \nCloudFormation stack first. Instances are started in an Auto Scaling Group so they may be restarted if you terminate an instance manually!   Sometimes Cloudbreak cannot synchronize its state with the cluster state at the cloud provider and the cluster can't\n be terminated. In this case the  Forced termination  option on the Cloudbreak Web UI can help to terminate the cluster\n  at the Cloudbreak side.  If it has happened:   You should check the related resources at the AWS CloudFormation  If it is needed you need to manually remove resources from there", 
            "title": "Cluster Termination"
        }, 
        {
            "location": "/aws/#silent-mode", 
            "text": "With Cloudbreak Shell you can execute script files as well. A script file contains shell commands and can \nbe executed with the  script  cloudbreak shell command  script  your script file   or with the  cbd util cloudbreak-shell-quiet  command  cbd util cloudbreak-shell-quiet   example.sh   IMPORTANT:  You have to copy all your files into the  cbd  working directory, what you would like to use in shell.\n For example if your  cbd  working directory is ~/cloudbreak-deployment then copy your script file to here.", 
            "title": "Silent Mode"
        }, 
        {
            "location": "/aws/#example", 
            "text": "The following example creates a Hadoop cluster with  hdp-small-default  blueprint on M4Xlarge instances with 2X100G \nattached disks on  default-aws-network  network using  all-services-port  security group. You should copy your ssh \npublic key file into your  cbd  working directory with name  id_rsa.pub  and paste your AWS credentials in the parts with  ...  highlight.  credential create --AWS --description description --name my-aws-credential --roleArn  arn role  --sshKeyPath id_rsa.pub\ncredential select --name my-aws-credential\ntemplate create --AWS --name awstemplate --description aws-template --instanceType m4.xlarge --volumeSize 100 \n--volumeCount 2\nblueprint select --name hdp-small-default\ninstancegroup configure --instanceGroup host_group_master_1 --nodecount 1 --templateName awstemplate --securityGroupName all-services-port --ambariServer true\ninstancegroup configure --instanceGroup host_group_master_2 --nodecount 1 --templateName awstemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_master_3 --nodecount 1 --templateName awstemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_client_1  --nodecount 1 --templateName awstemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_slave_1 --nodecount 3 --templateName awstemplate --securityGroupName all-services-port --ambariServer false\nnetwork select --name default-aws-network\nstack create --AWS --name my-first-stack --region us-east-1 --wait true\ncluster create --description  My first cluster  --wait true  Congratulations!  Your cluster should now be up and running on this way as well. To learn more about Cloudbreak and \nprovisioning, we have some  interesting insights  for you.", 
            "title": "Example"
        }, 
        {
            "location": "/azure/", 
            "text": "Azure Setup\n\n\nSetting up Cloudbreak on Azure is different than on other cloud providers for which we provide pre-built public images with Cloudbreak Deployer pre-installed. On Azure, you launch Cloudbreak Deployer using the \nAzure Resource Manager Templates\n.\n\n\nDeploy Using the Azure Portal\n\n\nTo get started with Cloudbreak installation using the Azure Resource Manager template, click here: \n  \n \n\n\nVM Requirements\n\n\nWhen selecting an instance type, consider these minimum and recomended requirements:\n\n- 8GB RAM, 10GB disk, 2 cores \n- The minimum instance type suitable for Cloudbreak is \nD2\n\n\nTo learn about all requirements, see \nSystem Requirements\n.\n\n\nDeployment Details\n\n\nIn addition to the default values, the following parameters are \nmandatory\n for the new \ncbd\n template:\n\n\nOn the \nCustom deployment\n panel:\n\n\n\n\nCreate a new \nResource group\n\n\nSelect an appropriate \nResource group location\n\n\n\n\nOn the \nSettings\n panel:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAdmin Username\n\n\nCreate an admin login that you will use to log in to the Cloudbreak UI. Must be a valid email address.\n\n\n\n\n\n\nAdmin User Password\n\n\nPassword for the admin login. Must be at least 8 characters containing letters, numbers, and symbols.\n\n\n\n\n\n\nUsername\n\n\nEnter an admin username for the virtual machine. You will use it to SSH to the VM.\n\n\n\n\n\n\nSmartsense\n\n\nSelect  whether you want to use SmartSense telemetry.\n\n\n\n\n\n\nRemote Location\n\n\nAllow connections from this address range. Must be a valid CIDR IP.\n\n\n\n\n\n\nSsh key\n\n\nPaste your SSH public key.\nYou can use \npbcopy\n to quickly copy it. For example: \npbcopy \n /Users/homedir/.ssh/id_rsa.pub\n\n\n\n\n\n\n\n\nFinally\n you should review the \nLegal terms\n from the \nCustom deployment\n panel:\n\n\n\n\nTo agree with the terms and conditions, click on \nCreate\n button in this panel\n\n\nAlso click on the \nCreate\n button on the \nCustom deployment\n\n\n\n\n\n\nDeployment takes about \n15-20 minutes\n. You can track the\nprogress on the resource group details. If any issue has occurred, open the \nAudit logs\n from the settings.\nWe have faced an interesting behaviour on the Azure Portal: \nAll operations were successful on template deployment,\nbut overall fail\n.\n\n\n\n\n\n\nOnce it's successful done, you can reach the Cloudbreak UI\nat:\nhttps://\nVM Public IP\n/\n\n\nemail: admin@example.com\n\n\npassword: cloudbreak\n\n\n\n\n\n\n\n\nUnder the Hood\n\n\nWhile Azure is creating the deployment, review this information about what happens in the background:\n\n\n\n\nStart an instance from the official CentOS image\n\n\nSo no custom image copy is needed, which would take about 30\n   minutes\n\n\nUse \nDocker VM Extension\n to install Docker\n\n\nUse \nCustomScript Extension\n to install\nCloudbreak Deployer (\ncbd\n)\n\n\n\n\nCloudbreak Deployer Highlights\n\n\n\n\nThe default SSH username for the Azure VMs is \ncloudbreak\n.\n\n\nCloudbreak Deployer location is \n/var/lib/cloudbreak-deployment\n on the launched \ncbd\n VM. This is the\n      \ncbd\n root folder there.\n\n\nAll \ncbd\n actions must be executed from the \ncbd\n root folder.\n\n\nMost of the \ncbd\n commands require \nroot\n permissions. So it would be worth if you apply the \nsudo su\n.\n\n\n\n\nValidate That Cloudbreak Deployer Has Started and Profile has public IP properly configured\n\n\n\n\n\n\nSSH to the launched Azure VM.\n\n\n\n\n\n\nMost of the \ncbd\n commands require \nroot\n permissions. So it would be worth if you apply the:\n\n\n\n\n\n\n  sudo su\n\n\n\n\n\n\nThis is a MUST on Azure because the \nCustomscript Extension\n which basically creates everything running as sudo and this is not modifiable.\n\n\n\n\n\n\nOpen the \ncloudbreak-deployment\n directory:\n\n\n\n\n  cd /var/lib/cloudbreak-deployment\n\n\n\n\n\n\nPre-installed Cloudbreak Deployer version and health:\n\n\n\n\n  cbd doctor\n\n\n\n\n\n\nIf you need to run \ncbd update\n refer to \nCloudbreak Deployer Update\n. Most of the \ncbd\n commands require \nroot\n permissions.\n\n\n\n\n\n\nStarted Cloudbreak Application logs:\n\n\n\n\n   cbd logs cloudbreak\n\n\n\n\n\n\nCloudbreak should start within a minute - you should see a line like this: \nStarted CloudbreakApplication in 36.823 seconds\n\n\n\n\nProvisioning Prerequisites\n\n\nWe use the new \nAzure ARM\n in \norder to launch clusters. In order to work we need to create an \nActive Directory\n application with the configured name and password and adds the permissions that are needed to call the Azure Resource Manager API. Cloudbreak Deployer automates all this for you.\n\n\n\n\nIf you forget to configure these steps you will not able to create any resource with Cloudbreak\n\n\n\n\nAzure Access Setup\n\n\nIf you do not have an \nActive Directory (AD)\n user then you have to configure it before deploying a cluster with \nCloudbreak:\n\n\n\n\nWhy you need this? Read more \nhere\n\n\n\n\n\n\nGo to \nmanage.windowsazure.com\n \n \nActive Directory\n\n\nSelect one of your AD where you would like to create the new user\n\n\nYou can configure your AD users on \nYour active directory\n \n \nUsers\n menu\n\n\n\n\n\n\nFull size \nhere\n.\n\n\n\n\nHere you can add the new user to AD. Simply click on \nAdd User\n in the bottom of the page\n\n\nTYPE OF USER\n: select \nNew user in your organization\n\n\nUSER NAME\n: type the new user name into the box\n\n\nFill out the name fields for the new user on the second page of the ADD USER window\n\n\nSubmit the new user creation on the third window with the big green button\n\n\nCopy the password \nFolo4965\n\n\nClick on the tick button in the bottom of the the ADD USER window\n\n\n\n\n\n\nYou will see the new user in the \nUSERS\n list\n\n\n\n\n\n\nYou have got a temporary password so you have to change it before you start using the new user.\n\n\n\n\n\n\nYou need to add your AD user to the \nmanage.windowsazure.com\n \n \nSettings\n \n \nAdministrators\n\n\n\n\n\n\nFull size \nhere\n.\n\n\n\n\nHere you can add the new user to Administrators. Simply click on \nAdd\n in the bottom of the page\n\n\nEMAIL ADDRESS\n: copy the previously created user email address here\n\n\nSelect the appropriate \nSUBSCRIPTION\n for the user\n\n\nClick on the tick button in the bottom of the the ADD A CO-ADMINISTRATOR window\n\n\n\n\n\n\nYou will see the new co-administrator a in the \nADMINISTRATORS\n list\n\n\n\n\nAzure Application Setup with Azure CLI\n\n\nIn order for Cloudbreak to be able to launch clusters on Azure on your behalf you need to set up your \nAzure ARM \napplication\n. If you do not want to create your ARM application via the Azure Web UI, \nyou can create it with Azure CLI\n.\n\n\nYou can find Azure CLI install documentation on the following link:\n\nAzure CLI\n\n\nFirst you have to login with the command below:\n\n\naz login\n\n\nThen you can setup your Azure Application with the following Azure CLI command:\n\n\naz ad sp create-for-rbac --name cloudbreak-app --password \n****\n --role Owner\n\n\n\n\nResponse:\n\n\n{\n  \nappId\n: \n********-748c-4018-b445-************\n,\n  \ndisplayName\n: \ncloudbreak-app\n,\n  \nname\n: \nhttp://cloudbreak-app\n,\n  \npassword\n: \n****\n,\n  \ntenant\n: \n********-d98e-4c64-9301-************\n\n}\n\n\n\n\n\n\nWhy you need this? Read more \nhere\n\n\n\n\n\n\nIt creates an Active Directory application with the configured name, password\n\n\nIt grants permissions to call the Azure Resource Manager API\n\n\n\n\nPlease use the output of the command when you creating your Azure credential in Cloudbreak.\n\n\nFile System Configuration\n\n\nWhen starting a cluster with Cloudbreak on Azure, the default file system is \u201cLocal HDFS\u201d.\n\n\nCloudbreak has support for \nAzure Data Lake Store (ADLS) file system\n, selecting it from the drop-down list automatically configures the required properties in the cluster. ADLS is not supported as default file system.   \n\n\nHadoop has built-in support for the \nWindows Azure Blob Storage (WASB) file system\n, so it can be\nused easily as default file system. To enable this behavior, \nUse File System As Default\n must be selected.\n\n\nDisks and Storage\n\n\nIn Azure every data disk attached to a virtual machine \nis stored\n as a virtual hard disk (VHD) in a page blob inside an Azure storage account. Because these are not local disks and the operations must be done on the VHD files it causes degraded performance when used as HDFS.\nWhen WASB is used as a Hadoop file system the files are full-value blobs in a storage account. It means better performance compared to the data disks and the WASB file system can be configured very easily but Azure storage accounts have their own \nlimitations\n as well. There is a space limitation for TB per storage account (500 TB) as well but the real bottleneck is the total request rate that is only 20000 IOPS where Azure will start to throw errors when trying to do an I/O operation.\nTo bypass those limits Azure Data Lake Store (ADLS) can be used, which is an Apache Hadoop file system compatible with Hadoop Distributed File System (HDFS) and works with the Hadoop ecosystem. To be able to use it, an ADLS account must be created on your Azure subscription. For more information on ADLS, refer to \nOverview of Azure Data Lake Store\n.\n\n\nContainers Within the Storage Account\n\n\nCloudbreak creates a new container in the configured storage account for each cluster with the following name\npattern \ncloudbreak-UNIQUE_ID\n. Re-using existing containers in the same account is not supported as dirty data can\nlead to failing cluster installations. In order to take advantage of the WASB file system your data does not have to\nbe in the same storage account nor in the same container. You can add as many accounts as you wish through Ambari, by\n setting the properties described \nhere\n. Once you\n added the appropriate properties you can use those storage accounts with the pre-existing data, like:\n\n\nhadoop fs -ls wasb://data@youraccount.blob.core.windows.net/terasort-input/\n\n\n\n\n\n\nIMPORTANT:\n Make sure that your cloud account can launch instances using the new Azure ARM (a.k.a. V2) API and\nyou have sufficient qouta (CPU, network, etc) for the requested cluster size.\n\n\n\n\nExamples\n\n\nYou can find additional examples for accessing resources in your storage accounts with Hadoop FileSystem Shell for \nWASB\n \nhere\n and for \nADLS\n \nhere\n.\n\n\nGenerate a New SSH Key\n\n\nAll the instances created by Cloudbreak are configured to allow key-based SSH,\nso you'll need to provide an SSH public key that can be used later to SSH onto the instances in the clusters you'll create with Cloudbreak.\nYou can use one of your existing keys or you can generate a new one.\n\n\nTo generate a new SSH keypair:\n\n\nssh-keygen -t rsa -b 4096 -C \nyour_email@example.com\n\n# Creates a new ssh key, using the provided email as a label\n# Generating public/private rsa key pair.\n\n\n\n\n# Enter file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]\nYou'll be asked to enter a passphrase, but you can leave it empty.\n\n# Enter passphrase (empty for no passphrase): [Type a passphrase]\n# Enter same passphrase again: [Type passphrase again]\n\n\n\n\nAfter you enter a passphrase the keypair is generated. The output should look something like below. \n\n\n# Your identification has been saved in /Users/you/.ssh/id_rsa.\n# Your public key has been saved in /Users/you/.ssh/id_rsa.pub.\n# The key fingerprint is:\n# 01:0f:f4:3b:ca:85:sd:17:sd:7d:sd:68:9d:sd:a2:sd your_email@example.com\n\n\n\n\nLater you'll need to pass the \n.pub\n file's contents to Cloudbreak and use the private part to SSH to the instances\n\n\nProvisioning via Browser\n\n\nYou can log into the Cloudbreak application at \nhttps://\nPublic_IP\n/\n.\n\n\nThe main goal of the Cloudbreak UI is to easily create clusters on your own cloud provider account.\nThis description details the AZURE setup - if you'd like to use a different cloud provider check out its manual.\n\n\nThis document explains the four steps that need to be followed to create Cloudbreak clusters from the UI:\n\n\n\n\nconnect your AZURE account with Cloudbreak\n\n\ncreate some template resources on the UI that describe the infrastructure of your clusters\n\n\ncreate a blueprint that describes the HDP services in your clusters\n\n\nlaunch the cluster itself based on these template resource\n\n\n\n\nSetting up Azure Credentials\n\n\nCloudbreak works by connecting your AZURE account through so called \nCredentials\n, and then uses these credentials to \ncreate resources on your behalf. The credentials can be configured on the \nmanage credentials\n panel on the \nCloudbreak Dashboard.\n\n\n\n\nPlease read the \nProvisioning prerequisites\n where you \ncan find the steps how can get the mandatory \nSubscription ID\n, \nApp ID\n, \nPassword\n and \nApp Owner Tenant ID\n for \nyour Cloudbreak credential.\n\n\n\n\nTo create a new AZURE credential you have two options:\n\n\n\n\nInteractive login\n\n\nApp based\n\n\n\n\nInteractive login\n\n\nInteractive login based credential creation is fully automated, meaning that the creation of the necessary Azure resources (application and service principal) is done automatically driven by Cloudbreak application itself, the user has to provide only a minimal set of input. \n\n\nBefore you can use interactive login, you have to provide your tenant ID and subscription ID in your Profile\n\n\n\n\n\n\nexport AZURE_TENANT_ID=********-d98e-4c64-9301-**************\n\n\n\n\n\n\nexport AZURE_SUBSCRIPTION_ID=********-8a1d-4ac9-909b-************\n\n\n\n\n\n\nSteps\n\n\n\n\n\n\nFill out the new credential \nName\n\n\n\n\nOnly alphanumeric and lowercase characters (min 5, max 100 characters) can be applied\n\n\n\n\n\n\n\n\nCopy your SSH public key to the \nSSH public key\n field\n\n\n\n\nThe SSH public key must be in OpenSSH format and it's private keypair can be used later to \nSSH onto every instance\n of every cluster you'll create with this credential.\n\n\nThe \nSSH username\n for the AZURE instances is \ncloudbreak\n.\n\n\n\n\n\n\n\n\nSelect Azure role type. You have the option to decide if Cloudbreak should use the built-in \nContributor\n Azure role or a custom existing or new role for managing cluster resources in Azure. \n    You have the following options:\n\n\n\n\nUse existing \"Contributor\" role\n\n\nThis is the default behaviour which needs no further input and will assign Cloudbreak service principal \nContributor\n role for your subscription\n\n\n\n\n\n\nReuse existing custom role\n\n\nYou can reuse an already existing Azure role which has the required minimal permission set necessary for Cloudbreak to be able the manage the cluster's resources. It returns an error if no role with the name specified exists or the role does not have the required permission set. \n\n\nYou can find documentation about creating custom roles \nhere\n.\n\n\n\n\n\n\n\n\n\n\nLet Cloudbreak create a custom role\n\n\nChoosing this option will let Cloudbreak application create the Azure role with the necessary permissions. It returns an error if a role alerady exists with the name specified.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe necessary Action set for Cloudbreak to be able to manage the clusters include:\n                    \"Microsoft.Compute/*\",\n                    \"Microsoft.Network/*\",\n                    \"Microsoft.Storage/*\",\n                    \"Microsoft.Resources/*\"\n\n\n\n\n\n\n\n\nClick next. Then you will see a device code on the screen. Click on the 'Azure login' button and please enter the code on the azure portal. \n\n\n\n\n\n\n\n\nSelect the account you wish to use \n\n\n\n\nThis account must be in the same subscription and tenant what you previously provided in your Profile otherwise the credential creation will fail. \n\n\n\n\n \n\n\n\n\n\n\nAfter that you should see a progress bar like on the image below \n\n\n\n\n\n\n\n\nApp based\n\n\nYou have to complete the \nProvisioning prerequisites\n where you can find the steps how can get the mandatory \nSubscription ID\n, \nApp ID\n, \nPassword\n and \nApp Owner Tenant ID\n for your Cloudbreak credential.\n\n\n\n\nFill out the new credential \nName\n\n\nOnly alphanumeric and lowercase characters (min 5, max 100 characters) can be applied\n\n\n\n\n\n\nCopy your AZURE Subscription ID to the \nSubscription Id\n field\n\n\n\n\n\n\nFull size \nhere\n.\n\n\n\n\nCopy your AZURE Active Directory Application:\n\n\nID to the \nApp Id\n field\n\n\npassword to the \nPassword\n field\n\n\nApp Owner Tenant Id\n field\n\n\n\n\n\n\n\n\n\n\nFull size \nhere\n.\n\n\n\n\nCopy your SSH public key to the \nSSH public key\n field\n\n\nThe SSH public key must be in OpenSSH format and it's private keypair can be used later to \nSSH onto every \ninstance\n of every cluster you'll create with this credential.\n\n\nThe \nSSH username\n for the AZURE instances is \ncloudbreak\n.\n\n\n\n\n\n\n\n\n\n\nAny other parameter is optional here.\n\n\nPublic in account\n means that all the users belonging to your account will be able to use this credential to create \nclusters, but cannot delete it.\n\n\nCloudbreak is supporting simple rsa public key instead of X509 certificate file after 1.0.4 version\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nInfrastructure Templates\n\n\nAfter your AZURE account is linked to Cloudbreak you can start creating resource templates that describe your clusters' \ninfrastructure:\n\n\n\n\ntemplates\n\n\nnetworks\n\n\nsecurity groups\n\n\n\n\nWhen you create one of the above resources, \nCloudbreak does not make any requests to AZURE. Resources are only created\n on AZURE after the \ncreate cluster\n button has pushed.\n These templates are saved to Cloudbreak's database and can be \n reused with multiple clusters to describe the infrastructure.\n\n\nTemplates\n\n\nTemplates describe the \ninstances of your cluster\n - the instance type and the attached volumes. A typical setup is\n to combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple\n large disks to the datanodes or have memory optimized instances for Spark nodes.\n\n\nThe instance templates can be configured on the \nmanage templates\n panel on the Cloudbreak Dashboard.\n\n\nThe \nVolume Type\n describes the \nStorage Account type\n which will be used for the attached disks. The only constraint is that the \nPremium storage\n can only be used\nfor \nDS\n instance types. For more details about the premium storage read \nthis\n.\n\n\nIf \nPublic in account\nis checked all the users belonging to your account will be able to use this resource to create \nclusters, but cannot delete it\n\n\nNetworks\n\n\nYour clusters can be created in their own \nnetworks\n or in one of your already existing one. The subnet's IP range must be defined in \nthe \nSubnet (CIDR)\n field using the general CIDR notation.\n\n\nDefault AZURE Network\n\n\nIf you don't want to create or use your custom network, you can use the \ndefault-azure-network\n for all your \nCloudbreak clusters. It will create a new network with a \n10.0.0.0/16\n subnet every time a cluster is created.\n\n\nCustom AZURE Network\n\n\nIf you'd like to deploy a cluster to a custom network you'll have to \ncreate a new network\n template on the \nmanage \nnetworks\n panel.\n\n\nYou have the following options:\n\n\n\n\nCreate a new virtual network and a new subnet\n:  Every time a cluster is created with this kind of network setup a new virtual network and a new subnet with the specified IP range will be created for the instances on Azure.\n\n\nUse an existing subnet in an existing virtual network\n: \nUse this kind of network setup if you have an existing virtual network with one or more subnets on Azure and you'd like to start the instances of a cluster in one of those subnets. \nIn this case you can define the \nSubnet Identifier\n and the \nVirtual Network Identifier\n and the \nResource Group Identifier\n of your network. \n\n\nThe \nResource Group Identifier\n identifies the resource group which contains your existing virtual network. \n\n\nThe \nVirtual Network Identifier\n and the \nSubnet Identifier\n will tell Cloudbreak which network and subnet to use to launch the new instances.\n\n\nIf you enable \nDon't create public IPs\n, then Cloudbreak will not assign public ip address to the VMs. Please make sure that Cloudbreak can access the launched instances and the instances can reach the internet.\n\n\nIf you enable \nDon't create new firewall rules\n, then Cloudbreak will not create security groups. Make sure that the created instances in the subnet can reach each other.\n\n\n\n\n\n\n\n\n\n\nIMPORTANT:\n In case of existing subnet make sure you have enough room within your network space for the new instances. The \nprovided subnet CIDR will be ignored, but the existing subnet's CIDR range will be used. The security group behavior will be changed in this case as well\ndescribed in the security group section below.\n\n\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to use this network template \nto create clusters, but cannot delete it.\n\n\n\n\nNOTE:\n The new networks are created on AZURE only after the the cluster provisioning starts with the selected \nnetwork template.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nSecurity groups\n\n\nSecurity group templates are very similar to the \nsecurity groups on Azure\n.\n\nThey describe the allowed inbound traffic to the instances in the cluster.\n\nCurrently only one security group template can be selected for a Cloudbreak cluster and all the instances have a \npublic IP address so all the instances in the cluster will belong to the same security group.\nThis may change in a later release.\n\n\nDefault Security Group\n\n\nYou can also use the two pre-defined security groups in Cloudbreak.\n\n\nonly-ssh-and-ssl:\n all ports are locked down except for SSH and the selected Ambari Server HTTPS (you can't access Hadoop services \noutside of the virtual network):\n\n\n\n\nSSH (22)\n\n\nHTTPS (443)\n\n\n\n\nCustom Security Group\n\n\nYou can define your own security group by adding all the ports, protocols and CIDR range you'd like to use. The rules\n defined here doesn't need to contain the internal rules, those are automatically added by Cloudbreak to the security\n  group on Azure.\n\n\nHadoop services :\n\n Ambari (8080)\n\n Consul (8500)\n\n NN (50070)\n\n RM Web (8088)\n\n Scheduler (8030RM)\n\n IPC (8050RM)\n\n Job history server (19888)\n\n HBase master (60000)\n\n HBase master web (60010)\n\n HBase RS (16020)\n\n HBase RS info (60030)\n\n Falcon (15000)\n\n Storm (8744)\n\n Hive metastore (9083)\n\n Hive server (10000)\n\n Hive server HTTP (10001)\n\n Accumulo master (9999)\n\n Accumulo Tserver (9997)\n\n Atlas (21000)\n\n KNOX (8443)\n\n Oozie (11000)\n\n Spark HS (18080)\n\n NM Web (8042)\n\n Zeppelin WebSocket (9996)\n\n Zeppelin UI (9995)\n\n Kibana (3080)\n* Elasticsearch (9200)\n\n\n\n\nIMPORTANT\n 443, 9443, and 22 ports needs to be there in every security group otherwise Cloudbreak won't be able to communicate with the provisioned cluster.\n\n\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to use this security group \ntemplate to create clusters, but cannot delete it.\n\n\n\n\nNOTE:\n The security groups are created on Azure only after the cluster provisioning starts with the selected \nsecurity group template.\n\n\nIMPORTANT:\n If you use and existing virtual network and subnet the selected security group will only be applied to the selected Ambari Server node due to the lack of\ncapability to attach multiple security groups to an existing subnet. If you'd like to open ports for Hadoop you must do it on your existing security group.\n\n\n\n\n\n\nFull size \nhere\n.\n/sub\n\n\nAvailability sets and rack awareness\n\n\nAvailability sets\n\n\nAzure implements the concept of \n\u201cAvailability Sets\u201d\n to support fault tolerance for VM's. This feature allows two or more VM's to be mapped to multiple fault domains. Fault domains define the group of virtual machines that share a common power source and network switch. VM's with different fault domains are guaranteed an SLA. This SLA includes guarantees that during OS Patching in Azure or during maintenance operations, at least one VM belonging to a different fault domain will be available.\n\n\nAvailability sets have either two or three Fault Domains, each sharing a common power source and network switch. When adding VM-s to an availability set, Azure automatically assigns each VM a Fault Domain.\n\n\nIn Cloudbreak UI, availability sets can be configured during cluster creation. First, you have to enable availability sets with the checkbox under \nConfigure Cluster\n tab. Then you can add the desired availability sets by providing a name and the desired fault domain count (2 or 3). \n\n\n\n\nFull size \nhere\n.\n\n\nThe sets defined here can be assigned to the hostgroups in \nChoose Blueprint\n tab. An availability set can be assigned to only one hostgroup so you should define as much availability set in advance as needed for your hostgroups. By default, there is no availability set selected. The assignment of fault domains is automated by Azure so there is no option in Cloudbreak.\n\n\n\n\nIMPORTANT:\n Single instances placed in an Availability Set are not subject to Azure\u2019s SLA, and you won\u2019t receive warnings of planned maintenance events, so Availability Groups should only be used when there\u2019s a group of two or more application tier VMs.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nAfter the deployment is finished, the layout of the VM-s inside an availability set can be checked in Azure Portal. There are \"Availability set\" resources corresponding to the hostgroups inside the deployments's resource group.  \n\n\n\n\nFull size \nhere\n.\n\n\nRack awareness\n\n\nRack awareness is having the knowledge of Cluster topology or more specifically how the different data nodes are distributed across the racks of a Hadoop cluster. The importance of this knowledge relies on this assumption that co-located data nodes inside a specific rack will have more bandwidth and less latency whereas two data nodes in separate racks will have comparatively less bandwidth and higher latency.\n\n\nThe main purpose of Rack awareness are:\n\n\n\n\nIncreasing the availability of data block\n\n\nBetter cluster performance\n\n\n\n\nHDFS replicates a data block into 3 replicas by default. In this configuration, 2 blocks stay rack local and one block is placed in a different rack. When building a Hadoop cluster on Azure there is no notion of a physical rack. However the fault domains are similar in the failure characteristics of a physical rack. Since electrical events affect a fault domain as an unit, it is important to assign the rack topology based on fault domain allocation.\n\n\nYou can view the rack assignment in Ambari, clicking on the Hosts menu item. If there was no availability set selected for the given host's hostgroup, it's rack remains set to \"default rack\".\n\n\n\n\nFull size \nhere\n.\n/sub\n\n\nDefining Cluster Services\n\n\nBlueprints\n\n\nBlueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are \nused by Ambari\n.\n\n\nYou can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file, URL (an \nexample blueprint\n) or the \nwhole JSON can be written in the \nJSON text\n box.\n\n\nThe host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.\n\n\n\n\nNOTE:\n It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will \nfill that with a default value.\n\n\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to use this blueprint to \ncreate clusters, but cannot delete or modify it.\n\n\n\n\nFull size \nhere\n.\n\n\nA blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications.\n\nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations...etc. that won't be applicable to the Cloudbreak cluster\n\n\nCluster Deployment\n\n\nAfter all the cluster resources are configured you can deploy a new HDP cluster.\n\n\nHere is a \nbasic flow for cluster creation on Cloudbreak Web UI\n:\n\n\n\n\nStart by selecting a previously created Azure credential in the header.\n\n\nOpen \ncreate cluster\n\n\n\n\nConfigure Cluster\n tab\n\n\n\n\nFill out the new cluster \nname\n\n\nCluster name must start with a lowercase alphabetic character then you can apply lowercase alphanumeric and\n   hyphens only (min 5, max 40 characters)\n\n\n\n\n\n\nSelect a \nRegion\n where you like your cluster be provisioned\n\n\nClick on the \nSetup Network and Security\n button\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to see the created cluster on\n the UI, but cannot delete or modify it.\n\n\n\n\n\n\n\n\nSetup Network and Security\n tab\n\n\n\n\nSelect one of the networks\n\n\nClick on the \nChoose Blueprint\n button\n\n\nIf \nEnable security\n is checked as well, Cloudbreak will install Key Distribution Center (KDC) and the cluster will\nbe Kerberized. See more about it in the \nKerberos\n section of this documentation.\n\n\n\n\n\n\n\n\nChoose Blueprint\n tab\n\n\n\n\nSelect one of the blueprint\n\n\nAfter you've selected a \nBlueprint\n, you should be able to configure:\n\n\nthe templates\n\n\nthe securitygroups\n\n\nthe number of nodes for all of the host groups in the blueprint\n\n\n\n\n\n\nYou need to select where you want to install the Ambari server to. Only 1 host group can be selected.\n   If you want to install the Ambari server to a separate node, you need to extend your blueprint with a new host group\n   which contains only 1 service: HDFS_CLIENT and select this host group for the Ambari server. Note: this host group cannot be scaled so\n   it is not advised to select a 'slave' host group for this purpose.\n\n\nClick on the \nAdd File System\n button\n\n\n\n\nAdd File System\n tab\n\n\n\n\nSelect one of the file system that fits your needs\n\n\nIf you've selected \nWASB\n you should configure:\n\n\nStorage Account Name\n\n\nStorage Account Access Key\n\n\n\n\n\n\nIf you've selected \nADLS\n, you should specify your preconfigured ADLS account name.    \n\n\nClick on the \nReview and Launch\n button\n\n\nFile system\n is a mandatory configuration for Azure. You can read more about WASB and ADLS in the \nFile System Configuration section\n.\n\n\n\n\n\n\n\n\nReview and Launch\n tab\n\n\n\n\nAfter the \ncreate and start cluster\n button has clicked Cloudbreak will start to create the cluster's resources on\n your Azure account.\n\n\n\n\nCloudbreak uses \nAzure Resource Manager\n to create the resources - you can check out the resources created by Cloudbreak\n on\nthe \nAzure Portal Resource groups\n page.\n\n\n\nFull size \nhere\n.\n\n\nBesides these you can check the progress on the Cloudbreak Web UI itself if you open the new cluster's \nEvent History\n.\n\n\n\nFull size \nhere\n.\n\n\nAdvanced options\n\n\nThere are some advanced features when deploying a new cluster, these are the following:\n\n\nAmbari Username\n This user will be used as admin user in Ambari. You can log in using this username on the Ambari UI.\n\n\nAmbari Password\n The password associated with the Ambari username. This password will be also the default password for all required passwords which are not specified in the blueprint. E.g: hive DB password.\n\n\nMinimum cluster size\n The provisioning strategy in case the cloud provider cannot allocate all the requested nodes.\n\n\nValidate blueprint\n This is selected by default. Cloudbreak validates the Ambari blueprint in this case.\n\n\nCustom Image\n If you enable this, you can override the default image for provision.\n\n\nEnable Availability sets\n You can set up availability set support if enabled.\n\n\nShipyard enabled cluster\n This is selected by default. Cloudbreak will start a \nShipyard\n container which helps you to manage your containers.\n\n\nPersistent Storage Name\n This is \ncbstore\n by default. Cloudbreak will copy the image into a storage which is not deleting under the termination. When you starting a new cluster then the provisioning will be much faster because of the existing image.\n\n\nAttached Storage Type\n This is \nsingle storage for all vm\n by default. If are you using the default option then your whole cluster will by in one storage which could be a bottleneck in case of \nAzure\n. If you are using the \nseparated storage for every vm\n then we will deploy as much storage account as many node you have and in this case IOPS limit concern just for one node.\n\n\nConfig recommendation strategy\n Strategy for how configuration recommendations will be applied. Recommended\nconfigurations gathered by the response of the stack advisor.\n\n\n\n\nNEVER_APPLY\n               Configuration recommendations are ignored with this option.\n\n\nONLY_STACK_DEFAULTS_APPLY\n Applies only on the default configurations for all included services.\n\n\nALWAYS_APPLY\n              Applies on all configuration properties.\n\n\n\n\nCluster Termination\n\n\nYou can terminate running or stopped clusters with the \nterminate\n button in the cluster details.\n\n\n\n\nIMPORTANT:\n Always use Cloudbreak to terminate the cluster. If that fails for some reason, try to delete the \nAzure resource group first. Instances are started in an Auto Scaling Group so they may be restarted if you terminate an \ninstance manually!\n\n\n\n\nSometimes Cloudbreak cannot synchronize its state with the cluster state at the cloud provider and the cluster can't\n be terminated. In this case the \nForced termination\n option can help to terminate the cluster at the Cloudbreak \n side. \nIf it has happened:\n\n\n\n\nYou should check the related resources at the Azure Portal\n\n\nIf it is needed you need to manually remove resources from there\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nInteractive mode / Cloudbreak Shell\n\n\nThe goal with the Cloudbreak Shell (Cloudbreak CLI) was to provide an interactive command line tool which supports:\n\n\n\n\nall functionality available through the REST API or Cloudbreak Web UI\n\n\nmakes possible complete automation of management task via scripts\n\n\ncontext aware command availability\n\n\ntab completion\n\n\nrequired/optional parameter support\n\n\nhint command to guide you on the usual path\n\n\n\n\nStart Cloudbreak Shell\n\n\nTo start the Cloudbreak CLI use the following commands:\n\n\n\n\nOpen your \ncloudbreak-deployment\n directory if it is needed. For example:\n\n\n\n\n   cd cloudbreak-deployment\n\n\n\n\n\n\nStart the \ncbd\n from here if it is needed\n\n\n\n\n   cbd start\n\n\n\n\n\n\nIn the root of your \ncloudbreak-deployment\n folder apply:\n\n\n\n\n   cbd util cloudbreak-shell\n\n\n\n\n\n\nAt the very first time it will take for a while, because of need to download all the necessary docker images.\n\n\n\n\nThis will launch the Cloudbreak shell inside a Docker container then it is ready to use.\n\n\n\nFull size \nhere\n.\n\n\n\n\nIMPORTANT You have to copy all your files into the \ncbd\n working directory, what you would like to use in shell.\n For \nexample if your \ncbd\n working directory is \n~/cloudbreak-deployment\n then copy your \nblueprint JSON, public ssh key \nfile...etc.\n to here. You can refer to these files with their names from the shell.\n\n\n\n\nAutocomplete and Hints\n\n\nCloudbreak Shell helps you with \nhint messages\n from the very beginning, for example:\n\n\ncloudbreak-shell\nhint\nHint: Add a blueprint with the 'blueprint create' command or select an existing one with 'blueprint select'\ncloudbreak-shell\n\n\n\n\n\nBeyond this you can use the \nautocompletion (double-TAB)\n as well:\n\n\ncloudbreak-shell\ncredential create --\ncredential create --AWS          credential create --AZURE        credential create --EC2          credential create --GCP          credential create --OPENSTACK\n\n\n\n\nProvisioning via CLI\n\n\nSetting up Azure Credential\n\n\nCloudbreak works by connecting your Azure account through so called Credentials, and then uses these credentials to \ncreate resources on your behalf. Credentials can be configured with the following command for example:\n\n\ncredential create --AZURE --name my-azure-credential --description \nsample credential\n --subscriptionId \nyour-azure-subscription-id --tenantId your-azure-application-tenant-id --appId \nyour-azure-application-id --password YourApplicationPassword --sshKeyString \nssh-rsa AAAAB3***etc.\n\n\n\n\n\n\n\nCloudbreak is supporting simple rsa public key instead of X509 certificate file after 1.0.4 version\n\n\nNOTE:\n Cloudbreak \ndoes not set your cloud user details\n - we work around the concept of Access Control \nService (ACS). You should have already a valid Azure Subscription and Application. You can find further details \nhere\n.\n\n\n\n\nAlternatives to provide \nSSH Key\n:\n\n\n\n\nyou can upload your public key from an url: \n\u2014sshKeyUrl\n \n\n\nor you can add the path of your public key: \n\u2014sshKeyPath\n\n\n\n\nYou can check whether the credential was created successfully\n\n\ncredential list\n\n\n\n\nYou can switch between your existing credentials\n\n\ncredential select --name my-azure-credential\n\n\n\n\nInfrastructure Templates\n\n\nAfter your Azure account is linked to Cloudbreak you can start creating resource templates that describe your clusters' \ninfrastructure:\n\n\n\n\nsecurity groups\n\n\nnetworks\n\n\ntemplates\n\n\n\n\nWhen you create one of the above resources, \nCloudbreak does not make any requests to Azure. Resources are only created\n on Azure after the \ncluster create\n has applied.\n These templates are saved to Cloudbreak's database and can be \n reused with multiple clusters to describe the infrastructure.\n\n\nTemplates\n\n\nTemplates describe the \ninstances of your cluster\n - the instance type and the attached volumes. A typical setup is\n to combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple\n large disks to the datanodes or have memory optimized instances for Spark nodes.\n\n\nA template can be used repeatedly to create identical copies of the same stack (or to use as a foundation to start a \nnew stack). Templates can be configured with the following command for example:\n\n\ntemplate create --AZURE --name my-azure-template --description \nsample description\n --instanceType Standard_D4 --volumeSize 100 --volumeCount 2 --volumeType Standard_LRS\n\n\n\n\nThe \nVolume Type\n describes the \nStorage Account type\n which will be used for the attached disks. The only constraint is that the \nPremium storage\n can only be used\nfor \nDS\n instance types. For more details about the premium storage read \nthis\n.\n\n\nOther available option here is \n--publicInAccount\n. If it is true, all the users belonging to your account will be able\n to use this template to create clusters, but cannot delete it.\n\n\nYou can check whether the template was created successfully\n\n\ntemplate list\n\n\n\n\nNetworks\n\n\nYour clusters can be created in their own \nnetworks\n or in one of your already existing one. If you choose an \nexisting network, it is possible to create a new subnet within the network. The subnet's IP range must be defined in \nthe \nSubnet (CIDR)\n field using the general CIDR notation.\n\n\nDefault AZURE Network\n\n\nIf you don't want to create or use your custom network, you can use the \ndefault-azure-network\n for all your \nCloudbreak clusters. It will create a new network with a \n10.0.0.0/16\n subnet and \n10.0.0.0/8\n address prefix every \ntime a cluster is created.\n\n\nCustom AZURE Network\n\n\nIf you'd like to deploy a cluster to a custom network you'll have to apply the following command:\n\n\nnetwork create --AZURE --name my-azure-network --addressPrefix 192.168.123.123 --subnet 10.0.0.0/16\n\n\n\n\n\n\nIMPORTANT:\n Make sure the defined subnet and theirs address prefixes here doesn't overlap with any of your \nalready deployed subnet and its already used address prefix in the network, because the validation only happens\nafter the cluster creation \nstarts.\n\n\nIn case of existing subnet make sure you have enough room within your network space for the new instances. The \nprovided subnet CIDR will be ignored, but a proper CIDR range will be used.\n\n\n\n\nYou can check whether the network was created successfully\n\n\nnetwork list\n\n\n\n\n--addressPrefix\n This list will be appended to the current list of address prefixes.\n\n\n\n\nThe address prefixes in this list should not overlap between them.\n\n\nThe address prefixes in this list should not overlap with existing address prefixes in the network.\n\n\n\n\nYou can find more details about the AZURE Address Prefixes \nhere\n.\n\n\nIf \n--publicInAccount\n is true, all the users belonging to your account will be able to use this network template \nto create clusters, but cannot delete it.\n\n\n\n\nNOTE:\n The new networks are created on AZURE only after the the cluster provisioning starts with the selected \nnetwork template.\n\n\n\n\nDefining Cluster Services\n\n\nBlueprints\n\n\nBlueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are \nused by Ambari\n.\n\n\nYou can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file or URL (an \nexample blueprint\n).\n\n\nThe host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.\n\n\n\n\nNOTE:\n It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will fill that with a default value.\n\n\n\n\nblueprint create --name my-blueprint --description \nsample description\n --file \nthe path of the blueprint\n\n\n\n\n\nOther available options:\n\n\n--url\n the url of the blueprint\n\n\n--publicInAccount\n If it is true, all the users belonging to your account will be able to use this blueprint to create \nclusters, but cannot delete it.\n\n\nYou can check whether the blueprint was created successfully\n\n\nblueprint list\n\n\n\n\nA blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications.\n\nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations..etc. that won't be applicable to the Cloudbreak cluster.\n\n\nMetadata Show\n\n\nYou can check the stack metadata with\n\n\nstack metadata --name myawsstack --instancegroup master\n\n\n\n\nOther available options:\n\n\n--id\n In this case you can select a stack with id.\n\n\n--outputType\n In this case you can modify the outputformat of the command (RAW or JSON). \n\n\nCluster Deployment\n\n\nAfter all the cluster resources are configured you can deploy a new HDP cluster. The following sub-sections show\nyou a \nbasic flow for cluster creation with Cloudbreak Shell\n.\n\n\nSelect Credential\n\n\nSelect one of your previously created Azure credential:\n\n\ncredential select --name my-azure-credential\n\n\n\n\nSelect Blueprint\n\n\nSelect one of your previously created blueprint which fits your needs:\n\n\nblueprint select --name multi-node-hdfs-yarn\n\n\n\n\nConfigure Instance Groups\n\n\nYou must configure instance groups before provisioning. An instance group define a group of nodes with a specified\ntemplate. Usually we create instance groups for host groups in the blueprint. For Ambari server only 1 host group can be specified.\nIf you want to install the Ambari server to a separate node, you need to extend your blueprint with a new host group\nwhich contains only 1 service: HDFS_CLIENT and select this host group for the Ambari server. Note: this host group cannot be scaled so\nit is not advised to select a 'slave' host group for this purpose.\n\n\ninstancegroup configure --instanceGroup master --nodecount 1 --templateName minviable-aws --securityGroupName all-services-port --ambariServer true\ninstancegroup configure --instanceGroup slave_1 --nodecount 1 --templateName minviable-aws --securityGroupName all-services-port --ambariServer false\n\n\n\n\nOther available option:\n\n\n--templateId\n Id of the template\n\n\nSelect Network\n\n\nSelect one of your previously created network which fits your needs or a default one:\n\n\nnetwork select --name default-azure-network\n\n\n\n\nCreate Stack / Create Cloud Infrastructure**\n\n\nStack means the running cloud infrastructure that is created based on the instance groups configured earlier\n(\ncredential\n, \ninstancegroups\n, \nnetwork\n, \nsecuritygroup\n). Same as in case of the API or UI the new cluster will\nuse your templates and by using Azure ARM will launch your cloud stack. Use the following command to create a\nstack to be used with your Hadoop cluster:\n\n\nstack create --AZURE --name myazurestack --region \nNorth Europe\n\n\n\n\n\nThe infrastructure is created asynchronously, the state of the stack can be checked with the stack \nshow command\n. If\nit reports AVAILABLE, it means that the virtual machines and the corresponding infrastructure is running at the cloud provider.\n\n\nOther available option is:\n\n\n--wait\n - in this case the create command will return only after the process has finished.\n\n\n--persistentStorage\n - This is \ncbstore\n by default. Cloudbreak will copy the image into a storage which is not deleting under the termination. When you starting a new cluster then the provisioning will be much faster because of the existing image.\n\n\n--attachedStorageType\n - This is \nSINGLE\n by default. If you are using the default option then your whole cluster will by in one storage which could be a bottleneck in case of \nAzure\n. If you are using the \nPER_VM\n then we will deploy as much storage account as many node you have and in this case IOPS limit concern just for one node.\n\n\nCreate a Hadoop Cluster / Cloud Provisioning\n\n\nYou are almost done! One more command and your Hadoop cluster is starting!\n Cloud provisioning is done once the\ncluster is up and running. The new cluster will use your selected blueprint and install your custom Hadoop cluster\nwith the selected components and services.\n\n\ncluster create --description \nmy first cluster\n\n\n\n\n\nOther available option is \n--wait\n - in this case the create command will return only after the process has finished.\n\n\nYou are done!\n You have several opportunities to check the progress during the infrastructure creation then\nprovisioning:\n\n\n\n\nCloudbreak uses \nARM\n to create the resources - you can check out the resources created by Cloudbreak on\n the Azure Portal Resource groups page.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\n\n\nIf stack then cluster creation have successfully done, you can check the Ambari Web UI. However you need to know the\nAmbari IP (for example: \nhttp://23.101.60.49:8080\n):\n\n\nYou can get the IP from the CLI as a result (\nambariServerIp 23.101.60.49\n) of the following command:\n\n\n\n\n\n\n\n\n         cluster show\n\n\n\n\n\n\nFull size \nhere\n.\n\n\n\n\nBesides these you can check the entire progress and the Ambari IP as well on the Cloudbreak Web UI itself. Open the\nnew cluster's \ndetails\n and its \nEvent History\n here.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nStop Cluster\n\n\nYou have the ability to \nstop your existing stack then its cluster\n if you want to suspend the work on it.\n\n\nSelect a stack for example with its name:\n\n\nstack select --name my-stack\n\n\n\n\nOther available option to define a stack is its \n--id\n.\n\n\nEvery time you should stop the \ncluster\n first then the \nstack\n. So apply following commands to stop the previously \nselected stack:\n\n\ncluster stop\nstack stop\n\n\n\n\nRestart Cluster\n\n\nSelect your stack that you would like to restart\n after this you can apply:\n\n\nstack start\n\n\n\n\nAfter the stack has successfully restarted, you can \nrestart the related cluster as well\n:\n\n\ncluster start\n\n\n\n\nUpscale Cluster\n\n\nIf you need more instances to your infrastructure, you can \nupscale your selected stack\n:\n\n\nstack node --ADD --instanceGroup host_group_slave_1 --adjustment 6\n\n\n\n\nOther available option is \n--withClusterUpScale\n - this indicates also a cluster upscale after the stack upscale. You\n can upscale the related cluster separately if you want to do this:\n\n\ncluster node --ADD --hostgroup host_group_slave_1 --adjustment 6\n\n\n\n\nDownscale Cluster\n\n\nYou also can reduce the number of instances in your infrastructure. \nAfter you selected your stack\n:\n\n\ncluster node --REMOVE  --hostgroup host_group_slave_1 --adjustment -2\n\n\n\n\nOther available option is \n--withStackDownScale\n - this indicates also a stack downscale after the cluster downscale.\n You can downscale the related stack separately if you want to do this:\n\n\nstack node --REMOVE  --instanceGroup host_group_slave_1 --adjustment -2\n\n\n\n\nCluster Termination\n\n\nYou can terminate running or stopped clusters with\n\n\nstack delete --name myawsstack\n\n\n\n\nOther available option is \n--wait\n - in this case the terminate command will return only after the process has finished. \n\n\n\n\nIMPORTANT:\n Always use Cloudbreak to terminate the cluster. If that fails for some reason, try to delete the \nCloudFormation stack first. Instances are started in an Auto Scaling Group so they may be restarted if you terminate an instance manually!\n\n\n\n\nSometimes Cloudbreak cannot synchronize its state with the cluster state at the cloud provider and the cluster can't\n be terminated. In this case the \nForced termination\n option on the Cloudbreak Web UI can help to terminate the cluster\n  at the Cloudbreak side. \nIf it has happened:\n\n\n\n\nYou should check the related resources at the AWS CloudFormation\n\n\nIf it is needed you need to manually remove resources from there\n\n\n\n\nSilent Mode\n\n\nWith Cloudbreak Shell you can execute script files as well. A script file contains shell commands and can \nbe executed with the \nscript\n cloudbreak shell command\n\n\nscript \nyour script file\n\n\n\n\n\nor with the \ncbd util cloudbreak-shell-quiet\n command\n\n\ncbd util cloudbreak-shell-quiet \n example.sh\n\n\n\n\n\n\nIMPORTANT:\n You have to copy all your files into the \ncbd\n working directory, what you would like to use in shell.\n For example if your \ncbd\n working directory is ~/cloudbreak-deployment then copy your script file to here.\n\n\n\n\nExample\n\n\nThe following example creates a hadoop cluster with \nhdp-small-default\n blueprint on Standard_D3 instances with \n2X100G attached disks on \ndefault-azure-network\n network using \nall-services-port\n security group. You should copy \nyour ssh public key file into your \ncbd\n working directory with name \nid_rsa.pub\n and paste your Azure credentials in \nthe parts with \n...\n highlight.\n\n\ncredential create --AZURE --description \ncredential description\n --name myazurecredential --subscriptionId \nyour Azure subscription id\n --appId \nyour Azure application id\n --tenantId \nyour tenant id\n --password \nyour Azure application password\n --sshKeyPath id_rsa.pub\ncredential select --name myazurecredential\ntemplate create --AZURE --name azuretemplate --description azure-template --instanceType Standard_D3 --volumeSize 100 \n--volumeCount 2\nblueprint select --name hdp-small-default\ninstancegroup configure --instanceGroup host_group_master_1 --nodecount 1 --templateName azuretemplate --securityGroupName all-services-port --ambariServer true\ninstancegroup configure --instanceGroup host_group_master_2 --nodecount 1 --templateName azuretemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_master_3 --nodecount 1 --templateName azuretemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_client_1  --nodecount 1 --templateName azuretemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_slave_1 --nodecount 3 --templateName azuretemplate --securityGroupName all-services-port --ambariServer false\nnetwork select --name default-azure-network\nstack create --AZURE --name my-first-stack --region \nWest US\n --wait true\ncluster create --description \nMy first cluster\n --wait true\n\n\n\n\nCongratulations!\n Your cluster should now be up and running on this way as well. To learn more about Cloudbreak and \nprovisioning, we have some \ninteresting insights\n for you.", 
            "title": "Azure"
        }, 
        {
            "location": "/azure/#azure-setup", 
            "text": "Setting up Cloudbreak on Azure is different than on other cloud providers for which we provide pre-built public images with Cloudbreak Deployer pre-installed. On Azure, you launch Cloudbreak Deployer using the  Azure Resource Manager Templates .", 
            "title": "Azure Setup"
        }, 
        {
            "location": "/azure/#deploy-using-the-azure-portal", 
            "text": "To get started with Cloudbreak installation using the Azure Resource Manager template, click here:", 
            "title": "Deploy Using the Azure Portal"
        }, 
        {
            "location": "/azure/#vm-requirements", 
            "text": "When selecting an instance type, consider these minimum and recomended requirements: \n- 8GB RAM, 10GB disk, 2 cores \n- The minimum instance type suitable for Cloudbreak is  D2  To learn about all requirements, see  System Requirements .", 
            "title": "VM Requirements"
        }, 
        {
            "location": "/azure/#deployment-details", 
            "text": "In addition to the default values, the following parameters are  mandatory  for the new  cbd  template:  On the  Custom deployment  panel:   Create a new  Resource group  Select an appropriate  Resource group location   On the  Settings  panel:     Parameter  Description      Admin Username  Create an admin login that you will use to log in to the Cloudbreak UI. Must be a valid email address.    Admin User Password  Password for the admin login. Must be at least 8 characters containing letters, numbers, and symbols.    Username  Enter an admin username for the virtual machine. You will use it to SSH to the VM.    Smartsense  Select  whether you want to use SmartSense telemetry.    Remote Location  Allow connections from this address range. Must be a valid CIDR IP.    Ssh key  Paste your SSH public key. You can use  pbcopy  to quickly copy it. For example:  pbcopy   /Users/homedir/.ssh/id_rsa.pub     Finally  you should review the  Legal terms  from the  Custom deployment  panel:   To agree with the terms and conditions, click on  Create  button in this panel  Also click on the  Create  button on the  Custom deployment    Deployment takes about  15-20 minutes . You can track the\nprogress on the resource group details. If any issue has occurred, open the  Audit logs  from the settings.\nWe have faced an interesting behaviour on the Azure Portal:  All operations were successful on template deployment,\nbut overall fail .    Once it's successful done, you can reach the Cloudbreak UI\nat: https:// VM Public IP /  email: admin@example.com  password: cloudbreak", 
            "title": "Deployment Details"
        }, 
        {
            "location": "/azure/#under-the-hood", 
            "text": "While Azure is creating the deployment, review this information about what happens in the background:   Start an instance from the official CentOS image  So no custom image copy is needed, which would take about 30\n   minutes  Use  Docker VM Extension  to install Docker  Use  CustomScript Extension  to install\nCloudbreak Deployer ( cbd )   Cloudbreak Deployer Highlights   The default SSH username for the Azure VMs is  cloudbreak .  Cloudbreak Deployer location is  /var/lib/cloudbreak-deployment  on the launched  cbd  VM. This is the\n       cbd  root folder there.  All  cbd  actions must be executed from the  cbd  root folder.  Most of the  cbd  commands require  root  permissions. So it would be worth if you apply the  sudo su .", 
            "title": "Under the Hood"
        }, 
        {
            "location": "/azure/#validate-that-cloudbreak-deployer-has-started-and-profile-has-public-ip-properly-configured", 
            "text": "SSH to the launched Azure VM.    Most of the  cbd  commands require  root  permissions. So it would be worth if you apply the:      sudo su   This is a MUST on Azure because the  Customscript Extension  which basically creates everything running as sudo and this is not modifiable.    Open the  cloudbreak-deployment  directory:     cd /var/lib/cloudbreak-deployment   Pre-installed Cloudbreak Deployer version and health:     cbd doctor   If you need to run  cbd update  refer to  Cloudbreak Deployer Update . Most of the  cbd  commands require  root  permissions.    Started Cloudbreak Application logs:      cbd logs cloudbreak   Cloudbreak should start within a minute - you should see a line like this:  Started CloudbreakApplication in 36.823 seconds", 
            "title": "Validate That Cloudbreak Deployer Has Started and Profile has public IP properly configured"
        }, 
        {
            "location": "/azure/#provisioning-prerequisites", 
            "text": "We use the new  Azure ARM  in \norder to launch clusters. In order to work we need to create an  Active Directory  application with the configured name and password and adds the permissions that are needed to call the Azure Resource Manager API. Cloudbreak Deployer automates all this for you.   If you forget to configure these steps you will not able to create any resource with Cloudbreak", 
            "title": "Provisioning Prerequisites"
        }, 
        {
            "location": "/azure/#azure-access-setup", 
            "text": "If you do not have an  Active Directory (AD)  user then you have to configure it before deploying a cluster with \nCloudbreak:   Why you need this? Read more  here    Go to  manage.windowsazure.com     Active Directory  Select one of your AD where you would like to create the new user  You can configure your AD users on  Your active directory     Users  menu    Full size  here .   Here you can add the new user to AD. Simply click on  Add User  in the bottom of the page  TYPE OF USER : select  New user in your organization  USER NAME : type the new user name into the box  Fill out the name fields for the new user on the second page of the ADD USER window  Submit the new user creation on the third window with the big green button  Copy the password  Folo4965  Click on the tick button in the bottom of the the ADD USER window    You will see the new user in the  USERS  list    You have got a temporary password so you have to change it before you start using the new user.    You need to add your AD user to the  manage.windowsazure.com     Settings     Administrators    Full size  here .   Here you can add the new user to Administrators. Simply click on  Add  in the bottom of the page  EMAIL ADDRESS : copy the previously created user email address here  Select the appropriate  SUBSCRIPTION  for the user  Click on the tick button in the bottom of the the ADD A CO-ADMINISTRATOR window    You will see the new co-administrator a in the  ADMINISTRATORS  list", 
            "title": "Azure Access Setup"
        }, 
        {
            "location": "/azure/#azure-application-setup-with-azure-cli", 
            "text": "In order for Cloudbreak to be able to launch clusters on Azure on your behalf you need to set up your  Azure ARM \napplication . If you do not want to create your ARM application via the Azure Web UI,  you can create it with Azure CLI .  You can find Azure CLI install documentation on the following link: Azure CLI  First you have to login with the command below:  az login  Then you can setup your Azure Application with the following Azure CLI command:  az ad sp create-for-rbac --name cloudbreak-app --password  ****  --role Owner  Response:  {\n   appId :  ********-748c-4018-b445-************ ,\n   displayName :  cloudbreak-app ,\n   name :  http://cloudbreak-app ,\n   password :  **** ,\n   tenant :  ********-d98e-4c64-9301-************ \n}   Why you need this? Read more  here    It creates an Active Directory application with the configured name, password  It grants permissions to call the Azure Resource Manager API   Please use the output of the command when you creating your Azure credential in Cloudbreak.", 
            "title": "Azure Application Setup with Azure CLI"
        }, 
        {
            "location": "/azure/#file-system-configuration", 
            "text": "When starting a cluster with Cloudbreak on Azure, the default file system is \u201cLocal HDFS\u201d.  Cloudbreak has support for  Azure Data Lake Store (ADLS) file system , selecting it from the drop-down list automatically configures the required properties in the cluster. ADLS is not supported as default file system.     Hadoop has built-in support for the  Windows Azure Blob Storage (WASB) file system , so it can be\nused easily as default file system. To enable this behavior,  Use File System As Default  must be selected.", 
            "title": "File System Configuration"
        }, 
        {
            "location": "/azure/#disks-and-storage", 
            "text": "In Azure every data disk attached to a virtual machine  is stored  as a virtual hard disk (VHD) in a page blob inside an Azure storage account. Because these are not local disks and the operations must be done on the VHD files it causes degraded performance when used as HDFS.\nWhen WASB is used as a Hadoop file system the files are full-value blobs in a storage account. It means better performance compared to the data disks and the WASB file system can be configured very easily but Azure storage accounts have their own  limitations  as well. There is a space limitation for TB per storage account (500 TB) as well but the real bottleneck is the total request rate that is only 20000 IOPS where Azure will start to throw errors when trying to do an I/O operation.\nTo bypass those limits Azure Data Lake Store (ADLS) can be used, which is an Apache Hadoop file system compatible with Hadoop Distributed File System (HDFS) and works with the Hadoop ecosystem. To be able to use it, an ADLS account must be created on your Azure subscription. For more information on ADLS, refer to  Overview of Azure Data Lake Store .", 
            "title": "Disks and Storage"
        }, 
        {
            "location": "/azure/#containers-within-the-storage-account", 
            "text": "Cloudbreak creates a new container in the configured storage account for each cluster with the following name\npattern  cloudbreak-UNIQUE_ID . Re-using existing containers in the same account is not supported as dirty data can\nlead to failing cluster installations. In order to take advantage of the WASB file system your data does not have to\nbe in the same storage account nor in the same container. You can add as many accounts as you wish through Ambari, by\n setting the properties described  here . Once you\n added the appropriate properties you can use those storage accounts with the pre-existing data, like:  hadoop fs -ls wasb://data@youraccount.blob.core.windows.net/terasort-input/   IMPORTANT:  Make sure that your cloud account can launch instances using the new Azure ARM (a.k.a. V2) API and\nyou have sufficient qouta (CPU, network, etc) for the requested cluster size.", 
            "title": "Containers Within the Storage Account"
        }, 
        {
            "location": "/azure/#examples", 
            "text": "You can find additional examples for accessing resources in your storage accounts with Hadoop FileSystem Shell for  WASB   here  and for  ADLS   here .", 
            "title": "Examples"
        }, 
        {
            "location": "/azure/#generate-a-new-ssh-key", 
            "text": "All the instances created by Cloudbreak are configured to allow key-based SSH,\nso you'll need to provide an SSH public key that can be used later to SSH onto the instances in the clusters you'll create with Cloudbreak.\nYou can use one of your existing keys or you can generate a new one.  To generate a new SSH keypair:  ssh-keygen -t rsa -b 4096 -C  your_email@example.com \n# Creates a new ssh key, using the provided email as a label\n# Generating public/private rsa key pair.  # Enter file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]\nYou'll be asked to enter a passphrase, but you can leave it empty.\n\n# Enter passphrase (empty for no passphrase): [Type a passphrase]\n# Enter same passphrase again: [Type passphrase again]  After you enter a passphrase the keypair is generated. The output should look something like below.   # Your identification has been saved in /Users/you/.ssh/id_rsa.\n# Your public key has been saved in /Users/you/.ssh/id_rsa.pub.\n# The key fingerprint is:\n# 01:0f:f4:3b:ca:85:sd:17:sd:7d:sd:68:9d:sd:a2:sd your_email@example.com  Later you'll need to pass the  .pub  file's contents to Cloudbreak and use the private part to SSH to the instances", 
            "title": "Generate a New SSH Key"
        }, 
        {
            "location": "/azure/#provisioning-via-browser", 
            "text": "You can log into the Cloudbreak application at  https:// Public_IP / .  The main goal of the Cloudbreak UI is to easily create clusters on your own cloud provider account.\nThis description details the AZURE setup - if you'd like to use a different cloud provider check out its manual.  This document explains the four steps that need to be followed to create Cloudbreak clusters from the UI:   connect your AZURE account with Cloudbreak  create some template resources on the UI that describe the infrastructure of your clusters  create a blueprint that describes the HDP services in your clusters  launch the cluster itself based on these template resource", 
            "title": "Provisioning via Browser"
        }, 
        {
            "location": "/azure/#setting-up-azure-credentials", 
            "text": "Cloudbreak works by connecting your AZURE account through so called  Credentials , and then uses these credentials to \ncreate resources on your behalf. The credentials can be configured on the  manage credentials  panel on the \nCloudbreak Dashboard.   Please read the  Provisioning prerequisites  where you \ncan find the steps how can get the mandatory  Subscription ID ,  App ID ,  Password  and  App Owner Tenant ID  for \nyour Cloudbreak credential.   To create a new AZURE credential you have two options:   Interactive login  App based", 
            "title": "Setting up Azure Credentials"
        }, 
        {
            "location": "/azure/#interactive-login", 
            "text": "Interactive login based credential creation is fully automated, meaning that the creation of the necessary Azure resources (application and service principal) is done automatically driven by Cloudbreak application itself, the user has to provide only a minimal set of input.   Before you can use interactive login, you have to provide your tenant ID and subscription ID in your Profile    export AZURE_TENANT_ID=********-d98e-4c64-9301-**************    export AZURE_SUBSCRIPTION_ID=********-8a1d-4ac9-909b-************", 
            "title": "Interactive login"
        }, 
        {
            "location": "/azure/#steps", 
            "text": "Fill out the new credential  Name   Only alphanumeric and lowercase characters (min 5, max 100 characters) can be applied     Copy your SSH public key to the  SSH public key  field   The SSH public key must be in OpenSSH format and it's private keypair can be used later to  SSH onto every instance  of every cluster you'll create with this credential.  The  SSH username  for the AZURE instances is  cloudbreak .     Select Azure role type. You have the option to decide if Cloudbreak should use the built-in  Contributor  Azure role or a custom existing or new role for managing cluster resources in Azure. \n    You have the following options:   Use existing \"Contributor\" role  This is the default behaviour which needs no further input and will assign Cloudbreak service principal  Contributor  role for your subscription    Reuse existing custom role  You can reuse an already existing Azure role which has the required minimal permission set necessary for Cloudbreak to be able the manage the cluster's resources. It returns an error if no role with the name specified exists or the role does not have the required permission set.   You can find documentation about creating custom roles  here .      Let Cloudbreak create a custom role  Choosing this option will let Cloudbreak application create the Azure role with the necessary permissions. It returns an error if a role alerady exists with the name specified.        The necessary Action set for Cloudbreak to be able to manage the clusters include:\n                    \"Microsoft.Compute/*\",\n                    \"Microsoft.Network/*\",\n                    \"Microsoft.Storage/*\",\n                    \"Microsoft.Resources/*\"     Click next. Then you will see a device code on the screen. Click on the 'Azure login' button and please enter the code on the azure portal.      Select the account you wish to use    This account must be in the same subscription and tenant what you previously provided in your Profile otherwise the credential creation will fail.         After that you should see a progress bar like on the image below", 
            "title": "Steps"
        }, 
        {
            "location": "/azure/#app-based", 
            "text": "You have to complete the  Provisioning prerequisites  where you can find the steps how can get the mandatory  Subscription ID ,  App ID ,  Password  and  App Owner Tenant ID  for your Cloudbreak credential.   Fill out the new credential  Name  Only alphanumeric and lowercase characters (min 5, max 100 characters) can be applied    Copy your AZURE Subscription ID to the  Subscription Id  field    Full size  here .   Copy your AZURE Active Directory Application:  ID to the  App Id  field  password to the  Password  field  App Owner Tenant Id  field      Full size  here .   Copy your SSH public key to the  SSH public key  field  The SSH public key must be in OpenSSH format and it's private keypair can be used later to  SSH onto every \ninstance  of every cluster you'll create with this credential.  The  SSH username  for the AZURE instances is  cloudbreak .      Any other parameter is optional here.  Public in account  means that all the users belonging to your account will be able to use this credential to create \nclusters, but cannot delete it.  Cloudbreak is supporting simple rsa public key instead of X509 certificate file after 1.0.4 version    Full size  here .", 
            "title": "App based"
        }, 
        {
            "location": "/azure/#infrastructure-templates", 
            "text": "After your AZURE account is linked to Cloudbreak you can start creating resource templates that describe your clusters' \ninfrastructure:   templates  networks  security groups   When you create one of the above resources,  Cloudbreak does not make any requests to AZURE. Resources are only created\n on AZURE after the  create cluster  button has pushed.  These templates are saved to Cloudbreak's database and can be \n reused with multiple clusters to describe the infrastructure.", 
            "title": "Infrastructure Templates"
        }, 
        {
            "location": "/azure/#templates", 
            "text": "Templates describe the  instances of your cluster  - the instance type and the attached volumes. A typical setup is\n to combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple\n large disks to the datanodes or have memory optimized instances for Spark nodes.  The instance templates can be configured on the  manage templates  panel on the Cloudbreak Dashboard.  The  Volume Type  describes the  Storage Account type  which will be used for the attached disks. The only constraint is that the  Premium storage  can only be used\nfor  DS  instance types. For more details about the premium storage read  this .  If  Public in account is checked all the users belonging to your account will be able to use this resource to create \nclusters, but cannot delete it", 
            "title": "Templates"
        }, 
        {
            "location": "/azure/#networks", 
            "text": "Your clusters can be created in their own  networks  or in one of your already existing one. The subnet's IP range must be defined in \nthe  Subnet (CIDR)  field using the general CIDR notation.  Default AZURE Network  If you don't want to create or use your custom network, you can use the  default-azure-network  for all your \nCloudbreak clusters. It will create a new network with a  10.0.0.0/16  subnet every time a cluster is created.  Custom AZURE Network  If you'd like to deploy a cluster to a custom network you'll have to  create a new network  template on the  manage \nnetworks  panel.  You have the following options:   Create a new virtual network and a new subnet :  Every time a cluster is created with this kind of network setup a new virtual network and a new subnet with the specified IP range will be created for the instances on Azure.  Use an existing subnet in an existing virtual network : \nUse this kind of network setup if you have an existing virtual network with one or more subnets on Azure and you'd like to start the instances of a cluster in one of those subnets. \nIn this case you can define the  Subnet Identifier  and the  Virtual Network Identifier  and the  Resource Group Identifier  of your network.   The  Resource Group Identifier  identifies the resource group which contains your existing virtual network.   The  Virtual Network Identifier  and the  Subnet Identifier  will tell Cloudbreak which network and subnet to use to launch the new instances.  If you enable  Don't create public IPs , then Cloudbreak will not assign public ip address to the VMs. Please make sure that Cloudbreak can access the launched instances and the instances can reach the internet.  If you enable  Don't create new firewall rules , then Cloudbreak will not create security groups. Make sure that the created instances in the subnet can reach each other.      IMPORTANT:  In case of existing subnet make sure you have enough room within your network space for the new instances. The \nprovided subnet CIDR will be ignored, but the existing subnet's CIDR range will be used. The security group behavior will be changed in this case as well\ndescribed in the security group section below.   If  Public in account  is checked all the users belonging to your account will be able to use this network template \nto create clusters, but cannot delete it.   NOTE:  The new networks are created on AZURE only after the the cluster provisioning starts with the selected \nnetwork template.    Full size  here .", 
            "title": "Networks"
        }, 
        {
            "location": "/azure/#security-groups", 
            "text": "Security group templates are very similar to the  security groups on Azure . They describe the allowed inbound traffic to the instances in the cluster. \nCurrently only one security group template can be selected for a Cloudbreak cluster and all the instances have a \npublic IP address so all the instances in the cluster will belong to the same security group.\nThis may change in a later release.  Default Security Group  You can also use the two pre-defined security groups in Cloudbreak.  only-ssh-and-ssl:  all ports are locked down except for SSH and the selected Ambari Server HTTPS (you can't access Hadoop services \noutside of the virtual network):   SSH (22)  HTTPS (443)   Custom Security Group  You can define your own security group by adding all the ports, protocols and CIDR range you'd like to use. The rules\n defined here doesn't need to contain the internal rules, those are automatically added by Cloudbreak to the security\n  group on Azure.  Hadoop services :  Ambari (8080)  Consul (8500)  NN (50070)  RM Web (8088)  Scheduler (8030RM)  IPC (8050RM)  Job history server (19888)  HBase master (60000)  HBase master web (60010)  HBase RS (16020)  HBase RS info (60030)  Falcon (15000)  Storm (8744)  Hive metastore (9083)  Hive server (10000)  Hive server HTTP (10001)  Accumulo master (9999)  Accumulo Tserver (9997)  Atlas (21000)  KNOX (8443)  Oozie (11000)  Spark HS (18080)  NM Web (8042)  Zeppelin WebSocket (9996)  Zeppelin UI (9995)  Kibana (3080)\n* Elasticsearch (9200)   IMPORTANT  443, 9443, and 22 ports needs to be there in every security group otherwise Cloudbreak won't be able to communicate with the provisioned cluster.   If  Public in account  is checked all the users belonging to your account will be able to use this security group \ntemplate to create clusters, but cannot delete it.   NOTE:  The security groups are created on Azure only after the cluster provisioning starts with the selected \nsecurity group template.  IMPORTANT:  If you use and existing virtual network and subnet the selected security group will only be applied to the selected Ambari Server node due to the lack of\ncapability to attach multiple security groups to an existing subnet. If you'd like to open ports for Hadoop you must do it on your existing security group.    Full size  here . /sub", 
            "title": "Security groups"
        }, 
        {
            "location": "/azure/#availability-sets-and-rack-awareness", 
            "text": "Availability sets  Azure implements the concept of  \u201cAvailability Sets\u201d  to support fault tolerance for VM's. This feature allows two or more VM's to be mapped to multiple fault domains. Fault domains define the group of virtual machines that share a common power source and network switch. VM's with different fault domains are guaranteed an SLA. This SLA includes guarantees that during OS Patching in Azure or during maintenance operations, at least one VM belonging to a different fault domain will be available.  Availability sets have either two or three Fault Domains, each sharing a common power source and network switch. When adding VM-s to an availability set, Azure automatically assigns each VM a Fault Domain.  In Cloudbreak UI, availability sets can be configured during cluster creation. First, you have to enable availability sets with the checkbox under  Configure Cluster  tab. Then you can add the desired availability sets by providing a name and the desired fault domain count (2 or 3).    Full size  here .  The sets defined here can be assigned to the hostgroups in  Choose Blueprint  tab. An availability set can be assigned to only one hostgroup so you should define as much availability set in advance as needed for your hostgroups. By default, there is no availability set selected. The assignment of fault domains is automated by Azure so there is no option in Cloudbreak.   IMPORTANT:  Single instances placed in an Availability Set are not subject to Azure\u2019s SLA, and you won\u2019t receive warnings of planned maintenance events, so Availability Groups should only be used when there\u2019s a group of two or more application tier VMs.    Full size  here .  After the deployment is finished, the layout of the VM-s inside an availability set can be checked in Azure Portal. There are \"Availability set\" resources corresponding to the hostgroups inside the deployments's resource group.     Full size  here .  Rack awareness  Rack awareness is having the knowledge of Cluster topology or more specifically how the different data nodes are distributed across the racks of a Hadoop cluster. The importance of this knowledge relies on this assumption that co-located data nodes inside a specific rack will have more bandwidth and less latency whereas two data nodes in separate racks will have comparatively less bandwidth and higher latency.  The main purpose of Rack awareness are:   Increasing the availability of data block  Better cluster performance   HDFS replicates a data block into 3 replicas by default. In this configuration, 2 blocks stay rack local and one block is placed in a different rack. When building a Hadoop cluster on Azure there is no notion of a physical rack. However the fault domains are similar in the failure characteristics of a physical rack. Since electrical events affect a fault domain as an unit, it is important to assign the rack topology based on fault domain allocation.  You can view the rack assignment in Ambari, clicking on the Hosts menu item. If there was no availability set selected for the given host's hostgroup, it's rack remains set to \"default rack\".   Full size  here . /sub", 
            "title": "Availability sets and rack awareness"
        }, 
        {
            "location": "/azure/#defining-cluster-services", 
            "text": "", 
            "title": "Defining Cluster Services"
        }, 
        {
            "location": "/azure/#blueprints", 
            "text": "Blueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are  used by Ambari .  You can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file, URL (an  example blueprint ) or the \nwhole JSON can be written in the  JSON text  box.  The host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.   NOTE:  It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will \nfill that with a default value.   If  Public in account  is checked all the users belonging to your account will be able to use this blueprint to \ncreate clusters, but cannot delete or modify it.   Full size  here .  A blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications. \nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations...etc. that won't be applicable to the Cloudbreak cluster", 
            "title": "Blueprints"
        }, 
        {
            "location": "/azure/#cluster-deployment", 
            "text": "After all the cluster resources are configured you can deploy a new HDP cluster.  Here is a  basic flow for cluster creation on Cloudbreak Web UI :   Start by selecting a previously created Azure credential in the header.  Open  create cluster   Configure Cluster  tab   Fill out the new cluster  name  Cluster name must start with a lowercase alphabetic character then you can apply lowercase alphanumeric and\n   hyphens only (min 5, max 40 characters)    Select a  Region  where you like your cluster be provisioned  Click on the  Setup Network and Security  button  If  Public in account  is checked all the users belonging to your account will be able to see the created cluster on\n the UI, but cannot delete or modify it.     Setup Network and Security  tab   Select one of the networks  Click on the  Choose Blueprint  button  If  Enable security  is checked as well, Cloudbreak will install Key Distribution Center (KDC) and the cluster will\nbe Kerberized. See more about it in the  Kerberos  section of this documentation.     Choose Blueprint  tab   Select one of the blueprint  After you've selected a  Blueprint , you should be able to configure:  the templates  the securitygroups  the number of nodes for all of the host groups in the blueprint    You need to select where you want to install the Ambari server to. Only 1 host group can be selected.\n   If you want to install the Ambari server to a separate node, you need to extend your blueprint with a new host group\n   which contains only 1 service: HDFS_CLIENT and select this host group for the Ambari server. Note: this host group cannot be scaled so\n   it is not advised to select a 'slave' host group for this purpose.  Click on the  Add File System  button   Add File System  tab   Select one of the file system that fits your needs  If you've selected  WASB  you should configure:  Storage Account Name  Storage Account Access Key    If you've selected  ADLS , you should specify your preconfigured ADLS account name.      Click on the  Review and Launch  button  File system  is a mandatory configuration for Azure. You can read more about WASB and ADLS in the  File System Configuration section .     Review and Launch  tab   After the  create and start cluster  button has clicked Cloudbreak will start to create the cluster's resources on\n your Azure account.   Cloudbreak uses  Azure Resource Manager  to create the resources - you can check out the resources created by Cloudbreak\n on\nthe  Azure Portal Resource groups  page.  Full size  here .  Besides these you can check the progress on the Cloudbreak Web UI itself if you open the new cluster's  Event History .  Full size  here .  Advanced options  There are some advanced features when deploying a new cluster, these are the following:  Ambari Username  This user will be used as admin user in Ambari. You can log in using this username on the Ambari UI.  Ambari Password  The password associated with the Ambari username. This password will be also the default password for all required passwords which are not specified in the blueprint. E.g: hive DB password.  Minimum cluster size  The provisioning strategy in case the cloud provider cannot allocate all the requested nodes.  Validate blueprint  This is selected by default. Cloudbreak validates the Ambari blueprint in this case.  Custom Image  If you enable this, you can override the default image for provision.  Enable Availability sets  You can set up availability set support if enabled.  Shipyard enabled cluster  This is selected by default. Cloudbreak will start a  Shipyard  container which helps you to manage your containers.  Persistent Storage Name  This is  cbstore  by default. Cloudbreak will copy the image into a storage which is not deleting under the termination. When you starting a new cluster then the provisioning will be much faster because of the existing image.  Attached Storage Type  This is  single storage for all vm  by default. If are you using the default option then your whole cluster will by in one storage which could be a bottleneck in case of  Azure . If you are using the  separated storage for every vm  then we will deploy as much storage account as many node you have and in this case IOPS limit concern just for one node.  Config recommendation strategy  Strategy for how configuration recommendations will be applied. Recommended\nconfigurations gathered by the response of the stack advisor.   NEVER_APPLY                Configuration recommendations are ignored with this option.  ONLY_STACK_DEFAULTS_APPLY  Applies only on the default configurations for all included services.  ALWAYS_APPLY               Applies on all configuration properties.", 
            "title": "Cluster Deployment"
        }, 
        {
            "location": "/azure/#cluster-termination", 
            "text": "You can terminate running or stopped clusters with the  terminate  button in the cluster details.   IMPORTANT:  Always use Cloudbreak to terminate the cluster. If that fails for some reason, try to delete the \nAzure resource group first. Instances are started in an Auto Scaling Group so they may be restarted if you terminate an \ninstance manually!   Sometimes Cloudbreak cannot synchronize its state with the cluster state at the cloud provider and the cluster can't\n be terminated. In this case the  Forced termination  option can help to terminate the cluster at the Cloudbreak \n side.  If it has happened:   You should check the related resources at the Azure Portal  If it is needed you need to manually remove resources from there    Full size  here .", 
            "title": "Cluster Termination"
        }, 
        {
            "location": "/azure/#interactive-mode-cloudbreak-shell", 
            "text": "The goal with the Cloudbreak Shell (Cloudbreak CLI) was to provide an interactive command line tool which supports:   all functionality available through the REST API or Cloudbreak Web UI  makes possible complete automation of management task via scripts  context aware command availability  tab completion  required/optional parameter support  hint command to guide you on the usual path", 
            "title": "Interactive mode / Cloudbreak Shell"
        }, 
        {
            "location": "/azure/#start-cloudbreak-shell", 
            "text": "To start the Cloudbreak CLI use the following commands:   Open your  cloudbreak-deployment  directory if it is needed. For example:      cd cloudbreak-deployment   Start the  cbd  from here if it is needed      cbd start   In the root of your  cloudbreak-deployment  folder apply:      cbd util cloudbreak-shell   At the very first time it will take for a while, because of need to download all the necessary docker images.   This will launch the Cloudbreak shell inside a Docker container then it is ready to use.  Full size  here .   IMPORTANT You have to copy all your files into the  cbd  working directory, what you would like to use in shell.  For \nexample if your  cbd  working directory is  ~/cloudbreak-deployment  then copy your  blueprint JSON, public ssh key \nfile...etc.  to here. You can refer to these files with their names from the shell.", 
            "title": "Start Cloudbreak Shell"
        }, 
        {
            "location": "/azure/#autocomplete-and-hints", 
            "text": "Cloudbreak Shell helps you with  hint messages  from the very beginning, for example:  cloudbreak-shell hint\nHint: Add a blueprint with the 'blueprint create' command or select an existing one with 'blueprint select'\ncloudbreak-shell   Beyond this you can use the  autocompletion (double-TAB)  as well:  cloudbreak-shell credential create --\ncredential create --AWS          credential create --AZURE        credential create --EC2          credential create --GCP          credential create --OPENSTACK", 
            "title": "Autocomplete and Hints"
        }, 
        {
            "location": "/azure/#provisioning-via-cli", 
            "text": "", 
            "title": "Provisioning via CLI"
        }, 
        {
            "location": "/azure/#setting-up-azure-credential", 
            "text": "Cloudbreak works by connecting your Azure account through so called Credentials, and then uses these credentials to \ncreate resources on your behalf. Credentials can be configured with the following command for example:  credential create --AZURE --name my-azure-credential --description  sample credential  --subscriptionId \nyour-azure-subscription-id --tenantId your-azure-application-tenant-id --appId \nyour-azure-application-id --password YourApplicationPassword --sshKeyString  ssh-rsa AAAAB3***etc.    Cloudbreak is supporting simple rsa public key instead of X509 certificate file after 1.0.4 version  NOTE:  Cloudbreak  does not set your cloud user details  - we work around the concept of Access Control \nService (ACS). You should have already a valid Azure Subscription and Application. You can find further details  here .   Alternatives to provide  SSH Key :   you can upload your public key from an url:  \u2014sshKeyUrl    or you can add the path of your public key:  \u2014sshKeyPath   You can check whether the credential was created successfully  credential list  You can switch between your existing credentials  credential select --name my-azure-credential", 
            "title": "Setting up Azure Credential"
        }, 
        {
            "location": "/azure/#infrastructure-templates_1", 
            "text": "After your Azure account is linked to Cloudbreak you can start creating resource templates that describe your clusters' \ninfrastructure:   security groups  networks  templates   When you create one of the above resources,  Cloudbreak does not make any requests to Azure. Resources are only created\n on Azure after the  cluster create  has applied.  These templates are saved to Cloudbreak's database and can be \n reused with multiple clusters to describe the infrastructure.", 
            "title": "Infrastructure Templates"
        }, 
        {
            "location": "/azure/#templates_1", 
            "text": "Templates describe the  instances of your cluster  - the instance type and the attached volumes. A typical setup is\n to combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple\n large disks to the datanodes or have memory optimized instances for Spark nodes.  A template can be used repeatedly to create identical copies of the same stack (or to use as a foundation to start a \nnew stack). Templates can be configured with the following command for example:  template create --AZURE --name my-azure-template --description  sample description  --instanceType Standard_D4 --volumeSize 100 --volumeCount 2 --volumeType Standard_LRS  The  Volume Type  describes the  Storage Account type  which will be used for the attached disks. The only constraint is that the  Premium storage  can only be used\nfor  DS  instance types. For more details about the premium storage read  this .  Other available option here is  --publicInAccount . If it is true, all the users belonging to your account will be able\n to use this template to create clusters, but cannot delete it.  You can check whether the template was created successfully  template list", 
            "title": "Templates"
        }, 
        {
            "location": "/azure/#networks_1", 
            "text": "Your clusters can be created in their own  networks  or in one of your already existing one. If you choose an \nexisting network, it is possible to create a new subnet within the network. The subnet's IP range must be defined in \nthe  Subnet (CIDR)  field using the general CIDR notation.  Default AZURE Network  If you don't want to create or use your custom network, you can use the  default-azure-network  for all your \nCloudbreak clusters. It will create a new network with a  10.0.0.0/16  subnet and  10.0.0.0/8  address prefix every \ntime a cluster is created.  Custom AZURE Network  If you'd like to deploy a cluster to a custom network you'll have to apply the following command:  network create --AZURE --name my-azure-network --addressPrefix 192.168.123.123 --subnet 10.0.0.0/16   IMPORTANT:  Make sure the defined subnet and theirs address prefixes here doesn't overlap with any of your \nalready deployed subnet and its already used address prefix in the network, because the validation only happens\nafter the cluster creation \nstarts.  In case of existing subnet make sure you have enough room within your network space for the new instances. The \nprovided subnet CIDR will be ignored, but a proper CIDR range will be used.   You can check whether the network was created successfully  network list  --addressPrefix  This list will be appended to the current list of address prefixes.   The address prefixes in this list should not overlap between them.  The address prefixes in this list should not overlap with existing address prefixes in the network.   You can find more details about the AZURE Address Prefixes  here .  If  --publicInAccount  is true, all the users belonging to your account will be able to use this network template \nto create clusters, but cannot delete it.   NOTE:  The new networks are created on AZURE only after the the cluster provisioning starts with the selected \nnetwork template.", 
            "title": "Networks"
        }, 
        {
            "location": "/azure/#defining-cluster-services_1", 
            "text": "", 
            "title": "Defining Cluster Services"
        }, 
        {
            "location": "/azure/#blueprints_1", 
            "text": "Blueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are  used by Ambari .  You can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file or URL (an  example blueprint ).  The host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.   NOTE:  It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will fill that with a default value.   blueprint create --name my-blueprint --description  sample description  --file  the path of the blueprint   Other available options:  --url  the url of the blueprint  --publicInAccount  If it is true, all the users belonging to your account will be able to use this blueprint to create \nclusters, but cannot delete it.  You can check whether the blueprint was created successfully  blueprint list  A blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications. \nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations..etc. that won't be applicable to the Cloudbreak cluster.", 
            "title": "Blueprints"
        }, 
        {
            "location": "/azure/#metadata-show", 
            "text": "You can check the stack metadata with  stack metadata --name myawsstack --instancegroup master  Other available options:  --id  In this case you can select a stack with id.  --outputType  In this case you can modify the outputformat of the command (RAW or JSON).", 
            "title": "Metadata Show"
        }, 
        {
            "location": "/azure/#cluster-deployment_1", 
            "text": "After all the cluster resources are configured you can deploy a new HDP cluster. The following sub-sections show\nyou a  basic flow for cluster creation with Cloudbreak Shell .", 
            "title": "Cluster Deployment"
        }, 
        {
            "location": "/azure/#select-credential", 
            "text": "Select one of your previously created Azure credential:  credential select --name my-azure-credential", 
            "title": "Select Credential"
        }, 
        {
            "location": "/azure/#select-blueprint", 
            "text": "Select one of your previously created blueprint which fits your needs:  blueprint select --name multi-node-hdfs-yarn", 
            "title": "Select Blueprint"
        }, 
        {
            "location": "/azure/#configure-instance-groups", 
            "text": "You must configure instance groups before provisioning. An instance group define a group of nodes with a specified\ntemplate. Usually we create instance groups for host groups in the blueprint. For Ambari server only 1 host group can be specified.\nIf you want to install the Ambari server to a separate node, you need to extend your blueprint with a new host group\nwhich contains only 1 service: HDFS_CLIENT and select this host group for the Ambari server. Note: this host group cannot be scaled so\nit is not advised to select a 'slave' host group for this purpose.  instancegroup configure --instanceGroup master --nodecount 1 --templateName minviable-aws --securityGroupName all-services-port --ambariServer true\ninstancegroup configure --instanceGroup slave_1 --nodecount 1 --templateName minviable-aws --securityGroupName all-services-port --ambariServer false  Other available option:  --templateId  Id of the template", 
            "title": "Configure Instance Groups"
        }, 
        {
            "location": "/azure/#select-network", 
            "text": "Select one of your previously created network which fits your needs or a default one:  network select --name default-azure-network", 
            "title": "Select Network"
        }, 
        {
            "location": "/azure/#create-stack-create-cloud-infrastructure", 
            "text": "Stack means the running cloud infrastructure that is created based on the instance groups configured earlier\n( credential ,  instancegroups ,  network ,  securitygroup ). Same as in case of the API or UI the new cluster will\nuse your templates and by using Azure ARM will launch your cloud stack. Use the following command to create a\nstack to be used with your Hadoop cluster:  stack create --AZURE --name myazurestack --region  North Europe   The infrastructure is created asynchronously, the state of the stack can be checked with the stack  show command . If\nit reports AVAILABLE, it means that the virtual machines and the corresponding infrastructure is running at the cloud provider.  Other available option is:  --wait  - in this case the create command will return only after the process has finished.  --persistentStorage  - This is  cbstore  by default. Cloudbreak will copy the image into a storage which is not deleting under the termination. When you starting a new cluster then the provisioning will be much faster because of the existing image.  --attachedStorageType  - This is  SINGLE  by default. If you are using the default option then your whole cluster will by in one storage which could be a bottleneck in case of  Azure . If you are using the  PER_VM  then we will deploy as much storage account as many node you have and in this case IOPS limit concern just for one node.", 
            "title": "Create Stack / Create Cloud Infrastructure**"
        }, 
        {
            "location": "/azure/#create-a-hadoop-cluster-cloud-provisioning", 
            "text": "You are almost done! One more command and your Hadoop cluster is starting!  Cloud provisioning is done once the\ncluster is up and running. The new cluster will use your selected blueprint and install your custom Hadoop cluster\nwith the selected components and services.  cluster create --description  my first cluster   Other available option is  --wait  - in this case the create command will return only after the process has finished.  You are done!  You have several opportunities to check the progress during the infrastructure creation then\nprovisioning:   Cloudbreak uses  ARM  to create the resources - you can check out the resources created by Cloudbreak on\n the Azure Portal Resource groups page.    Full size  here .   If stack then cluster creation have successfully done, you can check the Ambari Web UI. However you need to know the\nAmbari IP (for example:  http://23.101.60.49:8080 ):  You can get the IP from the CLI as a result ( ambariServerIp 23.101.60.49 ) of the following command:              cluster show   Full size  here .   Besides these you can check the entire progress and the Ambari IP as well on the Cloudbreak Web UI itself. Open the\nnew cluster's  details  and its  Event History  here.    Full size  here .", 
            "title": "Create a Hadoop Cluster / Cloud Provisioning"
        }, 
        {
            "location": "/azure/#stop-cluster", 
            "text": "You have the ability to  stop your existing stack then its cluster  if you want to suspend the work on it.  Select a stack for example with its name:  stack select --name my-stack  Other available option to define a stack is its  --id .  Every time you should stop the  cluster  first then the  stack . So apply following commands to stop the previously \nselected stack:  cluster stop\nstack stop", 
            "title": "Stop Cluster"
        }, 
        {
            "location": "/azure/#restart-cluster", 
            "text": "Select your stack that you would like to restart  after this you can apply:  stack start  After the stack has successfully restarted, you can  restart the related cluster as well :  cluster start", 
            "title": "Restart Cluster"
        }, 
        {
            "location": "/azure/#upscale-cluster", 
            "text": "If you need more instances to your infrastructure, you can  upscale your selected stack :  stack node --ADD --instanceGroup host_group_slave_1 --adjustment 6  Other available option is  --withClusterUpScale  - this indicates also a cluster upscale after the stack upscale. You\n can upscale the related cluster separately if you want to do this:  cluster node --ADD --hostgroup host_group_slave_1 --adjustment 6", 
            "title": "Upscale Cluster"
        }, 
        {
            "location": "/azure/#downscale-cluster", 
            "text": "You also can reduce the number of instances in your infrastructure.  After you selected your stack :  cluster node --REMOVE  --hostgroup host_group_slave_1 --adjustment -2  Other available option is  --withStackDownScale  - this indicates also a stack downscale after the cluster downscale.\n You can downscale the related stack separately if you want to do this:  stack node --REMOVE  --instanceGroup host_group_slave_1 --adjustment -2", 
            "title": "Downscale Cluster"
        }, 
        {
            "location": "/azure/#cluster-termination_1", 
            "text": "You can terminate running or stopped clusters with  stack delete --name myawsstack  Other available option is  --wait  - in this case the terminate command will return only after the process has finished.    IMPORTANT:  Always use Cloudbreak to terminate the cluster. If that fails for some reason, try to delete the \nCloudFormation stack first. Instances are started in an Auto Scaling Group so they may be restarted if you terminate an instance manually!   Sometimes Cloudbreak cannot synchronize its state with the cluster state at the cloud provider and the cluster can't\n be terminated. In this case the  Forced termination  option on the Cloudbreak Web UI can help to terminate the cluster\n  at the Cloudbreak side.  If it has happened:   You should check the related resources at the AWS CloudFormation  If it is needed you need to manually remove resources from there", 
            "title": "Cluster Termination"
        }, 
        {
            "location": "/azure/#silent-mode", 
            "text": "With Cloudbreak Shell you can execute script files as well. A script file contains shell commands and can \nbe executed with the  script  cloudbreak shell command  script  your script file   or with the  cbd util cloudbreak-shell-quiet  command  cbd util cloudbreak-shell-quiet   example.sh   IMPORTANT:  You have to copy all your files into the  cbd  working directory, what you would like to use in shell.\n For example if your  cbd  working directory is ~/cloudbreak-deployment then copy your script file to here.", 
            "title": "Silent Mode"
        }, 
        {
            "location": "/azure/#example", 
            "text": "The following example creates a hadoop cluster with  hdp-small-default  blueprint on Standard_D3 instances with \n2X100G attached disks on  default-azure-network  network using  all-services-port  security group. You should copy \nyour ssh public key file into your  cbd  working directory with name  id_rsa.pub  and paste your Azure credentials in \nthe parts with  ...  highlight.  credential create --AZURE --description  credential description  --name myazurecredential --subscriptionId  your Azure subscription id  --appId  your Azure application id  --tenantId  your tenant id  --password  your Azure application password  --sshKeyPath id_rsa.pub\ncredential select --name myazurecredential\ntemplate create --AZURE --name azuretemplate --description azure-template --instanceType Standard_D3 --volumeSize 100 \n--volumeCount 2\nblueprint select --name hdp-small-default\ninstancegroup configure --instanceGroup host_group_master_1 --nodecount 1 --templateName azuretemplate --securityGroupName all-services-port --ambariServer true\ninstancegroup configure --instanceGroup host_group_master_2 --nodecount 1 --templateName azuretemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_master_3 --nodecount 1 --templateName azuretemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_client_1  --nodecount 1 --templateName azuretemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_slave_1 --nodecount 3 --templateName azuretemplate --securityGroupName all-services-port --ambariServer false\nnetwork select --name default-azure-network\nstack create --AZURE --name my-first-stack --region  West US  --wait true\ncluster create --description  My first cluster  --wait true  Congratulations!  Your cluster should now be up and running on this way as well. To learn more about Cloudbreak and \nprovisioning, we have some  interesting insights  for you.", 
            "title": "Example"
        }, 
        {
            "location": "/gcp/", 
            "text": "Google Cloud Images\n\n\nWe have pre-built Cloudbreak Deployer cloud image for Google Cloud Platform (GCP). You can launch the latest Cloudbreak Deployer image at the \nGoogle Developers Console\n.\n\n\n\n\nAs an alternative to using the pre-built cloud images for GCP, you can install Cloudbreak Deployer on your own VM. For more information, see the \ninstallation instructions\n.\n\n\n\n\nPrerequisites\n\n\nPorts\n\n\nMake sure that you have opened the following ports on your \nSecurity Group\n:\n\n\n\n\nSSH (22)\n\n\nCloudbreak (443)\n\n\n\n\nCloudbreak Deployer GCP Image Details\n\n\nImport Cloudbreak Deployer Image\n\n\nImport the latest Cloudbreak Deployer image on the \nGoogle Developers Console\n with the help\n of the \nGoogle Cloud Shell\n.\n\n\nTo open the Google Cloud Shell, click on the \nActivate Google Cloud Shell\n icon in the top right corner of the page:\n\n\n\n\nFull size \nhere\n.\n\n\n\n\nFull size \nhere\n.\n\n\nNext, create your own Cloudbreak Deployer instance from the imported image on the Google Developers Console.\n\n\n\n\nImages are global resources, so you can use them across zones and projects.\n\n\n\n\nVM Requirements\n\n\nWhen selecting an instance type, consider these minimum and recomended requirements:  \n\n\n\n\n4GB RAM, 10GB disk, 2 cores\n\n\nThe minimum instance type suitable for Cloudbreak is \nn1-standard-2\n\n\n\n\nTo learn about all requirements, see \nSystem Requirements\n\n\nCloudbreak Deployer Setup on Google\n\n\nBefore getting started with Cloudbreak Deployer, you should know that:\n\n\n\n\nThe default SSH username for the GCP instances is \ncloudbreak\n.\n\n\nCloudbreak Deployer location on your VM is \n/var/lib/cloudbreak-deployment\n. This is the \ncbd\n root folder.\n\n\nYou must execute all \ncbd\n actions from the \ncbd\n root folder.\n\n\n\n\nIn the previous step, you should have already set up a VM with Cloudbreak Doployer either \nthe GCP Cloud Images\n or by \ninstalling the Cloudbreak Deployer\n manually on your own VM.\n\n\nThere are several ways to \nconnect to the previously created \ncbd\n VM\n.\n\n\nCloudbreak Deployment Directory\n\n\nTo navigate to the \ncloudbreak-deployment\n directory, use:\n\n\ncd /var/lib/cloudbreak-deployment\n\n\n\n\nThis directory contains configuration files and the supporting binaries for Cloudbreak Deployer.\n\n\nInitialize Your Profile\n\n\nFirst, initialize deployer by creating a \nProfile\n file with the following content:\n\n\nexport UAA_DEFAULT_SECRET='[SECRET]'\nexport UAA_DEFAULT_USER_PW='[PASSWORD]'\n\n\n\n\nBy default the \ncbd\n tool tries to guess \nPUBLIC_IP\n to bind Cloudbreak UI to it. But if \ncbd\n cannot get the IP address during the initialization, set the appropriate value also in your \nProfile\n.\n\n\nStart Cloudbreak Deployer\n\n\nTo start the Cloudbreak application, use the following command:\n\n\ncbd start\n\n\n\n\nThis will start all the Docker containers and initialize the application.\n\n\n\n\nThe first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.\n\n\n\n\nThe \ncbd start\n command includes the \ncbd generate\n command which applies the following steps:\n\n\n\n\ncreates the \ndocker-compose.yml\n file that describes the configuration of all the Docker containers needed for the Cloudbreak deployment.\n\n\ncreates the \nuaa.yml\n file that holds the configuration of the identity server used to authenticate users to Cloudbreak.\n\n\n\n\nValidate that Cloudbreak Deployer Has Started\n\n\nAfter the \ncbd start\n command finishes, check the following:\n\n\n\n\nPre-installed Cloudbreak Deployer version and health:\n\n\n\n\n   cbd doctor\n\n\n\n\n\n\nIf you need to run \ncbd update\n, refer to \nCloudbreak Deployer Update\n. Most of the \ncbd\n commands require \nroot\n permissions.\n\n\n\n\n\n\nStarted Cloudbreak Application logs:\n\n\n\n\n   cbd logs cloudbreak\n\n\n\n\n\n\nYou should see a line like this in the log: \nStarted CloudbreakApplication in 36.823 seconds\n. Cloudbreak normally takes less than a minute to start.\n\n\n\n\nCluster Provisioning Prerequisites\n\n\nCreating a Google Cloud Service Account\n\n\nFollow the \ninstructions\n in Google Cloud's documentation to create a \nService account\n and \nGenerate a new P12 key\n.\n\n\nMake sure that at API level (\nAPIs and auth\n menu) you have enabled:\n\n\n\n\nGoogle Compute Engine\n\n\nGoogle Compute Engine Instance Group Manager API\n\n\nGoogle Compute Engine Instance Groups API\n\n\nBigQuery API\n\n\nGoogle Cloud Deployment Manager API\n\n\nGoogle Cloud DNS API\n\n\nGoogle Cloud SQL\n\n\nGoogle Cloud Storage\n\n\nGoogle Cloud Storage JSON API\n\n\n\n\n\n\nIf you have enabled every API then you have to wait about \n10 minutes\n for the provider.\n\n\n\n\nWhen creating GCP credentials \nin Cloudbreak you will have to provide the email address of your \nService Account\n \n(from the Service accounts page of your Google Cloud Platform Permissions) and the \nProject ID\n (from the Dashboard \nof your Google Cloud Platform Home) where the service account is created.\n You'll also have to \nupload the \ngenerated P12 file and provide an OpenSSH formatted public key\n that will be used as an SSH key.\n\n\nGenerate a New SSH Key\n\n\nAll the instances created by Cloudbreak are configured to allow key-based SSH,\nso you'll need to provide an SSH public key that can be used later to SSH onto the instances in the clusters you'll create with Cloudbreak.\nYou can use one of your existing keys or you can generate a new one.\n\n\nTo generate a new SSH keypair:\n\n\nssh-keygen -t rsa -b 4096 -C \nyour_email@example.com\n\n# Creates a new ssh key, using the provided email as a label\n# Generating public/private rsa key pair.\n\n\n\n\n# Enter file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]\nYou'll be asked to enter a passphrase, but you can leave it empty.\n\n# Enter passphrase (empty for no passphrase): [Type a passphrase]\n# Enter same passphrase again: [Type passphrase again]\n\n\n\n\nAfter you enter a passphrase the keypair is generated. The output should look something like below. \n\n\n# Your identification has been saved in /Users/you/.ssh/id_rsa.\n# Your public key has been saved in /Users/you/.ssh/id_rsa.pub.\n# The key fingerprint is:\n# 01:0f:f4:3b:ca:85:sd:17:sd:7d:sd:68:9d:sd:a2:sd your_email@example.com\n\n\n\n\nLater you'll need to pass the \n.pub\n file's contents to Cloudbreak and use the private part to SSH to the instances\n\n\nCluster Provisioning via Browser\n\n\nYou can log into the Cloudbreak application at \nhttps://\nPUBLIC_IP\n.\n\n\nThe main goal of the Cloudbreak UI is to easily create clusters on your own cloud provider account.\nThis description details the GCP setup - if you'd like to use a different cloud provider check out its manual.\n\n\nThis document explains the four steps that need to be followed to create Cloudbreak clusters from the UI:\n\n\n\n\nconnect your GCP account with Cloudbreak\n\n\ncreate some template resources on the UI that describe the infrastructure of your clusters\n\n\ncreate a blueprint that describes the HDP services in your clusters\n\n\nlaunch the cluster itself based on these template resources\n\n\n\n\n\n\nIMPORTANT:\n Make sure that you have sufficient qouta (CPU, network, etc) for the requested cluster size.\n\n\n\n\nSetting up GCP Credentials\n\n\nCloudbreak works by connecting your GCP account through so called \nCredentials\n, and then uses these credentials to \ncreate resources on your behalf. The credentials can be configured on the \nmanage credentials\n panel on the \nCloudbreak Dashboard.\n\n\nTo create a new GCP credential follow these steps:\n\n\n\n\nFill out the new credential \nName\n\n\nOnly alphanumeric and lowercase characters (min 5, max 100 characters) can be applied\n\n\n\n\n\n\nCopy your GCP project ID to the \nProject Id\n field\n\n\nCopy your GCP Service Account email address to the \nService Account Email Address\n field\n\n\nUpload your GCP Service Account private key (generated \np12 Key\n) to the \nService Account Private (p12) Key\n field\n\n\nCopy your SSH public key to the \nSSH public key\n field\n\n\nThe SSH public key must be in OpenSSH format and it's private keypair can be used later to \nSSH onto every instance\n of every cluster you'll create with this credential.\n\n\nThe \nSSH username\n for the GCP instances is \ncloudbreak\n.\n\n\n\n\n\n\n\n\n\n\nAny other parameter is optional here.\n\n\nPublic in account\n means that all the users belonging to your account will be able to use this credential to create \nclusters, but cannot delete it.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nInfrastructure Templates\n\n\nAfter your GCP account is linked to Cloudbreak you can start creating resource templates that describe your clusters'\ninfrastructure:\n\n\n\n\ntemplates\n\n\nnetworks\n\n\nsecurity groups\n\n\n\n\nWhen you create one of the above resources, \nCloudbreak does not make any requests to GCP. Resources are only created\non GCP after the \ncreate cluster\n button has pushed.\n These templates are saved to Cloudbreak's database and can be\nreused with multiple clusters to describe the infrastructure.\n\n\nTemplates\n\n\nTemplates describe the \ninstances of your cluster\n - the instance type and the attached volumes. A typical setup is\n to combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple\n large disks to the datanodes or have memory optimized instances for Spark nodes.\n\n\nThe instance templates can be configured on the \nmanage templates\n panel on the Cloudbreak Dashboard.\n\n\nIf \nPreemptible\n is checked then the template will be \npreemptible\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to use this resource to create clusters, but cannot delete it.\n\n\nNetworks\n\n\nYour clusters can be created in their own \nnetworks\n or in one of your already existing one. If you choose an \nexisting network, it is possible to create a new subnet within the network. The subnet's IP range must be defined in \nthe \nSubnet (CIDR)\n field using the general CIDR notation. You can read more about \nGCP Networks\n and \nSubnet \nnetworks\n.\n\n\nDefault GCP Network\n\n\nIf you don't want to create or use your custom network, you can use the \ndefault-gcp-network\n for all your \nCloudbreak clusters. It will create a new network with a \n10.0.0.0/16\n subnet every time a cluster is created.\n\n\nCustom GCP Network\n\n\nIf you'd like to deploy a cluster to a custom network you'll have to \ncreate a new network\n template on the \nmanage \nnetworks\n panel.\n\n\nYou have the following options:\n\n\n\n\nCreate a new virtual network and a new subnet\n: Every time a cluster is created with this kind of network setup a new virtual network and a new subnet with the specified IP range will be created for the instances on Google Cloud.\n\n\nCreate a new subnet in an existing virtual network\n: Use this kind of network setup if you already have a virtual network on Google Cloud where you'd like to put the Cloudbreak created cluster but you'd like to have a separate subnet for it.\n\n\nUse an existing subnet in an existing virtual network\n: Use this kind of network setup if you have an existing virtual network with one or more subnets on Google Cloud and you'd like to start the instances of a cluster in one of those subnets. \nImportant constraints of the following parameters:\n\n\nDon't create public IPs\n: Please make sure that Cloudbreak can access the launched instances and the instances can reach the internet\n\n\nDon't create new firewall rules\n: Please make sure that the created instances in the subnet can reach each other (open every port in the subnet)\n\n\n\n\n\n\nUse a legacy network without subnets\n: Use this kind of network setup if you have a legacy virtual network on Google Cloud that doesn't have subnet support and you'd like to start instances in that virtual network directly.\n\n\n\n\n\n\nIMPORTANT:\n Please make sure the defined subnet here doesn't overlap with any of your already deployed subnet in the\n network, because the validation only happens after the cluster creation starts.\n\n\nIn case of existing subnet make sure you have enough room within your network space for the new instances. The \nprovided subnet CIDR will be ignored, but a proper CIDR range will be used.\n\n\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to use this network template \nto create clusters, but cannot delete it.\n\n\n\n\nNOTE:\n The new networks are created on GCP only after the the cluster provisioning starts with the selected \nnetwork template.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nSecurity Groups\n\n\nSecurity group templates are very similar to the \nFirewalls on GCP\n. \nThey describe the allowed inbound traffic \nto the instances in the cluster.\n Currently only one security group template can be selected for a Cloudbreak cluster \nand all the instances have a public IP address so all the instances in the cluster will belong to the same security \ngroup. This may change in a later release.\n\n\nDefault Security Group\n\n\nYou can also use the two pre-defined security groups in Cloudbreak.\n\n\nonly-ssh-and-ssl:\n all ports are locked down except for SSH and the selected Ambari Server HTTPS (you can't access Hadoop services \noutside of the virtual network):\n\n\n\n\nSSH (22)\n\n\nHTTPS (443)\n\n\n\n\nCustom Security Group\n\n\nYou can define your own security group by adding all the ports, protocols and CIDR range you'd like to use. The rules\n defined here doesn't need to contain the internal rules, those are automatically added by Cloudbreak to the security\n  group on GCP.\n\n\nHadoop services :\n\n Ambari (8080)\n\n Consul (8500)\n\n NN (50070)\n\n RM Web (8088)\n\n Scheduler (8030RM)\n\n IPC (8050RM)\n\n Job history server (19888)\n\n HBase master (60000)\n\n HBase master web (60010)\n\n HBase RS (16020)\n\n HBase RS info (60030)\n\n Falcon (15000)\n\n Storm (8744)\n\n Hive metastore (9083)\n\n Hive server (10000)\n\n Hive server HTTP (10001)\n\n Accumulo master (9999)\n\n Accumulo Tserver (9997)\n\n Atlas (21000)\n\n KNOX (8443)\n\n Oozie (11000)\n\n Spark HS (18080)\n\n NM Web (8042)\n\n Zeppelin WebSocket (9996)\n\n Zeppelin UI (9995)\n\n Kibana (3080)\n* Elasticsearch (9200)\n\n\n\n\nIMPORTANT\n 443, 9443, and 22 ports needs to be there in every security group otherwise Cloudbreak won't be able to communicate with the provisioned cluster.\n\n\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to use this security group \ntemplate to create clusters, but cannot delete it.\n\n\n\n\nNOTE:\n The security groups are created on GCP only after the cluster provisioning starts with the selected \nsecurity group template.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nDefining Cluster Services\n\n\nBlueprints\n\n\nBlueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are \nused by Ambari\n.\n\n\nYou can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file, URL (an \nexample blueprint\n) or the \nwhole JSON can be written in the \nJSON text\n box.\n\n\nThe host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.\n\n\n\n\nNOTE:\n It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will \nfill that with a default value.\n\n\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to use this blueprint to \ncreate clusters, but cannot delete or modify it.\n\n\n\n\nFull size \nhere\n.\n\n\nA blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications.\n\nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations...etc. that won't be applicable to the Cloudbreak cluster\n\n\nCluster Deployment\n\n\nAfter all the cluster resources are configured you can deploy a new HDP cluster.\n\n\nHere is a \nbasic flow for cluster creation on Cloudbreak Web UI\n:\n\n\n\n\nStart by selecting a previously created GCP credential in the header.\n\n\nOpen \ncreate cluster\n\n\n\n\nConfigure Cluster\n tab\n\n\n\n\nFill out the new cluster \nname\n\n\nCluster name must start with a lowercase alphabetic character then you can apply lowercase alphanumeric and \n   hyphens only (min 5, max 40 characters)\n\n\n\n\n\n\nSelect a \nRegion\n where you like your cluster be provisioned\n\n\nClick on the \nSetup Network and Security\n button\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to see the created cluster on\n the UI, but cannot delete or modify it.\n\n\n\n\n\n\n\n\nSetup Network and Security\n tab\n\n\n\n\nSelect one of the security groups\n\n\nClick on the \nChoose Blueprint\n button\n\n\nIf \nEnable security\n is checked as well, Cloudbreak will install Key Distribution Center (KDC) and the cluster will \nbe Kerberized. See more about it in the \nKerberos\n section of this documentation.\n\n\n\n\n\n\n\n\nChoose Blueprint\n tab\n\n\n\n\nSelect one of the blueprint\n\n\nAfter you've selected a \nBlueprint\n, you should be able to configure:\n\n\nthe templates\n\n\nthe securitygroups\n\n\nthe number of nodes for all of the host groups in the blueprint\n\n\n\n\n\n\nYou need to select where you want to install the Ambari server to. Only 1 host group can be selected.\n   If you want to install the Ambari server to a separate node, you need to extend your blueprint with a new host group\n   which contains only 1 service: HDFS_CLIENT and select this host group for the Ambari server. Note: this host group cannot be scaled so \n   it is not advised to select a 'slave' host group for this purpose.\n\n\nClick on the \nAdd File System\n button\n\n\n\n\nAdd File System\n tab\n\n\n\n\nSelect one of the file system that fits your needs\n\n\nAfter you've selected \nGCS file system\n, you should configure:\n\n\nDefault Bucket Name\n\n\n\n\n\n\nClick on the \nReview and Launch\n button\n\n\nYou can read more about \nGCS File System\n and \nBucket Naming\n in GCP \nDocumentation.\n\n\n\n\n\n\n\n\nReview and Launch\n tab\n\n\n\n\nAfter the \ncreate and start cluster\n button has clicked Cloudbreak will start to create the cluster's resources on \n your GCP account.\n\n\n\n\nCloudbreak uses \nGoogle Cloud Platform\n to create the resources - you can check out the resources created by Cloudbreak\n on the \nCompute Engine\n page of the \nGoogle Compute Platform\n.\n\n\n\nFull size \nhere\n.\n\n\nBesides these you can check the progress on the Cloudbreak Web UI itself if you open the new cluster's \nEvent History\n.\n\n\n\nFull size \nhere\n.\n\n\nAdvanced Options\n\n\nThere are some advanced features when deploying a new cluster, these are the following:\n\n\nAmbari Username\n This user will be used as admin user in Ambari. You can log in using this username on the Ambari UI.\n\n\nAmbari Password\n The password associated with the Ambari username. This password will be also the default password for all required passwords which are not specified in the blueprint. E.g: hive DB password.\n\n\nAvailability Zone\n You can restrict the instances to a \nspecific availability zone\n. It may be useful if you're using\n reserved instances.\n\n\nMinimum cluster size\n The provisioning strategy in case the cloud provider cannot allocate all the requested nodes.\n\n\nValidate blueprint\n This is selected by default. Cloudbreak validates the Ambari blueprint in this case.\n\n\nCustom Image\n If you enable this, you can override the default image for provision.\n\n\nShipyard enabled cluster\n This is selected by default. Cloudbreak will start a \nShipyard\n container which helps you to manage your containers.\n\n\nConfig recommendation strategy\n Strategy for how configuration recommendations will be applied. Recommended \nconfigurations gathered by the response of the stack advisor. \n\n\n\n\nNEVER_APPLY\n               Configuration recommendations are ignored with this option.\n\n\nONLY_STACK_DEFAULTS_APPLY\n Applies only on the default configurations for all included services.\n\n\nALWAYS_APPLY\n              Applies on all configuration properties.\n\n\n\n\nCluster Termination\n\n\nYou can terminate running or stopped clusters with the \nterminate\n button in the cluster details.\n\n\n\n\nIMPORTANT:\n Always use Cloudbreak to terminate the cluster. If that fails for some reason, try to delete the \nGCP instances first. Instances are started in an Auto Scaling Group so they may be restarted if you terminate an \ninstance manually!\n\n\n\n\nSometimes Cloudbreak cannot synchronize its state with the cluster state at the cloud provider and the cluster can't\n be terminated. In this case the \nForced termination\n option can help to terminate the cluster at the Cloudbreak \n side. \nIf it has happened:\n\n\n\n\nYou should check the related resources at the Google Cloud Platform\n\n\nIf it is needed you need to manually remove resources from there\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nInteractive mode / Cloudbreak Shell\n\n\nThe goal with the Cloudbreak Shell (Cloudbreak CLI) was to provide an interactive command line tool which supports:\n\n\n\n\nall functionality available through the REST API or Cloudbreak Web UI\n\n\nmakes possible complete automation of management task via scripts\n\n\ncontext aware command availability\n\n\ntab completion\n\n\nrequired/optional parameter support\n\n\nhint command to guide you on the usual path\n\n\n\n\nStart Cloudbreak Shell\n\n\nTo start the Cloudbreak CLI use the following commands:\n\n\n\n\nOpen your \ncloudbreak-deployment\n directory if it is needed. For example:\n\n\n\n\n   cd cloudbreak-deployment\n\n\n\n\n\n\nStart the \ncbd\n from here if it is needed\n\n\n\n\n   cbd start\n\n\n\n\n\n\nIn the root of your \ncloudbreak-deployment\n folder apply:\n\n\n\n\n   cbd util cloudbreak-shell\n\n\n\n\n\n\nAt the very first time it will take for a while, because of need to download all the necessary docker images.\n\n\n\n\nThis will launch the Cloudbreak shell inside a Docker container then it is ready to use.\n\n\n\nFull size \nhere\n.\n\n\n\n\nIMPORTANT You have to copy all your files into the \ncbd\n working directory, what you would like to use in shell.\n For \nexample if your \ncbd\n working directory is \n~/cloudbreak-deployment\n then copy your \nblueprint JSON, public ssh key \nfile...etc.\n to here. You can refer to these files with their names from the shell.\n\n\n\n\nAutocomplete and Hints\n\n\nCloudbreak Shell helps you with \nhint messages\n from the very beginning, for example:\n\n\ncloudbreak-shell\nhint\nHint: Add a blueprint with the 'blueprint create' command or select an existing one with 'blueprint select'\ncloudbreak-shell\n\n\n\n\n\nBeyond this you can use the \nautocompletion (double-TAB)\n as well:\n\n\ncloudbreak-shell\ncredential create --\ncredential create --AWS          credential create --AZURE        credential create --EC2          credential create --GCP          credential create --OPENSTACK\n\n\n\n\nCluster Provisioning via CLI\n\n\nSetting up GCP Credential\n\n\nCloudbreak works by connecting your GCP account through so called Credentials, and then uses these credentials to \ncreate resources on your behalf. Credentials can be configured with the following command for example:\n\n\ncredential create --GCP --description \nsample description\n --name my-gcp-credential --projectId \nyour gcp projectid\n \n--serviceAccountId \nyour GCP service account mail address\n --serviceAccountPrivateKeyPath /files/mykey.p12 \n--sshKeyString \nssh-rsa AAAAB3***etc.\n\n\n\n\n\n\n\nNOTE:\n Cloudbreak \ndoes not set your cloud user details\n - we work around the concept of GCP Service \nAccount Credentials. You should have already a valid GCP service account. You can find further details \nhere\n.\n\n\n\n\nAlternatives to provide \nSSH Key\n:\n\n\n\n\nyou can upload your public key from an url: \n\u2014sshKeyUrl\n \n\n\nor you can add the path of your public key: \n\u2014sshKeyPath\n\n\n\n\nYou can check whether the credential was created successfully\n\n\ncredential list\n\n\n\n\nYou can switch between your existing credentials\n\n\ncredential select --name my-gcp-credential\n\n\n\n\nInfrastructure Templates\n\n\nAfter your GCP account is linked to Cloudbreak you can start creating resource templates that describe your clusters'\ninfrastructure:\n\n\n\n\nsecurity groups\n\n\nnetworks\n\n\ntemplates\n\n\n\n\nWhen you create one of the above resources, \nCloudbreak does not make any requests to GCP. Resources are only created\n on GCP after the \ncluster create\n has applied.\n These templates are saved to Cloudbreak's database and can be\n reused with multiple clusters to describe the infrastructure.\n\n\nTemplates\n\n\nTemplates describe the \ninstances of your cluster\n - the instance type and the attached volumes. A typical setup is\n to combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple\n large disks to the datanodes or have memory optimized instances for Spark nodes.\n\n\nA template can be used repeatedly to create identical copies of the same stack (or to use as a foundation to start a\nnew stack). Templates can be configured with the following command for example:\n\n\ntemplate create --GCP --name my-gcp-template --instanceType n1-standard-2 --volumeCount 2 --volumeSize 100\n\n\n\n\nOther available options here:\n\n\n--volumeType\n The default is \npd-standard\n (HDD), other allowed value is \npd-ssd\n\n(SSD).\n\n\n--preemptible\n is true, the template will be \npreemptible\n\n\n--publicInAccount\n is true, all the users belonging to your account will be able to use this template\nto create clusters, but cannot delete it.\n\n\nYou can check whether the template was created successfully\n\n\ntemplate list\n\n\n\n\nNetworks\n\n\nYour clusters can be created in their own \nnetworks\n or in one of your already existing one. If you choose an \nexisting network, it is possible to create a new subnet within the network. The subnet's IP range must be defined in \nthe \nSubnet (CIDR)\n field using the general CIDR notation. You can read more about \nGCP Networks\n and \nSubnet networks\n.\n\n\nDefault GCP Network\n\n\nIf you don't want to create or use your custom network, you can use the \ndefault-gcp-network\n for all your \nCloudbreak clusters. It will create a new network with a \n10.0.0.0/16\n subnet every time a cluster is created.\n\n\nCustom GCP Network\n\n\nIf you'd like to deploy a cluster to a custom network you'll have to apply the following command:\n\n\nnetwork create --GCP --name my-gcp-network --description \nsample description\n\n\n\n\n\nOther available options here:\n\n\n--networkId\n The Virtual Network Identifier of your network. This is an optional \nvalue and must be an ID of an existing GCP virtual network. If the identifier is provided, the subnet CIDR will be \nignored and the existing network's CIDR range will be used.\n\n\n--publicInAccount\n is true, all the users belonging to your account will be able to use this network template \nto create clusters, but cannot delete it.\n\n\n--subnet\n specified subnet which will be used by the cluster (will be created under the provisioning).\n\n\n--subnetId\n if you have an existing subnet in the network then you can specify the id here and the cluster will use that existing subnet.\n\n\n\n\nIMPORTANT:\n Make sure the defined subnet here doesn't overlap with any of your \nalready deployed subnet in the network, because the validation only happens after the cluster creation starts.\n\n\nIn case of existing subnet make sure you have enough room within your network space for the new instances. The \nprovided subnet CIDR will be ignored, but a proper CIDR range will be used.\n\n\n\n\nYou can check whether the network was created successfully\n\n\nnetwork list\n\n\n\n\n\n\nNOTE:\n The new networks are created on GCP only after the the cluster provisioning starts with the selected \nnetwork template.\n\n\n\n\nDefining Cluster Services\n\n\nBlueprints\n\n\nBlueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are \nused by Ambari\n.\n\n\nYou can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file or URL (an \nexample blueprint\n).\n\n\nThe host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.\n\n\n\n\nNOTE:\n It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will fill that with a default value.\n\n\n\n\nblueprint create --name my-blueprint --description \nsample description\n --file \nthe path of the blueprint\n\n\n\n\n\nOther available options:\n\n\n--url\n the url of the blueprint\n\n\n--publicInAccount\n If it is true, all the users belonging to your account will be able to use this blueprint to create \nclusters, but cannot delete it.\n\n\nYou can check whether the blueprint was created successfully\n\n\nblueprint list\n\n\n\n\nA blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications.\n\nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations..etc. that won't be applicable to the Cloudbreak cluster.\n\n\nMetadata Show\n\n\nYou can check the stack metadata with\n\n\nstack metadata --name myawsstack --instancegroup master\n\n\n\n\nOther available options:\n\n\n--id\n In this case you can select a stack with id.\n\n\n--outputType\n In this case you can modify the outputformat of the command (RAW or JSON). \n\n\nCluster Deployment\n\n\nAfter all the cluster resources are configured you can deploy a new HDP cluster. The following sub-sections show \nyou a \nbasic flow for cluster creation with Cloudbreak Shell\n.\n\n\nSelect Credential\n\n\nSelect one of your previously created GCP credential:\n\n\ncredential select --name my-gcp-credential\n\n\n\n\nSelect Blueprint\n\n\nSelect one of your previously created blueprint which fits your needs:\n\n\nblueprint select --name multi-node-hdfs-yarn\n\n\n\n\nConfigure Instance Groups\n\n\nYou must configure instance groups before provisioning. An instance group define a group of nodes with a specified \ntemplate. Usually we create instance groups for host groups in the blueprint. For Ambari server only 1 host group can be specified.\nIf you want to install the Ambari server to a separate node, you need to extend your blueprint with a new host group\nwhich contains only 1 service: HDFS_CLIENT and select this host group for the Ambari server. Note: this host group cannot be scaled so \nit is not advised to select a 'slave' host group for this purpose.\n\n\ninstancegroup configure --instanceGroup master --nodecount 1 --templateName minviable-aws --securityGroupName all-services-port --ambariServer true\ninstancegroup configure --instanceGroup slave_1 --nodecount 1 --templateName minviable-aws --securityGroupName all-services-port --ambariServer false\n\n\n\n\nOther available option:\n\n\n--templateId\n Id of the template\n\n\nSelect Network\n\n\nSelect one of your previously created network which fits your needs or a default one:\n\n\nnetwork select --name default-gcp-network\n\n\n\n\nCreate Stack / Create Cloud Infrastructure\n\n\nStack means the running cloud infrastructure that is created based on the instance groups configured earlier \n(\ncredential\n, \ninstancegroups\n, \nnetwork\n, \nsecuritygroup\n). Same as in case of the API or UI the new cluster will \nuse your templates and by using GCP will launch your cloud stack. Use the following command to create a \nstack to be used with your Hadoop cluster:\n\n\nstack create --GCP --name mygcpstack --region us-central1\n\n\n\n\nThe infrastructure is created asynchronously, the state of the stack can be checked with the stack \nshow command\n. If \nit reports AVAILABLE, it means that the virtual machines and the corresponding infrastructure is running at the cloud provider.\n\n\nOther available option is:\n\n\n--wait\n - in this case the create command will return only after the process has finished. \n\n\nCreate a Hadoop cluster / Cloud Provisioning\n\n\nYou are almost done! One more command and your Hadoop cluster is starting!\n Cloud provisioning is done once the \ncluster is up and running. The new cluster will use your selected blueprint and install your custom Hadoop cluster \nwith the selected components and services.\n\n\ncluster create --description \nmy first cluster\n\n\n\n\n\nOther available option is \n--wait\n - in this case the create command will return only after the process has finished. \n\n\nYou are done!\n You have several opportunities to check the progress during the infrastructure creation then \nprovisioning:\n\n\n\n\nCloudbreak uses \nGoogle Cloud Platform\n to create the resources - you can check out the resources created by \nCloudbreak on the Compute Engine page of the Google Compute Platform..\n\n\n\n\n\n\nFull size \nhere\n.\n\n\n\n\nIf stack then cluster creation have successfully done, you can check the Ambari Web UI. However you need to know the \nAmbari IP (for example: \nhttp://130.211.163.13:8080\n): \n\n\nYou can get the IP from the CLI as a result (\nambariServerIp 130.211.163.13\n) of the following command:\n\n\n\n\n\n\n\n\n         cluster show\n\n\n\n\n\n\nFull size \nhere\n.\n\n\n\n\nBesides these you can check the entire progress and the Ambari IP as well on the Cloudbreak Web UI itself. Open the \nnew cluster's \ndetails\n and its \nEvent History\n here.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nStop Cluster\n\n\nYou have the ability to \nstop your existing stack then its cluster\n if you want to suspend the work on it.\n\n\nSelect a stack for example with its name:\n\n\nstack select --name my-stack\n\n\n\n\nOther available option to define a stack is its \n--id\n.\n\n\nEvery time you should stop the \ncluster\n first then the \nstack\n. So apply following commands to stop the previously \nselected stack:\n\n\ncluster stop\nstack stop\n\n\n\n\nRestart Cluster\n\n\nSelect your stack that you would like to restart\n after this you can apply:\n\n\nstack start\n\n\n\n\nAfter the stack has successfully restarted, you can \nrestart the related cluster as well\n:\n\n\ncluster start\n\n\n\n\nUpscale Cluster\n\n\nIf you need more instances to your infrastructure, you can \nupscale your selected stack\n:\n\n\nstack node --ADD --instanceGroup host_group_slave_1 --adjustment 6\n\n\n\n\nOther available option is \n--withClusterUpScale\n - this indicates also a cluster upscale after the stack upscale. You\n can upscale the related cluster separately if you want to do this:\n\n\ncluster node --ADD --hostgroup host_group_slave_1 --adjustment 6\n\n\n\n\nDownscale Cluster\n\n\nYou also can reduce the number of instances in your infrastructure. \nAfter you selected your stack\n:\n\n\ncluster node --REMOVE  --hostgroup host_group_slave_1 --adjustment -2\n\n\n\n\nOther available option is \n--withStackDownScale\n - this indicates also a stack downscale after the cluster downscale.\n You can downscale the related stack separately if you want to do this:\n\n\nstack node --REMOVE  --instanceGroup host_group_slave_1 --adjustment -2\n\n\n\n\nCluster Termination\n\n\nYou can terminate running or stopped clusters with\n\n\nstack delete --name myawsstack\n\n\n\n\nOther available option is \n--wait\n - in this case the terminate command will return only after the process has finished. \n\n\n\n\nIMPORTANT:\n Always use Cloudbreak to terminate the cluster. If that fails for some reason, try to delete the \nCloudFormation stack first. Instances are started in an Auto Scaling Group so they may be restarted if you terminate an instance manually!\n\n\n\n\nSometimes Cloudbreak cannot synchronize its state with the cluster state at the cloud provider and the cluster can't\n be terminated. In this case the \nForced termination\n option on the Cloudbreak Web UI can help to terminate the cluster\n  at the Cloudbreak side. \nIf it has happened:\n\n\n\n\nYou should check the related resources at the AWS CloudFormation\n\n\nIf it is needed you need to manually remove resources from there\n\n\n\n\nSilent Mode\n\n\nWith Cloudbreak Shell you can execute script files as well. A script file contains shell commands and can \nbe executed with the \nscript\n cloudbreak shell command\n\n\nscript \nyour script file\n\n\n\n\n\nor with the \ncbd util cloudbreak-shell-quiet\n command\n\n\ncbd util cloudbreak-shell-quiet \n example.sh\n\n\n\n\n\n\nIMPORTANT:\n You have to copy all your files into the \ncbd\n working directory, what you would like to use in shell.\n For example if your \ncbd\n working directory is ~/cloudbreak-deployment then copy your script file to here.\n\n\n\n\nExample\n\n\nThe following example creates a hadoop cluster with \nhdp-small-default\n blueprint on M3Xlarge instances with 2X100G \nattached disks on \ndefault-gcp-network\n network using \nall-services-port\n security group. You should copy your ssh \npublic key file (with name \nid_rsa.pub\n) and your GCP service account generated private key ( with name \ngcp.p12\n) into your \ncbd\n working \ndirectory and change the \n...\n parts with your GCP credential details.\n\n\ncredential create --GCP --description \nmy credential\n --name my-gcp-credential --projectId \nyour gcp projectid\n --serviceAccountId \nyour GCP service account mail address\n --serviceAccountPrivateKeyPath gcp.p12 --sshKeyFile id_rsa.pub\ncredential select --name my-gcp-credential\ntemplate create --GCP --name gcptemplate --description gcp-template --instanceType n1-standard-4 --volumeSize 100 \n--volumeCount 2\nblueprint select --name hdp-small-default\ninstancegroup configure --instanceGroup host_group_master_1 --nodecount 1 --templateName gcptemplate --securityGroupName all-services-port --ambariServer true\ninstancegroup configure --instanceGroup host_group_master_2 --nodecount 1 --templateName gcptemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_master_3 --nodecount 1 --templateName gcptemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_client_1  --nodecount 1 --templateName gcptemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_slave_1 --nodecount 3 --templateName gcptemplate --securityGroupName all-services-port --ambariServer false\nnetwork select --name default-gcp-network\nstack create --GCP --name my-first-stack --region us-central1 --wait true\ncluster create --description \nMy first cluster\n --wait true\n\n\n\n\nCongratulations!\n Your cluster should now be up and running on this way as well. To learn more about Cloudbreak and \nprovisioning, we have some \ninteresting insights\n for you.", 
            "title": "GCP"
        }, 
        {
            "location": "/gcp/#google-cloud-images", 
            "text": "We have pre-built Cloudbreak Deployer cloud image for Google Cloud Platform (GCP). You can launch the latest Cloudbreak Deployer image at the  Google Developers Console .   As an alternative to using the pre-built cloud images for GCP, you can install Cloudbreak Deployer on your own VM. For more information, see the  installation instructions .", 
            "title": "Google Cloud Images"
        }, 
        {
            "location": "/gcp/#prerequisites", 
            "text": "", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/gcp/#ports", 
            "text": "Make sure that you have opened the following ports on your  Security Group :   SSH (22)  Cloudbreak (443)", 
            "title": "Ports"
        }, 
        {
            "location": "/gcp/#cloudbreak-deployer-gcp-image-details", 
            "text": "", 
            "title": "Cloudbreak Deployer GCP Image Details"
        }, 
        {
            "location": "/gcp/#import-cloudbreak-deployer-image", 
            "text": "Import the latest Cloudbreak Deployer image on the  Google Developers Console  with the help\n of the  Google Cloud Shell .  To open the Google Cloud Shell, click on the  Activate Google Cloud Shell  icon in the top right corner of the page:   Full size  here .   Full size  here .  Next, create your own Cloudbreak Deployer instance from the imported image on the Google Developers Console.   Images are global resources, so you can use them across zones and projects.", 
            "title": "Import Cloudbreak Deployer Image"
        }, 
        {
            "location": "/gcp/#vm-requirements", 
            "text": "When selecting an instance type, consider these minimum and recomended requirements:     4GB RAM, 10GB disk, 2 cores  The minimum instance type suitable for Cloudbreak is  n1-standard-2   To learn about all requirements, see  System Requirements", 
            "title": "VM Requirements"
        }, 
        {
            "location": "/gcp/#cloudbreak-deployer-setup-on-google", 
            "text": "Before getting started with Cloudbreak Deployer, you should know that:   The default SSH username for the GCP instances is  cloudbreak .  Cloudbreak Deployer location on your VM is  /var/lib/cloudbreak-deployment . This is the  cbd  root folder.  You must execute all  cbd  actions from the  cbd  root folder.   In the previous step, you should have already set up a VM with Cloudbreak Doployer either  the GCP Cloud Images  or by  installing the Cloudbreak Deployer  manually on your own VM.  There are several ways to  connect to the previously created  cbd  VM .", 
            "title": "Cloudbreak Deployer Setup on Google"
        }, 
        {
            "location": "/gcp/#cloudbreak-deployment-directory", 
            "text": "To navigate to the  cloudbreak-deployment  directory, use:  cd /var/lib/cloudbreak-deployment  This directory contains configuration files and the supporting binaries for Cloudbreak Deployer.", 
            "title": "Cloudbreak Deployment Directory"
        }, 
        {
            "location": "/gcp/#initialize-your-profile", 
            "text": "First, initialize deployer by creating a  Profile  file with the following content:  export UAA_DEFAULT_SECRET='[SECRET]'\nexport UAA_DEFAULT_USER_PW='[PASSWORD]'  By default the  cbd  tool tries to guess  PUBLIC_IP  to bind Cloudbreak UI to it. But if  cbd  cannot get the IP address during the initialization, set the appropriate value also in your  Profile .", 
            "title": "Initialize Your Profile"
        }, 
        {
            "location": "/gcp/#start-cloudbreak-deployer", 
            "text": "To start the Cloudbreak application, use the following command:  cbd start  This will start all the Docker containers and initialize the application.   The first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.   The  cbd start  command includes the  cbd generate  command which applies the following steps:   creates the  docker-compose.yml  file that describes the configuration of all the Docker containers needed for the Cloudbreak deployment.  creates the  uaa.yml  file that holds the configuration of the identity server used to authenticate users to Cloudbreak.", 
            "title": "Start Cloudbreak Deployer"
        }, 
        {
            "location": "/gcp/#validate-that-cloudbreak-deployer-has-started", 
            "text": "After the  cbd start  command finishes, check the following:   Pre-installed Cloudbreak Deployer version and health:      cbd doctor   If you need to run  cbd update , refer to  Cloudbreak Deployer Update . Most of the  cbd  commands require  root  permissions.    Started Cloudbreak Application logs:      cbd logs cloudbreak   You should see a line like this in the log:  Started CloudbreakApplication in 36.823 seconds . Cloudbreak normally takes less than a minute to start.", 
            "title": "Validate that Cloudbreak Deployer Has Started"
        }, 
        {
            "location": "/gcp/#cluster-provisioning-prerequisites", 
            "text": "", 
            "title": "Cluster Provisioning Prerequisites"
        }, 
        {
            "location": "/gcp/#creating-a-google-cloud-service-account", 
            "text": "Follow the  instructions  in Google Cloud's documentation to create a  Service account  and  Generate a new P12 key .  Make sure that at API level ( APIs and auth  menu) you have enabled:   Google Compute Engine  Google Compute Engine Instance Group Manager API  Google Compute Engine Instance Groups API  BigQuery API  Google Cloud Deployment Manager API  Google Cloud DNS API  Google Cloud SQL  Google Cloud Storage  Google Cloud Storage JSON API    If you have enabled every API then you have to wait about  10 minutes  for the provider.   When creating GCP credentials  in Cloudbreak you will have to provide the email address of your  Service Account  \n(from the Service accounts page of your Google Cloud Platform Permissions) and the  Project ID  (from the Dashboard \nof your Google Cloud Platform Home) where the service account is created.  You'll also have to  upload the \ngenerated P12 file and provide an OpenSSH formatted public key  that will be used as an SSH key.", 
            "title": "Creating a Google Cloud Service Account"
        }, 
        {
            "location": "/gcp/#generate-a-new-ssh-key", 
            "text": "All the instances created by Cloudbreak are configured to allow key-based SSH,\nso you'll need to provide an SSH public key that can be used later to SSH onto the instances in the clusters you'll create with Cloudbreak.\nYou can use one of your existing keys or you can generate a new one.  To generate a new SSH keypair:  ssh-keygen -t rsa -b 4096 -C  your_email@example.com \n# Creates a new ssh key, using the provided email as a label\n# Generating public/private rsa key pair.  # Enter file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]\nYou'll be asked to enter a passphrase, but you can leave it empty.\n\n# Enter passphrase (empty for no passphrase): [Type a passphrase]\n# Enter same passphrase again: [Type passphrase again]  After you enter a passphrase the keypair is generated. The output should look something like below.   # Your identification has been saved in /Users/you/.ssh/id_rsa.\n# Your public key has been saved in /Users/you/.ssh/id_rsa.pub.\n# The key fingerprint is:\n# 01:0f:f4:3b:ca:85:sd:17:sd:7d:sd:68:9d:sd:a2:sd your_email@example.com  Later you'll need to pass the  .pub  file's contents to Cloudbreak and use the private part to SSH to the instances", 
            "title": "Generate a New SSH Key"
        }, 
        {
            "location": "/gcp/#cluster-provisioning-via-browser", 
            "text": "You can log into the Cloudbreak application at  https:// PUBLIC_IP .  The main goal of the Cloudbreak UI is to easily create clusters on your own cloud provider account.\nThis description details the GCP setup - if you'd like to use a different cloud provider check out its manual.  This document explains the four steps that need to be followed to create Cloudbreak clusters from the UI:   connect your GCP account with Cloudbreak  create some template resources on the UI that describe the infrastructure of your clusters  create a blueprint that describes the HDP services in your clusters  launch the cluster itself based on these template resources    IMPORTANT:  Make sure that you have sufficient qouta (CPU, network, etc) for the requested cluster size.", 
            "title": "Cluster Provisioning via Browser"
        }, 
        {
            "location": "/gcp/#setting-up-gcp-credentials", 
            "text": "Cloudbreak works by connecting your GCP account through so called  Credentials , and then uses these credentials to \ncreate resources on your behalf. The credentials can be configured on the  manage credentials  panel on the \nCloudbreak Dashboard.  To create a new GCP credential follow these steps:   Fill out the new credential  Name  Only alphanumeric and lowercase characters (min 5, max 100 characters) can be applied    Copy your GCP project ID to the  Project Id  field  Copy your GCP Service Account email address to the  Service Account Email Address  field  Upload your GCP Service Account private key (generated  p12 Key ) to the  Service Account Private (p12) Key  field  Copy your SSH public key to the  SSH public key  field  The SSH public key must be in OpenSSH format and it's private keypair can be used later to  SSH onto every instance  of every cluster you'll create with this credential.  The  SSH username  for the GCP instances is  cloudbreak .      Any other parameter is optional here.  Public in account  means that all the users belonging to your account will be able to use this credential to create \nclusters, but cannot delete it.    Full size  here .", 
            "title": "Setting up GCP Credentials"
        }, 
        {
            "location": "/gcp/#infrastructure-templates", 
            "text": "After your GCP account is linked to Cloudbreak you can start creating resource templates that describe your clusters'\ninfrastructure:   templates  networks  security groups   When you create one of the above resources,  Cloudbreak does not make any requests to GCP. Resources are only created\non GCP after the  create cluster  button has pushed.  These templates are saved to Cloudbreak's database and can be\nreused with multiple clusters to describe the infrastructure.", 
            "title": "Infrastructure Templates"
        }, 
        {
            "location": "/gcp/#templates", 
            "text": "Templates describe the  instances of your cluster  - the instance type and the attached volumes. A typical setup is\n to combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple\n large disks to the datanodes or have memory optimized instances for Spark nodes.  The instance templates can be configured on the  manage templates  panel on the Cloudbreak Dashboard.  If  Preemptible  is checked then the template will be  preemptible  If  Public in account  is checked all the users belonging to your account will be able to use this resource to create clusters, but cannot delete it.", 
            "title": "Templates"
        }, 
        {
            "location": "/gcp/#networks", 
            "text": "Your clusters can be created in their own  networks  or in one of your already existing one. If you choose an \nexisting network, it is possible to create a new subnet within the network. The subnet's IP range must be defined in \nthe  Subnet (CIDR)  field using the general CIDR notation. You can read more about  GCP Networks  and  Subnet \nnetworks .  Default GCP Network  If you don't want to create or use your custom network, you can use the  default-gcp-network  for all your \nCloudbreak clusters. It will create a new network with a  10.0.0.0/16  subnet every time a cluster is created.  Custom GCP Network  If you'd like to deploy a cluster to a custom network you'll have to  create a new network  template on the  manage \nnetworks  panel.  You have the following options:   Create a new virtual network and a new subnet : Every time a cluster is created with this kind of network setup a new virtual network and a new subnet with the specified IP range will be created for the instances on Google Cloud.  Create a new subnet in an existing virtual network : Use this kind of network setup if you already have a virtual network on Google Cloud where you'd like to put the Cloudbreak created cluster but you'd like to have a separate subnet for it.  Use an existing subnet in an existing virtual network : Use this kind of network setup if you have an existing virtual network with one or more subnets on Google Cloud and you'd like to start the instances of a cluster in one of those subnets.  Important constraints of the following parameters:  Don't create public IPs : Please make sure that Cloudbreak can access the launched instances and the instances can reach the internet  Don't create new firewall rules : Please make sure that the created instances in the subnet can reach each other (open every port in the subnet)    Use a legacy network without subnets : Use this kind of network setup if you have a legacy virtual network on Google Cloud that doesn't have subnet support and you'd like to start instances in that virtual network directly.    IMPORTANT:  Please make sure the defined subnet here doesn't overlap with any of your already deployed subnet in the\n network, because the validation only happens after the cluster creation starts.  In case of existing subnet make sure you have enough room within your network space for the new instances. The \nprovided subnet CIDR will be ignored, but a proper CIDR range will be used.   If  Public in account  is checked all the users belonging to your account will be able to use this network template \nto create clusters, but cannot delete it.   NOTE:  The new networks are created on GCP only after the the cluster provisioning starts with the selected \nnetwork template.    Full size  here .", 
            "title": "Networks"
        }, 
        {
            "location": "/gcp/#security-groups", 
            "text": "Security group templates are very similar to the  Firewalls on GCP .  They describe the allowed inbound traffic \nto the instances in the cluster.  Currently only one security group template can be selected for a Cloudbreak cluster \nand all the instances have a public IP address so all the instances in the cluster will belong to the same security \ngroup. This may change in a later release.  Default Security Group  You can also use the two pre-defined security groups in Cloudbreak.  only-ssh-and-ssl:  all ports are locked down except for SSH and the selected Ambari Server HTTPS (you can't access Hadoop services \noutside of the virtual network):   SSH (22)  HTTPS (443)   Custom Security Group  You can define your own security group by adding all the ports, protocols and CIDR range you'd like to use. The rules\n defined here doesn't need to contain the internal rules, those are automatically added by Cloudbreak to the security\n  group on GCP.  Hadoop services :  Ambari (8080)  Consul (8500)  NN (50070)  RM Web (8088)  Scheduler (8030RM)  IPC (8050RM)  Job history server (19888)  HBase master (60000)  HBase master web (60010)  HBase RS (16020)  HBase RS info (60030)  Falcon (15000)  Storm (8744)  Hive metastore (9083)  Hive server (10000)  Hive server HTTP (10001)  Accumulo master (9999)  Accumulo Tserver (9997)  Atlas (21000)  KNOX (8443)  Oozie (11000)  Spark HS (18080)  NM Web (8042)  Zeppelin WebSocket (9996)  Zeppelin UI (9995)  Kibana (3080)\n* Elasticsearch (9200)   IMPORTANT  443, 9443, and 22 ports needs to be there in every security group otherwise Cloudbreak won't be able to communicate with the provisioned cluster.   If  Public in account  is checked all the users belonging to your account will be able to use this security group \ntemplate to create clusters, but cannot delete it.   NOTE:  The security groups are created on GCP only after the cluster provisioning starts with the selected \nsecurity group template.    Full size  here .", 
            "title": "Security Groups"
        }, 
        {
            "location": "/gcp/#defining-cluster-services", 
            "text": "", 
            "title": "Defining Cluster Services"
        }, 
        {
            "location": "/gcp/#blueprints", 
            "text": "Blueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are  used by Ambari .  You can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file, URL (an  example blueprint ) or the \nwhole JSON can be written in the  JSON text  box.  The host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.   NOTE:  It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will \nfill that with a default value.   If  Public in account  is checked all the users belonging to your account will be able to use this blueprint to \ncreate clusters, but cannot delete or modify it.   Full size  here .  A blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications. \nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations...etc. that won't be applicable to the Cloudbreak cluster", 
            "title": "Blueprints"
        }, 
        {
            "location": "/gcp/#cluster-deployment", 
            "text": "After all the cluster resources are configured you can deploy a new HDP cluster.  Here is a  basic flow for cluster creation on Cloudbreak Web UI :   Start by selecting a previously created GCP credential in the header.  Open  create cluster   Configure Cluster  tab   Fill out the new cluster  name  Cluster name must start with a lowercase alphabetic character then you can apply lowercase alphanumeric and \n   hyphens only (min 5, max 40 characters)    Select a  Region  where you like your cluster be provisioned  Click on the  Setup Network and Security  button  If  Public in account  is checked all the users belonging to your account will be able to see the created cluster on\n the UI, but cannot delete or modify it.     Setup Network and Security  tab   Select one of the security groups  Click on the  Choose Blueprint  button  If  Enable security  is checked as well, Cloudbreak will install Key Distribution Center (KDC) and the cluster will \nbe Kerberized. See more about it in the  Kerberos  section of this documentation.     Choose Blueprint  tab   Select one of the blueprint  After you've selected a  Blueprint , you should be able to configure:  the templates  the securitygroups  the number of nodes for all of the host groups in the blueprint    You need to select where you want to install the Ambari server to. Only 1 host group can be selected.\n   If you want to install the Ambari server to a separate node, you need to extend your blueprint with a new host group\n   which contains only 1 service: HDFS_CLIENT and select this host group for the Ambari server. Note: this host group cannot be scaled so \n   it is not advised to select a 'slave' host group for this purpose.  Click on the  Add File System  button   Add File System  tab   Select one of the file system that fits your needs  After you've selected  GCS file system , you should configure:  Default Bucket Name    Click on the  Review and Launch  button  You can read more about  GCS File System  and  Bucket Naming  in GCP \nDocumentation.     Review and Launch  tab   After the  create and start cluster  button has clicked Cloudbreak will start to create the cluster's resources on \n your GCP account.   Cloudbreak uses  Google Cloud Platform  to create the resources - you can check out the resources created by Cloudbreak\n on the  Compute Engine  page of the  Google Compute Platform .  Full size  here .  Besides these you can check the progress on the Cloudbreak Web UI itself if you open the new cluster's  Event History .  Full size  here .", 
            "title": "Cluster Deployment"
        }, 
        {
            "location": "/gcp/#advanced-options", 
            "text": "There are some advanced features when deploying a new cluster, these are the following:  Ambari Username  This user will be used as admin user in Ambari. You can log in using this username on the Ambari UI.  Ambari Password  The password associated with the Ambari username. This password will be also the default password for all required passwords which are not specified in the blueprint. E.g: hive DB password.  Availability Zone  You can restrict the instances to a  specific availability zone . It may be useful if you're using\n reserved instances.  Minimum cluster size  The provisioning strategy in case the cloud provider cannot allocate all the requested nodes.  Validate blueprint  This is selected by default. Cloudbreak validates the Ambari blueprint in this case.  Custom Image  If you enable this, you can override the default image for provision.  Shipyard enabled cluster  This is selected by default. Cloudbreak will start a  Shipyard  container which helps you to manage your containers.  Config recommendation strategy  Strategy for how configuration recommendations will be applied. Recommended \nconfigurations gathered by the response of the stack advisor.    NEVER_APPLY                Configuration recommendations are ignored with this option.  ONLY_STACK_DEFAULTS_APPLY  Applies only on the default configurations for all included services.  ALWAYS_APPLY               Applies on all configuration properties.", 
            "title": "Advanced Options"
        }, 
        {
            "location": "/gcp/#cluster-termination", 
            "text": "You can terminate running or stopped clusters with the  terminate  button in the cluster details.   IMPORTANT:  Always use Cloudbreak to terminate the cluster. If that fails for some reason, try to delete the \nGCP instances first. Instances are started in an Auto Scaling Group so they may be restarted if you terminate an \ninstance manually!   Sometimes Cloudbreak cannot synchronize its state with the cluster state at the cloud provider and the cluster can't\n be terminated. In this case the  Forced termination  option can help to terminate the cluster at the Cloudbreak \n side.  If it has happened:   You should check the related resources at the Google Cloud Platform  If it is needed you need to manually remove resources from there    Full size  here .", 
            "title": "Cluster Termination"
        }, 
        {
            "location": "/gcp/#interactive-mode-cloudbreak-shell", 
            "text": "The goal with the Cloudbreak Shell (Cloudbreak CLI) was to provide an interactive command line tool which supports:   all functionality available through the REST API or Cloudbreak Web UI  makes possible complete automation of management task via scripts  context aware command availability  tab completion  required/optional parameter support  hint command to guide you on the usual path", 
            "title": "Interactive mode / Cloudbreak Shell"
        }, 
        {
            "location": "/gcp/#start-cloudbreak-shell", 
            "text": "To start the Cloudbreak CLI use the following commands:   Open your  cloudbreak-deployment  directory if it is needed. For example:      cd cloudbreak-deployment   Start the  cbd  from here if it is needed      cbd start   In the root of your  cloudbreak-deployment  folder apply:      cbd util cloudbreak-shell   At the very first time it will take for a while, because of need to download all the necessary docker images.   This will launch the Cloudbreak shell inside a Docker container then it is ready to use.  Full size  here .   IMPORTANT You have to copy all your files into the  cbd  working directory, what you would like to use in shell.  For \nexample if your  cbd  working directory is  ~/cloudbreak-deployment  then copy your  blueprint JSON, public ssh key \nfile...etc.  to here. You can refer to these files with their names from the shell.", 
            "title": "Start Cloudbreak Shell"
        }, 
        {
            "location": "/gcp/#autocomplete-and-hints", 
            "text": "Cloudbreak Shell helps you with  hint messages  from the very beginning, for example:  cloudbreak-shell hint\nHint: Add a blueprint with the 'blueprint create' command or select an existing one with 'blueprint select'\ncloudbreak-shell   Beyond this you can use the  autocompletion (double-TAB)  as well:  cloudbreak-shell credential create --\ncredential create --AWS          credential create --AZURE        credential create --EC2          credential create --GCP          credential create --OPENSTACK", 
            "title": "Autocomplete and Hints"
        }, 
        {
            "location": "/gcp/#cluster-provisioning-via-cli", 
            "text": "", 
            "title": "Cluster Provisioning via CLI"
        }, 
        {
            "location": "/gcp/#setting-up-gcp-credential", 
            "text": "Cloudbreak works by connecting your GCP account through so called Credentials, and then uses these credentials to \ncreate resources on your behalf. Credentials can be configured with the following command for example:  credential create --GCP --description  sample description  --name my-gcp-credential --projectId  your gcp projectid  \n--serviceAccountId  your GCP service account mail address  --serviceAccountPrivateKeyPath /files/mykey.p12 \n--sshKeyString  ssh-rsa AAAAB3***etc.    NOTE:  Cloudbreak  does not set your cloud user details  - we work around the concept of GCP Service \nAccount Credentials. You should have already a valid GCP service account. You can find further details  here .   Alternatives to provide  SSH Key :   you can upload your public key from an url:  \u2014sshKeyUrl    or you can add the path of your public key:  \u2014sshKeyPath   You can check whether the credential was created successfully  credential list  You can switch between your existing credentials  credential select --name my-gcp-credential", 
            "title": "Setting up GCP Credential"
        }, 
        {
            "location": "/gcp/#infrastructure-templates_1", 
            "text": "After your GCP account is linked to Cloudbreak you can start creating resource templates that describe your clusters'\ninfrastructure:   security groups  networks  templates   When you create one of the above resources,  Cloudbreak does not make any requests to GCP. Resources are only created\n on GCP after the  cluster create  has applied.  These templates are saved to Cloudbreak's database and can be\n reused with multiple clusters to describe the infrastructure.", 
            "title": "Infrastructure Templates"
        }, 
        {
            "location": "/gcp/#templates_1", 
            "text": "Templates describe the  instances of your cluster  - the instance type and the attached volumes. A typical setup is\n to combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple\n large disks to the datanodes or have memory optimized instances for Spark nodes.  A template can be used repeatedly to create identical copies of the same stack (or to use as a foundation to start a\nnew stack). Templates can be configured with the following command for example:  template create --GCP --name my-gcp-template --instanceType n1-standard-2 --volumeCount 2 --volumeSize 100  Other available options here:  --volumeType  The default is  pd-standard  (HDD), other allowed value is  pd-ssd \n(SSD).  --preemptible  is true, the template will be  preemptible  --publicInAccount  is true, all the users belonging to your account will be able to use this template\nto create clusters, but cannot delete it.  You can check whether the template was created successfully  template list", 
            "title": "Templates"
        }, 
        {
            "location": "/gcp/#networks_1", 
            "text": "Your clusters can be created in their own  networks  or in one of your already existing one. If you choose an \nexisting network, it is possible to create a new subnet within the network. The subnet's IP range must be defined in \nthe  Subnet (CIDR)  field using the general CIDR notation. You can read more about  GCP Networks  and  Subnet networks .  Default GCP Network  If you don't want to create or use your custom network, you can use the  default-gcp-network  for all your \nCloudbreak clusters. It will create a new network with a  10.0.0.0/16  subnet every time a cluster is created.  Custom GCP Network  If you'd like to deploy a cluster to a custom network you'll have to apply the following command:  network create --GCP --name my-gcp-network --description  sample description   Other available options here:  --networkId  The Virtual Network Identifier of your network. This is an optional \nvalue and must be an ID of an existing GCP virtual network. If the identifier is provided, the subnet CIDR will be \nignored and the existing network's CIDR range will be used.  --publicInAccount  is true, all the users belonging to your account will be able to use this network template \nto create clusters, but cannot delete it.  --subnet  specified subnet which will be used by the cluster (will be created under the provisioning).  --subnetId  if you have an existing subnet in the network then you can specify the id here and the cluster will use that existing subnet.   IMPORTANT:  Make sure the defined subnet here doesn't overlap with any of your \nalready deployed subnet in the network, because the validation only happens after the cluster creation starts.  In case of existing subnet make sure you have enough room within your network space for the new instances. The \nprovided subnet CIDR will be ignored, but a proper CIDR range will be used.   You can check whether the network was created successfully  network list   NOTE:  The new networks are created on GCP only after the the cluster provisioning starts with the selected \nnetwork template.", 
            "title": "Networks"
        }, 
        {
            "location": "/gcp/#defining-cluster-services_1", 
            "text": "", 
            "title": "Defining Cluster Services"
        }, 
        {
            "location": "/gcp/#blueprints_1", 
            "text": "Blueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are  used by Ambari .  You can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file or URL (an  example blueprint ).  The host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.   NOTE:  It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will fill that with a default value.   blueprint create --name my-blueprint --description  sample description  --file  the path of the blueprint   Other available options:  --url  the url of the blueprint  --publicInAccount  If it is true, all the users belonging to your account will be able to use this blueprint to create \nclusters, but cannot delete it.  You can check whether the blueprint was created successfully  blueprint list  A blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications. \nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations..etc. that won't be applicable to the Cloudbreak cluster.", 
            "title": "Blueprints"
        }, 
        {
            "location": "/gcp/#metadata-show", 
            "text": "You can check the stack metadata with  stack metadata --name myawsstack --instancegroup master  Other available options:  --id  In this case you can select a stack with id.  --outputType  In this case you can modify the outputformat of the command (RAW or JSON).", 
            "title": "Metadata Show"
        }, 
        {
            "location": "/gcp/#cluster-deployment_1", 
            "text": "After all the cluster resources are configured you can deploy a new HDP cluster. The following sub-sections show \nyou a  basic flow for cluster creation with Cloudbreak Shell .", 
            "title": "Cluster Deployment"
        }, 
        {
            "location": "/gcp/#select-credential", 
            "text": "Select one of your previously created GCP credential:  credential select --name my-gcp-credential", 
            "title": "Select Credential"
        }, 
        {
            "location": "/gcp/#select-blueprint", 
            "text": "Select one of your previously created blueprint which fits your needs:  blueprint select --name multi-node-hdfs-yarn", 
            "title": "Select Blueprint"
        }, 
        {
            "location": "/gcp/#configure-instance-groups", 
            "text": "You must configure instance groups before provisioning. An instance group define a group of nodes with a specified \ntemplate. Usually we create instance groups for host groups in the blueprint. For Ambari server only 1 host group can be specified.\nIf you want to install the Ambari server to a separate node, you need to extend your blueprint with a new host group\nwhich contains only 1 service: HDFS_CLIENT and select this host group for the Ambari server. Note: this host group cannot be scaled so \nit is not advised to select a 'slave' host group for this purpose.  instancegroup configure --instanceGroup master --nodecount 1 --templateName minviable-aws --securityGroupName all-services-port --ambariServer true\ninstancegroup configure --instanceGroup slave_1 --nodecount 1 --templateName minviable-aws --securityGroupName all-services-port --ambariServer false  Other available option:  --templateId  Id of the template", 
            "title": "Configure Instance Groups"
        }, 
        {
            "location": "/gcp/#select-network", 
            "text": "Select one of your previously created network which fits your needs or a default one:  network select --name default-gcp-network", 
            "title": "Select Network"
        }, 
        {
            "location": "/gcp/#create-stack-create-cloud-infrastructure", 
            "text": "Stack means the running cloud infrastructure that is created based on the instance groups configured earlier \n( credential ,  instancegroups ,  network ,  securitygroup ). Same as in case of the API or UI the new cluster will \nuse your templates and by using GCP will launch your cloud stack. Use the following command to create a \nstack to be used with your Hadoop cluster:  stack create --GCP --name mygcpstack --region us-central1  The infrastructure is created asynchronously, the state of the stack can be checked with the stack  show command . If \nit reports AVAILABLE, it means that the virtual machines and the corresponding infrastructure is running at the cloud provider.  Other available option is:  --wait  - in this case the create command will return only after the process has finished.", 
            "title": "Create Stack / Create Cloud Infrastructure"
        }, 
        {
            "location": "/gcp/#create-a-hadoop-cluster-cloud-provisioning", 
            "text": "You are almost done! One more command and your Hadoop cluster is starting!  Cloud provisioning is done once the \ncluster is up and running. The new cluster will use your selected blueprint and install your custom Hadoop cluster \nwith the selected components and services.  cluster create --description  my first cluster   Other available option is  --wait  - in this case the create command will return only after the process has finished.   You are done!  You have several opportunities to check the progress during the infrastructure creation then \nprovisioning:   Cloudbreak uses  Google Cloud Platform  to create the resources - you can check out the resources created by \nCloudbreak on the Compute Engine page of the Google Compute Platform..    Full size  here .   If stack then cluster creation have successfully done, you can check the Ambari Web UI. However you need to know the \nAmbari IP (for example:  http://130.211.163.13:8080 ):   You can get the IP from the CLI as a result ( ambariServerIp 130.211.163.13 ) of the following command:              cluster show   Full size  here .   Besides these you can check the entire progress and the Ambari IP as well on the Cloudbreak Web UI itself. Open the \nnew cluster's  details  and its  Event History  here.    Full size  here .", 
            "title": "Create a Hadoop cluster / Cloud Provisioning"
        }, 
        {
            "location": "/gcp/#stop-cluster", 
            "text": "You have the ability to  stop your existing stack then its cluster  if you want to suspend the work on it.  Select a stack for example with its name:  stack select --name my-stack  Other available option to define a stack is its  --id .  Every time you should stop the  cluster  first then the  stack . So apply following commands to stop the previously \nselected stack:  cluster stop\nstack stop", 
            "title": "Stop Cluster"
        }, 
        {
            "location": "/gcp/#restart-cluster", 
            "text": "Select your stack that you would like to restart  after this you can apply:  stack start  After the stack has successfully restarted, you can  restart the related cluster as well :  cluster start", 
            "title": "Restart Cluster"
        }, 
        {
            "location": "/gcp/#upscale-cluster", 
            "text": "If you need more instances to your infrastructure, you can  upscale your selected stack :  stack node --ADD --instanceGroup host_group_slave_1 --adjustment 6  Other available option is  --withClusterUpScale  - this indicates also a cluster upscale after the stack upscale. You\n can upscale the related cluster separately if you want to do this:  cluster node --ADD --hostgroup host_group_slave_1 --adjustment 6", 
            "title": "Upscale Cluster"
        }, 
        {
            "location": "/gcp/#downscale-cluster", 
            "text": "You also can reduce the number of instances in your infrastructure.  After you selected your stack :  cluster node --REMOVE  --hostgroup host_group_slave_1 --adjustment -2  Other available option is  --withStackDownScale  - this indicates also a stack downscale after the cluster downscale.\n You can downscale the related stack separately if you want to do this:  stack node --REMOVE  --instanceGroup host_group_slave_1 --adjustment -2", 
            "title": "Downscale Cluster"
        }, 
        {
            "location": "/gcp/#cluster-termination_1", 
            "text": "You can terminate running or stopped clusters with  stack delete --name myawsstack  Other available option is  --wait  - in this case the terminate command will return only after the process has finished.    IMPORTANT:  Always use Cloudbreak to terminate the cluster. If that fails for some reason, try to delete the \nCloudFormation stack first. Instances are started in an Auto Scaling Group so they may be restarted if you terminate an instance manually!   Sometimes Cloudbreak cannot synchronize its state with the cluster state at the cloud provider and the cluster can't\n be terminated. In this case the  Forced termination  option on the Cloudbreak Web UI can help to terminate the cluster\n  at the Cloudbreak side.  If it has happened:   You should check the related resources at the AWS CloudFormation  If it is needed you need to manually remove resources from there", 
            "title": "Cluster Termination"
        }, 
        {
            "location": "/gcp/#silent-mode", 
            "text": "With Cloudbreak Shell you can execute script files as well. A script file contains shell commands and can \nbe executed with the  script  cloudbreak shell command  script  your script file   or with the  cbd util cloudbreak-shell-quiet  command  cbd util cloudbreak-shell-quiet   example.sh   IMPORTANT:  You have to copy all your files into the  cbd  working directory, what you would like to use in shell.\n For example if your  cbd  working directory is ~/cloudbreak-deployment then copy your script file to here.", 
            "title": "Silent Mode"
        }, 
        {
            "location": "/gcp/#example", 
            "text": "The following example creates a hadoop cluster with  hdp-small-default  blueprint on M3Xlarge instances with 2X100G \nattached disks on  default-gcp-network  network using  all-services-port  security group. You should copy your ssh \npublic key file (with name  id_rsa.pub ) and your GCP service account generated private key ( with name  gcp.p12 ) into your  cbd  working \ndirectory and change the  ...  parts with your GCP credential details.  credential create --GCP --description  my credential  --name my-gcp-credential --projectId  your gcp projectid  --serviceAccountId  your GCP service account mail address  --serviceAccountPrivateKeyPath gcp.p12 --sshKeyFile id_rsa.pub\ncredential select --name my-gcp-credential\ntemplate create --GCP --name gcptemplate --description gcp-template --instanceType n1-standard-4 --volumeSize 100 \n--volumeCount 2\nblueprint select --name hdp-small-default\ninstancegroup configure --instanceGroup host_group_master_1 --nodecount 1 --templateName gcptemplate --securityGroupName all-services-port --ambariServer true\ninstancegroup configure --instanceGroup host_group_master_2 --nodecount 1 --templateName gcptemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_master_3 --nodecount 1 --templateName gcptemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_client_1  --nodecount 1 --templateName gcptemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_slave_1 --nodecount 3 --templateName gcptemplate --securityGroupName all-services-port --ambariServer false\nnetwork select --name default-gcp-network\nstack create --GCP --name my-first-stack --region us-central1 --wait true\ncluster create --description  My first cluster  --wait true  Congratulations!  Your cluster should now be up and running on this way as well. To learn more about Cloudbreak and \nprovisioning, we have some  interesting insights  for you.", 
            "title": "Example"
        }, 
        {
            "location": "/openstack/", 
            "text": "OpenStack Supported Versions\n\n\nCloudbreak was tested against the following versions of \nRed Hat Distribution of OpenStack\n (RDO):\n\n\n\n\nJuno\n\n\nKilo\n\n\nLiberty\n\n\nMitaka\n\n\n\n\nCloudbreak requires that the  standard components are installed and configured on OpenStack:\n\n\n\n\nKeystone V2 or Keystone V3\n\n\nNeutron (self-service and provider networking)\n\n\nNova (KVM or Xen hypervisor)\n\n\nGlance\n\n\nCinder (optional)\n\n\nHeat (optional, but it is highly recommended, since provisioning through native api calls will be deprecated in the future)\n\n\n\n\nOpenStack Images\n\n\nWe have pre-built cloud images for OpenStack with the Cloudbreak Deployer pre-installed and with Cloudbreak\npre-installed. Following steps will guide you through the launch of the images then the needed configuration.\n\n\n\n\nAlternatively, instead of using the pre-built cloud image, you can install Cloudbreak Deployer on your own VM. See\n \ninstall the Cloudbreak Deployer\n for more information.\n\n\n\n\nPlease make sure you opened the following ports on your \nsecurity group\n:\n\n\n\n\nSSH (22)\n\n\nCloudbreak (443)\n\n\n\n\nOpenStack Image Details\n\n\nCloudbreak Deployer image\n\n\nCloudbreak image\n\n\nImport the image into your OpenStack\n\n\nCloudbreak Deployer import\n\n\nexport OS_IMAGE_NAME=\nadd_a_name_to_your_new_image\n\nexport OS_USERNAME=\nyour_os_user_name\n\nexport OS_AUTH_URL=\nhttp://.../v2.0\n\nexport OS_TENANT_NAME=\nyour_os_tenant_name\n\n\n\n\n\nImport the new image into your OpenStack:\n\n\nglance image-create --name \n$OS_IMAGE_NAME\n --file \n$CBD_LATEST_IMAGE\n --disk-format qcow2 --container-format bare\n--progress\n\n\n\n\n\n\nMinimum and Recommended VM requirements\n:\n 8GB RAM, 10GB disk, 2 cores\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nCloudbreak import\n\n\nexport CB_LATEST_IMAGE_NAME=\nfile_name_of_the_above_cloudbreak_image\n\nexport OS_USERNAME=\nyour_os_user_name\n\nexport OS_AUTH_URL=\nhttp://.../v2.0\n\nexport OS_TENANT_NAME=\nyour_os_tenant_name\n\n\n\n\n\nImport the new image into your OpenStack:\n\n\nglance image-create --name \n$CB_LATEST_IMAGE_NAME\n --file \n$CB_LATEST_IMAGE\n --disk-format qcow2\n--container-format bare --progress\n\n\n\n\nOpenStack Setup\n\n\nBefore configuring Cloudbreak Deployer, you should know that:\n\n\n\n\nThe default SSH username for the OpenStack instances is \ncloudbreak\n.\n\n\nCloudbreak Deployer location on the launched EC2 instance is \n/var/lib/cloudbreak-deployment\n. This is the\n  \ncbd\n root folder.\n\n\nYou must execute all \ncbd\n actions from the \ncbd\n root folder as a \ncloudbreak\n user.\n\n\n\n\nSet up Cloudbreak Deployer\n\n\nYou should have already installed the Cloudbreak Deployer either by \nusing the OpenStack Cloud Images\n or by\n\ninstalling the Cloudbreak Deployer\n manually on your own VM.\n\n\nIf you have your own installed VM, check the \nInitialize your Profile\n\nsection here before starting the provisioning.\n\n\nYou can \nconnect to the previously created \ncbd\n VM\n.\n\n\nTo open the \ncloudbreak-deployment\n directory, run:\n\n\ncd /var/lib/cloudbreak-deployment/\n\n\n\n\nThis directory contains configuration files and the supporting binaries for Cloudbreak Deployer.\n\n\nInitialize Your Profile\n\n\nFirst, initialize deployer by creating a \nProfile\n file with the following content:\n\n\nexport UAA_DEFAULT_SECRET='[SECRET]'\nexport UAA_DEFAULT_USER_PW='[PASSWORD]'\nexport PUBLIC_IP='[PUBLIC_IP]'\n\n\n\n\nThe \nPUBLIC_IP\n is mandatory, because it is used to access the Cloudbreak UI.\n\n\nOpenStack-specific Configuration\n\n\nMake sure that the \nVM image used by Cloudbreak is imported on your OpenStack\n.\n\n\nUsing Self-signed Certificates\n\n\nIf your OpenStack is secured with a self-signed certificate, you need to import that certificate into Cloudbreak, \nor else Cloudbreak won't be able to communicate with your OpenStack. To import the certificate, place the certificate \nfile in the generated certs directory \n/certs/trusted/\n. The trusted directory does not exist by default, so you need to create it.\nCloudbreak will automatically pick up these certificates and import them into its truststore upon start.\n\n\nAvailability Zones and Region config\n\n\nBy default Cloudbreak uses \nRegionOne\n region with \nnova\n availability zone, but OpenStack supports multiple regions and multiple availability zones. You can customize Cloudbreak deployment and enable multiple\nregions and availability zones by creating an \nopenstack-zone.json\n under the \netc\n directory of Cloudbreak deployment (e.g. \n/var/lib/cloudbreak-deployment/etc/openstack-zone.json\n).\nYou can find an example of \nopenstack-zone.json\n containing two regions and four availability zones below:\n\n\n{\n  \nitems\n: [\n    {\n      \nname\n: \nMyRegionOne\n,\n      \nzones\n: [ \naz1\n, \naz2\n, \naz3\n]\n    },\n    {\n      \nname\n: \nMyRegionTwo\n,\n      \nzones\n: [ \nmyaz\n]\n    }\n  ]\n}\n\n\n\n\nIf the \netc\n directory does not exist under Cloudbreak deployment directory, then please create it. Restart is needed to pick up the changes done in \nopenstack-zone.json\n file. \n\n\nStart Cloudbreak Deployer\n\n\nTo start the Cloudbreak application, use the following command:\n\n\ncbd start\n\n\n\n\nThis will start all the Docker containers and initialize the application.\n\n\n\n\nThe first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.\n\n\n\n\nThe \ncbd start\n command includes the \ncbd generate\n command which applies the following steps:\n\n\n\n\ncreates the \ndocker-compose.yml\n file that describes the configuration of all the Docker containers needed for the Cloudbreak deployment.\n\n\ncreates the \nuaa.yml\n file that holds the configuration of the identity server used to authenticate users to Cloudbreak.\n\n\n\n\nValidate that Cloudbreak Deployer Has Started\n\n\nAfter the \ncbd start\n command finishes, check the following:\n\n\n\n\nPre-installed Cloudbreak Deployer version and health:\n\n\n\n\n   cbd doctor\n\n\n\n\n\n\nIf you need to run \ncbd update\n, refer to \nCloudbreak Deployer Update\n.\n\n\n\n\n\n\nCloudbreak Application logs:\n\n\n\n\n   cbd logs cloudbreak\n\n\n\n\n\n\nYou should see a line like this: \nStarted CloudbreakApplication in 36.823 seconds\n. Cloudbreak normally takes less than a minute to start.\n\n\n\n\nProvisioning Prerequisites\n\n\nGenerate a New SSH Key\n\n\nAll the instances created by Cloudbreak are configured to allow key-based SSH,\nso you'll need to provide an SSH public key that can be used later to SSH onto the instances in the clusters you'll create with Cloudbreak.\nYou can use one of your existing keys or you can generate a new one.\n\n\nTo generate a new SSH keypair:\n\n\nssh-keygen -t rsa -b 4096 -C \nyour_email@example.com\n\n# Creates a new ssh key, using the provided email as a label\n# Generating public/private rsa key pair.\n\n\n\n\n# Enter file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]\nYou'll be asked to enter a passphrase, but you can leave it empty.\n\n# Enter passphrase (empty for no passphrase): [Type a passphrase]\n# Enter same passphrase again: [Type passphrase again]\n\n\n\n\nAfter you enter a passphrase the keypair is generated. The output should look something like below. \n\n\n# Your identification has been saved in /Users/you/.ssh/id_rsa.\n# Your public key has been saved in /Users/you/.ssh/id_rsa.pub.\n# The key fingerprint is:\n# 01:0f:f4:3b:ca:85:sd:17:sd:7d:sd:68:9d:sd:a2:sd your_email@example.com\n\n\n\n\nLater you'll need to pass the \n.pub\n file's contents to Cloudbreak and use the private part to SSH to the instances\n\n\nProvisioning via Browser\n\n\nYou can log into the Cloudbreak application at \nhttps://\nPublic_IP\n/\n.\n\n\nThe main goal of the Cloudbreak UI is to easily create clusters on your own cloud provider account.\nThis description details the OpenStack setup - if you'd like to use a different cloud provider check out its manual.\n\n\nThis document explains the four steps that need to be followed to create Cloudbreak clusters from the UI:\n\n\n\n\nconnect your OpenStack account with Cloudbreak\n\n\ncreate some template resources on the UI that describe the infrastructure of your clusters\n\n\ncreate a blueprint that describes the HDP services in your clusters\n\n\nlaunch the cluster itself based on these resources\n\n\n\n\n\n\nIMPORTANT\n Make sure that you have sufficient qouta (CPU, network, etc) for the requested cluster size\n\n\n\n\nSetting up OpenStack credentials\n\n\nCloudbreak works by connecting your OpenStack account through so called \nCredentials\n, and then uses these credentials\n to create resources on your behalf. The credentials can be configured on the \nmanage credentials\n panel on the \nCloudbreak Dashboard.\n\n\nTo create a new OpenStack credential follow these steps:\n\n\n\n\nSelect the \nKeystone Version\n. For instance, select the \nv2\n\n\nFill out the new credential \nName\n\n\nOnly alphanumeric and lowercase characters (min 5, max 100 characters) can be applied\n\n\n\n\n\n\nCopy your OpenStack user name to the \nUser\n field\n\n\nCopy your OpenStack user password to the \nPassword\n field\n\n\nCopy your OpenStack tenant name to the \nTenant Name\n field\n\n\nCopy your OpenStack identity service (Keystone) endpoint (e.g. http://PUBLIC_IP:5000/v2.0) to the \nEndpoint\n field\n\n\nCopy your SSH public key to the \nSSH public key\n field\n\n\nThe SSH public key must be in OpenSSH format and it's private keypair can be used later to \nSSH onto every \ninstance\n of every cluster you'll create with this credential.\n\n\nThe \nSSH username\n for the OpenStack instances is \ncloudbreak\n.\n\n\n\n\n\n\n\n\n\n\nAny other parameter is optional here. You can read more about Keystone v3 \nhere\n.\n\n\nAPI Facing\n is the URL perspective in which the API is accessing data.\n\n\nPublic in account\n means that all the users belonging to your account will be able to use this credential to create \nclusters, but cannot delete it.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nInfrastructure templates\n\n\nAfter your OpenStack account is linked to Cloudbreak you can start creating resource templates that describe your \nclusters' infrastructure:\n\n\n\n\ntemplates\n\n\nnetworks\n\n\nsecurity groups\n\n\n\n\nWhen you create one of the above resources, \nCloudbreak does not make any requests to OpenStack. Resources are only\ncreated on OpenStack after the \ncreate cluster\n button has pushed.\n These templates are saved to Cloudbreak's \ndatabase and can be reused with multiple clusters to describe the infrastructure.\n\n\nTemplates\n\n\nTemplates describe the \ninstances of your cluster\n - the instance type and the attached volumes. A typical setup is\n to combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple\n large disks to the datanodes or have memory optimized instances for Spark nodes.\n\n\nThe instance templates can be configured on the \nmanage templates\n panel on the Cloudbreak Dashboard.\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to use this resource to create clusters, but cannot delete it.\n\n\nNetworks\n\n\nYour clusters can be created in their own \nnetworks\n or in one of your already existing one. If you choose an\nexisting network, it is possible to create a new subnet within the network. The subnet's IP range must be defined in\nthe \nSubnet (CIDR)\n field using the general CIDR notation. Here you can read more about \nOpenStack networking\n.\n\n\nCustom OpenStack Network\n\n\nIf you'd like to deploy a cluster to your OpenStack network you'll have to \ncreate a new network\n template on the\n\nmanage networks\n panel on the Cloudbreak Dashboard.\n\n\n\n\n\"Before launching an instance, you must create the necessary virtual network infrastructure...an instance uses a\npublic provider virtual network that connects to the physical network infrastructure...This network includes a DHCP\nserver that provides IP addresses to instances...The admin or other privileged user must create this network because\nit connects directly to the physical network infrastructure.\"\n\n\nHere you can read more about OpenStack \nvirtual network\n and \npublic provider network\n.\n\n\n\n\nYou have the following options to create a new network:\n\n\n\n\nCreate a new network and a new subnet\n: Every time a cluster is created with this kind of network setup a new network and a new subnet with the specified IP range will be created for the instances on OpenStack.\n\n\nCreate a new subnet in an existing network\n: Use this kind of network setup if you already have a network on OpenStack where you'd like to put the Cloudbreak created cluster but you'd like to have a separate subnet for it.\n\n\nUse an existing subnet in an existing network\n: Use this kind of network setup if you have an existing network with one or more subnets on OpenStack and you'd like to start the instances of a cluster in one of those subnets.\n\n\n\n\nExplanation of the parameters:\n\n\n\n\nName\n the name of the new network\n\n\nLength must be between 5 and 100 characters\n\n\nStarts with a lowercase alphabetic character\n\n\nCan contain lowercase alphanumeric and hyphens only\n\n\n\n\n\n\nSubnet (CIDR)\n With this field you define the IP address space usable by your VMs within the cluster. Cloudbreak supports the private address space defined in \nRFC1918\n. E.g. you can use 10.0.0.0/24\n\n\nFloating Pool ID\n \nFloating IPs\n  are not automatically allocated to instances by default, they needs to be attached to instances after creation. The Floating IPs are used to provide access to your VMs running on OpenStack. You can figure out the available network pools and their IDs by using the \nnova floating-ip-pool-list\n and \nneutron net-external-list\n or copy-pasting it from OpenStack Horizon UI. Such networks have the \nExternal Network\n field set to \nYes\n. If you are unable to find the ID then just consult with your OpenStack network administrator. Please note that if you do not set this field then your cluster might not be accessible.\n\n\nVirtual Network Identifier\n This is the ID of an existing virtual network on OpenStack where you would like to launch the cluster. (Must be provided for \nCreate a new subnet in an existing network\n and \nUse an existing subnet in an existing network\n)\n\n\nRouter Identifier\n Specify the router ID that shall interconnect your existing Network with the Subnet which will be created by CLoudbreak. (Must be provided for \nCreate a new subnet in an existing network\n).\n\n\nSubnet Identifier\n This is the ID of an existing subnet on OpenStack where you would like to launch the cluster. (Must be provided for \nUse an existing subnet in an existing network\n)\n\n\n\n\n\n\nIMPORTANT\n Please make sure the defined subnet here doesn't overlap with any of your already deployed subnet in the\n network, because the validation only happens after the cluster creation starts.\n\n\nIn case of existing subnet make sure you have enough room within your network space for the new instances. The\nprovided subnet CIDR will be ignored, but a proper CIDR range will be used.\n\n\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to use this network template\nto create clusters, but cannot delete it.\n\n\n\n\nNOTE\n The new networks are created on OpenStack only after the the cluster provisioning starts with the selected\nnetwork template.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nSecurity groups\n\n\nSecurity group templates are very similar to the \nSecurity Groups on OpenStack\n. \nThey describe the allowed inbound traffic \nto the instances in the cluster.\n Currently only one security group template can be selected for a Cloudbreak cluster \nand all the instances have a public IP address so all the instances in the cluster will belong to the same security \ngroup. This may change in a later release.\n\n\nDefault Security Group\n\n\nYou can also use the two pre-defined security groups in Cloudbreak.\n\n\nonly-ssh-and-ssl:\n all ports are locked down except for SSH and the selected Ambari Server HTTPS (you can't access Hadoop services \noutside of the network):\n\n\n\n\nSSH (22)\n\n\nHTTPS (443)\n\n\n\n\nCustom Security Group\n\n\nYou can define your own security group by adding all the ports, protocols and CIDR range you'd like to use. The rules\n defined here doesn't need to contain the internal rules, those are automatically added by Cloudbreak to the security\n  group on OpenStack.\n\n\nHadoop services :\n\n Ambari (8080)\n\n Consul (8500)\n\n NN (50070)\n\n RM Web (8088)\n\n Scheduler (8030RM)\n\n IPC (8050RM)\n\n Job history server (19888)\n\n HBase master (60000)\n\n HBase master web (60010)\n\n HBase RS (16020)\n\n HBase RS info (60030)\n\n Falcon (15000)\n\n Storm (8744)\n\n Hive metastore (9083)\n\n Hive server (10000)\n\n Hive server HTTP (10001)\n\n Accumulo master (9999)\n\n Accumulo Tserver (9997)\n\n Atlas (21000)\n\n KNOX (8443)\n\n Oozie (11000)\n\n Spark HS (18080)\n\n NM Web (8042)\n\n Zeppelin WebSocket (9996)\n\n Zeppelin UI (9995)\n\n Kibana (3080)\n* Elasticsearch (9200)\n\n\n\n\nIMPORTANT\n 443, 9443, and 22 ports needs to be there in every security group otherwise Cloudbreak won't be able to communicate with the provisioned cluster.\n\n\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to use this security group \ntemplate to create clusters, but cannot delete it.\n\n\n\n\nNOTE\n The security groups are created on OpenStack only after the cluster provisioning starts with the selected \nsecurity group template.\n\n\n\n\n\n\nFull size \nhere\n.\n/sub\n\n\nDefining Cluster Services\n\n\nBlueprints\n\n\nBlueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are \nused by Ambari\n.\n\n\nYou can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file, URL (an \nexample blueprint\n) or the \nwhole JSON can be written in the \nJSON text\n box.\n\n\nThe host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.\n\n\n\n\nNOTE:\n It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will \nfill that with a default value.\n\n\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to use this blueprint to \ncreate clusters, but cannot delete or modify it.\n\n\n\n\nFull size \nhere\n.\n\n\nA blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications.\n\nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations...etc. that won't be applicable to the Cloudbreak cluster\n\n\nCluster deployment\n\n\nAfter all the cluster resources are configured you can deploy a new HDP cluster.\n\n\nHere is a \nbasic flow for cluster creation on Cloudbreak Web UI\n:\n\n\n\n\nStart by selecting a previously created OpenStack credential in the header.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\n\n\nOpen \ncreate cluster\n\n\n\n\nConfigure Cluster\n tab\n\n\n\n\nFill out the new cluster \nname\n\n\nThe name must be between 5 and 40 characters long and must satisfy the followings:\n\n\nStarts with a lowercase alphabetic character\n\n\nCan contain lowercase alphanumeric and hyphens only\n\n\n\n\n\n\n\n\n\n\nSelect one of your \nRegion\n where you like your cluster be provisioned\n\n\nClick on the \nSetup Network and Security\n button\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to see the created cluster on\n the UI, but cannot delete or modify it.\n\n\n\n\n\n\n\n\nSetup Network and Security\n tab\n\n\n\n\nSelect one of your previously created networks\n\n\nClick on the \nChoose Blueprint\n button\n\n\nIf \nEnable security\n is checked as well, Cloudbreak will install Key Distribution Center (KDC) and the cluster will \nbe Kerberized. See more about it in the \nKerberos\n section of this documentation.\n\n\n\n\n\n\n\n\nChoose Blueprint\n tab\n\n\n\n\nSelect one of the blueprints\n\n\nAfter you've selected a \nBlueprint\n, you should be able to configure:\n\n\nthe templates\n\n\nthe securitygroups\n\n\nthe number of nodes for all of the host groups in the blueprint\n\n\n\n\n\n\nYou need to select where you want to install the Ambari server to. Only 1 host group can be selected.\n   If you want to install the Ambari server to a separate node, you need to extend your blueprint with a new host group\n   which contains only 1 service: HDFS_CLIENT and select this host group for the Ambari server. Note: this host group cannot be scaled so \n   it is not advised to select a 'slave' host group for this purpose.\n\n\nClick on the \nReview and Launch\n button\n\n\n\n\nReview and Launch\n tab\n\n\n\n\nAfter the \ncreate and start cluster\n button has clicked Cloudbreak will start to create the cluster's resources on \n your OpenStack account.\n\n\n\n\nCloudbreak uses \nOpenStack\n to create the resources - you can check out the resources created by Cloudbreak\n on the \nInstances\n page of your OpenStack \nProject\n.\n\n\n\nFull size \nhere\n.\n\n\nBesides these you can check the progress on the Cloudbreak Web UI itself if you open the new cluster's \nEvent History\n.\n\n\n\nFull size \nhere\n.\n\n\nAdvanced options\n\n\nAmbari Username\n This user will be used as admin user in Ambari. You can log in using this username on the Ambari UI.\n\n\nAmbari Password\n The password associated with the Ambari username. This password will be also the default password for all required passwords which are not specified in the blueprint. E.g: hive DB password.\n\n\nConnector Variant\n Cloudbreak provides two implementation for creating OpenStack cluster\n\n\n\n\nHEAT\n using \nHEAT\n template to create the resources\n\n\nNATIVE\n using API calls to create the resources\n\n\n\n\n\n\nThe HEAT variant utilizes the Heat templating to launch a stack, but the NATIVE variant starts the cluster\n  by using a sequence of API calls without Heat to achieve the same result, although both of them are using the same \n  authentication and credential management.\n\n\n\n\nMinimum cluster size\n The provisioning strategy in case the cloud provider cannot allocate all the requested nodes.\n\n\nValidate blueprint\n This is selected by default. Cloudbreak validates the Ambari blueprint in this case.\n\n\nCustom Image\n If you enable this, you can override the default image for provision.\n\n\nShipyard enabled cluster\n This is selected by default. Cloudbreak will start a \nShipyard\n container which helps you to manage your containers.\n\n\nConfig recommendation strategy\n Strategy for how configuration recommendations will be applied. Recommended \nconfigurations gathered by the response of the stack advisor. \n\n\n\n\nNEVER_APPLY\n               Configuration recommendations are ignored with this option.\n\n\nONLY_STACK_DEFAULTS_APPLY\n Applies only on the default configurations for all included services.\n\n\nALWAYS_APPLY\n              Applies on all configuration properties.\n\n\n\n\nCluster termination\n\n\nYou can terminate running or stopped clusters with the \nterminate\n button in the cluster details.\n\n\n\n\nIMPORTANT\n Always use Cloudbreak to terminate the cluster. If that fails for some reason, try to delete the \nOpenStack instances first. Instances are started in an Auto Scaling Group so they may be restarted if you terminate an \ninstance manually!\n\n\n\n\nSometimes Cloudbreak cannot synchronize its state with the cluster state at the cloud provider and the cluster can't\n be terminated. In this case the \nForced termination\n option can help to terminate the cluster at the Cloudbreak \n side. \nIf it has happened:\n\n\n\n\nYou should check the related resources at the OpenStack\n\n\nIf it is needed you need to manually remove resources from there\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nInteractive mode / Cloudbreak Shell\n\n\nThe goal with the Cloudbreak Shell (Cloudbreak CLI) was to provide an interactive command line tool which supports:\n\n\n\n\nall functionality available through the REST API or Cloudbreak Web UI\n\n\nmakes possible complete automation of management task via scripts\n\n\ncontext aware command availability\n\n\ntab completion\n\n\nrequired/optional parameter support\n\n\nhint command to guide you on the usual path\n\n\n\n\nStart Cloudbreak Shell\n\n\nTo start the Cloudbreak CLI use the following commands:\n\n\n\n\nOpen your \ncloudbreak-deployment\n directory if it is needed. For example:\n\n\n\n\n   cd cloudbreak-deployment\n\n\n\n\n\n\nStart the \ncbd\n from here if it is needed\n\n\n\n\n   cbd start\n\n\n\n\n\n\nIn the root of your \ncloudbreak-deployment\n folder apply:\n\n\n\n\n   cbd util cloudbreak-shell\n\n\n\n\n\n\nAt the very first time it will take for a while, because of need to download all the necessary docker images.\n\n\n\n\nThis will launch the Cloudbreak shell inside a Docker container then it is ready to use.\n\n\n\nFull size \nhere\n.\n\n\n\n\nIMPORTANT You have to copy all your files into the \ncbd\n working directory, what you would like to use in shell.\n For \nexample if your \ncbd\n working directory is \n~/cloudbreak-deployment\n then copy your \nblueprint JSON, public ssh key \nfile...etc.\n to here. You can refer to these files with their names from the shell.\n\n\n\n\nAutocomplete and Hints\n\n\nCloudbreak Shell helps you with \nhint messages\n from the very beginning, for example:\n\n\ncloudbreak-shell\nhint\nHint: Add a blueprint with the 'blueprint create' command or select an existing one with 'blueprint select'\ncloudbreak-shell\n\n\n\n\n\nBeyond this you can use the \nautocompletion (double-TAB)\n as well:\n\n\ncloudbreak-shell\ncredential create --\ncredential create --AWS          credential create --AZURE        credential create --EC2          credential create --GCP          credential create --OPENSTACK\n\n\n\n\nProvisioning via CLI\n\n\nSetting up OpenStack credential\n\n\nCloudbreak works by connecting your OpenStack account through so called Credentials, and then uses these credentials to \ncreate resources on your behalf. Credentials can be configured with the following command for example:\n\n\ncredential create --OPENSTACK --name my-os-credential --description \nsample description\n --userName \nOpenStack username\n --password \nOpenStack password\n --tenantName \nOpenStack tenant name\n --endPoint \nOpenStack Identity Service (Keystone) endpoint\n --sshKeyString \nssh-rsa AAAAB****etc\n\n\n\n\n\n\n\nNOTE\n that Cloudbreak \ndoes not set your cloud user details\n - we work around the concept of \nOpenStack's \nauthentication\n. You should have already valid OpenStack credentials. You can \nfind further details \nhere\n.\n\n\n\n\nAlternatives to provide \nSSH Key\n:\n\n\n\n\nyou can upload your public key from an url: \n\u2014sshKeyUrl\n \n\n\nor you can add the path of your public key: \n\u2014sshKeyPath\n\n\n\n\nOther available option:\n\n\n--facing\n URL perspective in which the API is accessing data, allowed types are: public, admin and internal.\n\n\n\n\nNOTE\n If facing not specified OpenStack default value will be applied.\n\n\n\n\nYou can check whether the credential was created successfully\n\n\ncredential list\n\n\n\n\nYou can switch between your existing credentials\n\n\ncredential select --name my-os-credential\n\n\n\n\nInfrastructure templates\n\n\nAfter your OpenStack account is linked to Cloudbreak you can start creating resource templates that describe your \nclusters' infrastructure:\n\n\n\n\nsecurity groups\n\n\nnetworks\n\n\ntemplates\n\n\n\n\nWhen you create one of the above resources, \nCloudbreak does not make any requests to OpenStack. Resources are only \ncreated on OpenStack after the \ncluster create\n has applied.\n These templates are saved to Cloudbreak's database and\n can be reused with multiple clusters to describe the infrastructure.\n\n\nTemplates\n\n\nTemplates describe the \ninstances of your cluster\n - the instance type and the attached volumes. A typical setup is\n to combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple\n large disks to the datanodes or have memory optimized instances for Spark nodes.\n\n\nA template can be used repeatedly to create identical copies of the same stack (or to use as a foundation to start a \nnew stack). Templates can be configured with the following command for example:\n\n\ntemplate create --OPENSTACK --name my-os-template --description \nsample description\n --instanceType m1.medium \n--volumeSize 100 --volumeCount 1\n\n\n\n\nOther available option here is \n--publicInAccount\n. If it is true, all the users belonging to your account will be able\n to use this template to create clusters, but cannot delete it.\n\n\nYou can check whether the template was created successfully\n\n\ntemplate list\n\n\n\n\nNetworks\n\n\nYour clusters can be created in their own \nnetworks\n or in one of your already existing one. If you choose an \nexisting network, it is possible to create a new subnet within the network. The subnet's IP range must be defined in \nthe \nSubnet (CIDR)\n field using the general CIDR notation. Here you can read more about \nOpenStack networking\n.\n\n\nCustom OpenStack Network\n\n\nIf you'd like to deploy a cluster to your OpenStack network you'll have to \ncreate a new network\n template.\n\n\nA network also can be used repeatedly to create identical copies of the same stack (or to use as a foundation to \nstart a new stack).\n\n\n\n\n\"Before launching an instance, you must create the necessary virtual network infrastructure...an instance uses a \npublic provider virtual network that connects to the physical network infrastructure...This network includes a DHCP \nserver that provides IP addresses to instances...The admin or other privileged user must create this network because \nit connects directly to the physical network infrastructure.\"\n\n\nHere you can read more about OpenStack \nvirtual network\n and \npublic provider network\n.\n\n\n\n\nnetwork create --OPENSTACK --name my-os-network --description openstack-network --publicNetID \nid of an OpenStack \npublic network\n --subnet 10.0.0.0/16\n\n\n\n\n\n\nIMPORTANT\n\n\n\n\nIn case of existing subnet all three parameters must be provided, with new subnet only two are required.\n\n\nPlease make sure the defined subnet here doesn't overlap with any of your already deployed subnet in the\n network, because the validation only happens after the cluster creation starts.\n\n\nIn case of existing subnet make sure you have enough room within your network space for the new instances. The \nprovided subnet CIDR will be ignored, but a proper CIDR range will be used.\n\n\n\n\nNOTE\n The new networks are created on OpenStack only after the the cluster provisioning starts with the selected \nnetwork template.\n\n\n\n\nOther available options here:\n\n\n--networkId\n This must be an ID of an existing OpenStack virtual network.\n\n\n--routerId\n Your virtual network router ID (must be provided in case of existing virtual network).\n\n\n--subnetId\n Your subnet ID within your virtual network. If the identifier is provided, the \nSubnet \n(CIDR)\n will be ignored. Leave it blank if you'd like to create a new subnet within the virtual network with the \nprovided \nSubnet (CIDR)\n range.\n\n\n--publicInAccount\n If it is true, all the users belonging to your account will be able to use this template to create clusters, but cannot delete it.\n\n\nYou can check whether the network was created successfully\n\n\nnetwork list\n\n\n\n\nDefining Cluster Services\n\n\nBlueprints\n\n\nBlueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are \nused by Ambari\n.\n\n\nYou can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file or URL (an \nexample blueprint\n).\n\n\nThe host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.\n\n\n\n\nNOTE:\n It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will fill that with a default value.\n\n\n\n\nblueprint create --name my-blueprint --description \nsample description\n --file \nthe path of the blueprint\n\n\n\n\n\nOther available options:\n\n\n--url\n the url of the blueprint\n\n\n--publicInAccount\n If it is true, all the users belonging to your account will be able to use this blueprint to create \nclusters, but cannot delete it.\n\n\nYou can check whether the blueprint was created successfully\n\n\nblueprint list\n\n\n\n\nA blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications.\n\nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations..etc. that won't be applicable to the Cloudbreak cluster.\n\n\nMetadata Show\n\n\nYou can check the stack metadata with\n\n\nstack metadata --name myawsstack --instancegroup master\n\n\n\n\nOther available options:\n\n\n--id\n In this case you can select a stack with id.\n\n\n--outputType\n In this case you can modify the outputformat of the command (RAW or JSON). \n\n\nCluster deployment\n\n\nAfter all the cluster resources are configured you can deploy a new HDP cluster. The following sub-sections show \nyou a \nbasic flow for cluster creation with Cloudbreak Shell\n.\n\n\nSelect credential\n\n\nSelect one of your previously created OpenStack credential:\n\n\ncredential select --name my-os-credential\n\n\n\n\nSelect blueprint\n\n\nSelect one of your previously created blueprint which fits your needs:\n\n\nblueprint select --name multi-node-hdfs-yarn\n\n\n\n\nConfigure instance groups\n\n\nYou must configure instance groups before provisioning. An instance group define a group of nodes with a specified \ntemplate and security group. Usually we create instance groups for host groups in the blueprint. For Ambari server only 1 host group can be specified.\nIf you want to install the Ambari server to a separate node, you need to extend your blueprint with a new host group\nwhich contains only 1 service: HDFS_CLIENT and select this host group for the Ambari server. Note: this host group cannot be scaled so \nit is not advised to select a 'slave' host group for this purpose.\n\n\ninstancegroup configure --instanceGroup master --nodecount 1 --templateName minviable-aws --securityGroupName all-services-port --ambariServer true\ninstancegroup configure --instanceGroup slave_1 --nodecount 1 --templateName minviable-aws --securityGroupName all-services-port --ambariServer false\n\n\n\n\nOther available option:\n\n\n--templateId\n Id of the template\n\n\nSelect network\n\n\nSelect one of your previously created network which fits your needs or a default one:\n\n\nnetwork select --name my-os-network\n\n\n\n\nCreate stack / Create cloud infrastructure\n\n\nStack means the running cloud infrastructure that is created based on the instance groups configured earlier \n(\ncredential\n, \ninstancegroups\n, \nnetwork\n, \nsecuritygroup\n). Same as in case of the API or UI the new cluster will \nuse your templates and by using OpenStack will launch your cloud stack. Use the following command to create a \nstack to be used with your Hadoop cluster:\n\n\nstack create --OPENSTACK --name myosstack --region local\n\n\n\n\nThe infrastructure is created asynchronously, the state of the stack can be checked with the stack \nshow command\n. If \nit reports AVAILABLE, it means that the virtual machines and the corresponding infrastructure is running at the cloud provider.\n\n\nOther available option is:\n\n\n--wait\n - in this case the create command will return only after the process has finished. \n\n\nCreate a Hadoop cluster / Cloud provisioning\n\n\nYou are almost done! One more command and your Hadoop cluster is starting!\n Cloud provisioning is done once the \ncluster is up and running. The new cluster will use your selected blueprint and install your custom Hadoop cluster \nwith the selected components and services.\n\n\ncluster create --description \nmy first cluster\n\n\n\n\n\nOther available option is \n--wait\n - in this case the create command will return only after the process has finished. \n\n\nYou are done!\n You have several opportunities to check the progress during the infrastructure creation then \nprovisioning:\n\n\n\n\nCloudbreak uses \nOpenStack\n to create the resources - you can check out the resources created by Cloudbreak on\n the OpenStack Console Instances page.\n\n\n\n\nFor example:\n\n\n\nFull size \nhere\n.\n\n\n\n\nIf stack then cluster creation have successfully done, you can check the Ambari Web UI. However you need to know the \nAmbari IP (for example: \nhttp://172.16.252.59:8080\n): \n\n\nYou can get the IP from the CLI as a result (\nambariServerIp 172.16.252.59\n) of the following command:\n\n\n\n\n\n\n\n\n         cluster show\n\n\n\n\nFor example:\n\n\n\nFull size \nhere\n.\n\n\n\n\nBesides these you can check the entire progress and the Ambari IP as well on the Cloudbreak Web UI itself. Open the \nnew cluster's \ndetails\n and its \nEvent History\n here.\n\n\n\n\nFor example:\n\n\n\nFull size \nhere\n.\n\n\nStop Cluster\n\n\nYou have the ability to \nstop your existing stack then its cluster\n if you want to suspend the work on it.\n\n\nSelect a stack for example with its name:\n\n\nstack select --name my-stack\n\n\n\n\nOther available option to define a stack is its \n--id\n.\n\n\nEvery time you should stop the \ncluster\n first then the \nstack\n. So apply following commands to stop the previously \nselected stack:\n\n\ncluster stop\nstack stop\n\n\n\n\nRestart Cluster\n\n\nSelect your stack that you would like to restart\n after this you can apply:\n\n\nstack start\n\n\n\n\nAfter the stack has successfully restarted, you can \nrestart the related cluster as well\n:\n\n\ncluster start\n\n\n\n\nUpscale Cluster\n\n\nIf you need more instances to your infrastructure, you can \nupscale your selected stack\n:\n\n\nstack node --ADD --instanceGroup host_group_slave_1 --adjustment 6\n\n\n\n\nOther available option is \n--withClusterUpScale\n - this indicates also a cluster upscale after the stack upscale. You\n can upscale the related cluster separately if you want to do this:\n\n\ncluster node --ADD --hostgroup host_group_slave_1 --adjustment 6\n\n\n\n\nDownscale Cluster\n\n\nYou also can reduce the number of instances in your infrastructure. \nAfter you selected your stack\n:\n\n\ncluster node --REMOVE  --hostgroup host_group_slave_1 --adjustment -2\n\n\n\n\nOther available option is \n--withStackDownScale\n - this indicates also a stack downscale after the cluster downscale.\n You can downscale the related stack separately if you want to do this:\n\n\nstack node --REMOVE  --instanceGroup host_group_slave_1 --adjustment -2\n\n\n\n\nCluster Termination\n\n\nYou can terminate running or stopped clusters with\n\n\nstack delete --name myawsstack\n\n\n\n\nOther available option is \n--wait\n - in this case the terminate command will return only after the process has finished. \n\n\n\n\nIMPORTANT:\n Always use Cloudbreak to terminate the cluster. If that fails for some reason, try to delete the \nCloudFormation stack first. Instances are started in an Auto Scaling Group so they may be restarted if you terminate an instance manually!\n\n\n\n\nSometimes Cloudbreak cannot synchronize its state with the cluster state at the cloud provider and the cluster can't\n be terminated. In this case the \nForced termination\n option on the Cloudbreak Web UI can help to terminate the cluster\n  at the Cloudbreak side. \nIf it has happened:\n\n\n\n\nYou should check the related resources at the AWS CloudFormation\n\n\nIf it is needed you need to manually remove resources from there\n\n\n\n\nSilent Mode\n\n\nWith Cloudbreak Shell you can execute script files as well. A script file contains shell commands and can \nbe executed with the \nscript\n cloudbreak shell command\n\n\nscript \nyour script file\n\n\n\n\n\nor with the \ncbd util cloudbreak-shell-quiet\n command\n\n\ncbd util cloudbreak-shell-quiet \n example.sh\n\n\n\n\n\n\nIMPORTANT:\n You have to copy all your files into the \ncbd\n working directory, what you would like to use in shell.\n For example if your \ncbd\n working directory is ~/cloudbreak-deployment then copy your script file to here.\n\n\n\n\nExample\n\n\nThe following example creates a hadoop cluster with \nhdp-small-default\n blueprint on \nm1.large\n instances with 2X100G\n attached disks on \nosnetwork\n network using \nall-services-port\n security group. You should copy your ssh public key \n file into your \ncbd\n working directory with name \nid_rsa.pub\n and change the \n...\n parts with your OpenStack \n credential and network details.\n\n\ncredential create --OPENSTACK --name my-os-credential --description \ncredentail description\n --userName \nOpenStack username\n --password \nOpenStack password\n --tenantName \nOpenStack tenant name\n --endPoint \nOpenStack Identity Service (Keystone) endpoint\n --sshKeyPath \npath of your public SSH key file\n\ncredential select --name my-os-credential\ntemplate create --OPENSTACK --name ostemplate --description openstack-template --instanceType m1.large --volumeSize 100 --volumeCount 2\nblueprint select --name hdp-small-default\ninstancegroup configure --instanceGroup host_group_master_1 --nodecount 1 --templateName ostemplate --securityGroupName all-services-port --ambariServer true\ninstancegroup configure --instanceGroup host_group_master_2 --nodecount 1 --templateName ostemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_master_3 --nodecount 1 --templateName ostemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_client_1  --nodecount 1 --templateName ostemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_slave_1 --nodecount 3 --templateName ostemplate --securityGroupName all-services-port --ambariServer false\nnetwork create --OPENSTACK --name osnetwork --description openstack-network --publicNetID \nid of an OpenStack public network\n --subnet 10.0.0.0/16\nnetwork select --name osnetwork\nstack create --OPENSTACK --name my-first-stack --region local --wait true\ncluster create --description \nMy first cluster\n --wait true\n\n\n\n\nCongratulations!\n Your cluster should now be up and running on this way as well. To learn more about Cloudbreak and \nprovisioning, we have some \ninteresting insights\n for you.", 
            "title": "OpenStack"
        }, 
        {
            "location": "/openstack/#openstack-supported-versions", 
            "text": "Cloudbreak was tested against the following versions of  Red Hat Distribution of OpenStack  (RDO):   Juno  Kilo  Liberty  Mitaka   Cloudbreak requires that the  standard components are installed and configured on OpenStack:   Keystone V2 or Keystone V3  Neutron (self-service and provider networking)  Nova (KVM or Xen hypervisor)  Glance  Cinder (optional)  Heat (optional, but it is highly recommended, since provisioning through native api calls will be deprecated in the future)", 
            "title": "OpenStack Supported Versions"
        }, 
        {
            "location": "/openstack/#openstack-images", 
            "text": "We have pre-built cloud images for OpenStack with the Cloudbreak Deployer pre-installed and with Cloudbreak\npre-installed. Following steps will guide you through the launch of the images then the needed configuration.   Alternatively, instead of using the pre-built cloud image, you can install Cloudbreak Deployer on your own VM. See\n  install the Cloudbreak Deployer  for more information.   Please make sure you opened the following ports on your  security group :   SSH (22)  Cloudbreak (443)", 
            "title": "OpenStack Images"
        }, 
        {
            "location": "/openstack/#openstack-image-details", 
            "text": "", 
            "title": "OpenStack Image Details"
        }, 
        {
            "location": "/openstack/#cloudbreak-deployer-image", 
            "text": "", 
            "title": "Cloudbreak Deployer image"
        }, 
        {
            "location": "/openstack/#cloudbreak-image", 
            "text": "", 
            "title": "Cloudbreak image"
        }, 
        {
            "location": "/openstack/#import-the-image-into-your-openstack", 
            "text": "", 
            "title": "Import the image into your OpenStack"
        }, 
        {
            "location": "/openstack/#cloudbreak-deployer-import", 
            "text": "export OS_IMAGE_NAME= add_a_name_to_your_new_image \nexport OS_USERNAME= your_os_user_name \nexport OS_AUTH_URL= http://.../v2.0 \nexport OS_TENANT_NAME= your_os_tenant_name   Import the new image into your OpenStack:  glance image-create --name  $OS_IMAGE_NAME  --file  $CBD_LATEST_IMAGE  --disk-format qcow2 --container-format bare\n--progress   Minimum and Recommended VM requirements :  8GB RAM, 10GB disk, 2 cores    Full size  here .", 
            "title": "Cloudbreak Deployer import"
        }, 
        {
            "location": "/openstack/#cloudbreak-import", 
            "text": "export CB_LATEST_IMAGE_NAME= file_name_of_the_above_cloudbreak_image \nexport OS_USERNAME= your_os_user_name \nexport OS_AUTH_URL= http://.../v2.0 \nexport OS_TENANT_NAME= your_os_tenant_name   Import the new image into your OpenStack:  glance image-create --name  $CB_LATEST_IMAGE_NAME  --file  $CB_LATEST_IMAGE  --disk-format qcow2\n--container-format bare --progress", 
            "title": "Cloudbreak import"
        }, 
        {
            "location": "/openstack/#openstack-setup", 
            "text": "Before configuring Cloudbreak Deployer, you should know that:   The default SSH username for the OpenStack instances is  cloudbreak .  Cloudbreak Deployer location on the launched EC2 instance is  /var/lib/cloudbreak-deployment . This is the\n   cbd  root folder.  You must execute all  cbd  actions from the  cbd  root folder as a  cloudbreak  user.", 
            "title": "OpenStack Setup"
        }, 
        {
            "location": "/openstack/#set-up-cloudbreak-deployer", 
            "text": "You should have already installed the Cloudbreak Deployer either by  using the OpenStack Cloud Images  or by installing the Cloudbreak Deployer  manually on your own VM.  If you have your own installed VM, check the  Initialize your Profile \nsection here before starting the provisioning.  You can  connect to the previously created  cbd  VM .  To open the  cloudbreak-deployment  directory, run:  cd /var/lib/cloudbreak-deployment/  This directory contains configuration files and the supporting binaries for Cloudbreak Deployer.", 
            "title": "Set up Cloudbreak Deployer"
        }, 
        {
            "location": "/openstack/#initialize-your-profile", 
            "text": "First, initialize deployer by creating a  Profile  file with the following content:  export UAA_DEFAULT_SECRET='[SECRET]'\nexport UAA_DEFAULT_USER_PW='[PASSWORD]'\nexport PUBLIC_IP='[PUBLIC_IP]'  The  PUBLIC_IP  is mandatory, because it is used to access the Cloudbreak UI.", 
            "title": "Initialize Your Profile"
        }, 
        {
            "location": "/openstack/#openstack-specific-configuration", 
            "text": "Make sure that the  VM image used by Cloudbreak is imported on your OpenStack .", 
            "title": "OpenStack-specific Configuration"
        }, 
        {
            "location": "/openstack/#using-self-signed-certificates", 
            "text": "If your OpenStack is secured with a self-signed certificate, you need to import that certificate into Cloudbreak, \nor else Cloudbreak won't be able to communicate with your OpenStack. To import the certificate, place the certificate \nfile in the generated certs directory  /certs/trusted/ . The trusted directory does not exist by default, so you need to create it.\nCloudbreak will automatically pick up these certificates and import them into its truststore upon start.", 
            "title": "Using Self-signed Certificates"
        }, 
        {
            "location": "/openstack/#availability-zones-and-region-config", 
            "text": "By default Cloudbreak uses  RegionOne  region with  nova  availability zone, but OpenStack supports multiple regions and multiple availability zones. You can customize Cloudbreak deployment and enable multiple\nregions and availability zones by creating an  openstack-zone.json  under the  etc  directory of Cloudbreak deployment (e.g.  /var/lib/cloudbreak-deployment/etc/openstack-zone.json ).\nYou can find an example of  openstack-zone.json  containing two regions and four availability zones below:  {\n   items : [\n    {\n       name :  MyRegionOne ,\n       zones : [  az1 ,  az2 ,  az3 ]\n    },\n    {\n       name :  MyRegionTwo ,\n       zones : [  myaz ]\n    }\n  ]\n}  If the  etc  directory does not exist under Cloudbreak deployment directory, then please create it. Restart is needed to pick up the changes done in  openstack-zone.json  file.", 
            "title": "Availability Zones and Region config"
        }, 
        {
            "location": "/openstack/#start-cloudbreak-deployer", 
            "text": "To start the Cloudbreak application, use the following command:  cbd start  This will start all the Docker containers and initialize the application.   The first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.   The  cbd start  command includes the  cbd generate  command which applies the following steps:   creates the  docker-compose.yml  file that describes the configuration of all the Docker containers needed for the Cloudbreak deployment.  creates the  uaa.yml  file that holds the configuration of the identity server used to authenticate users to Cloudbreak.", 
            "title": "Start Cloudbreak Deployer"
        }, 
        {
            "location": "/openstack/#validate-that-cloudbreak-deployer-has-started", 
            "text": "After the  cbd start  command finishes, check the following:   Pre-installed Cloudbreak Deployer version and health:      cbd doctor   If you need to run  cbd update , refer to  Cloudbreak Deployer Update .    Cloudbreak Application logs:      cbd logs cloudbreak   You should see a line like this:  Started CloudbreakApplication in 36.823 seconds . Cloudbreak normally takes less than a minute to start.", 
            "title": "Validate that Cloudbreak Deployer Has Started"
        }, 
        {
            "location": "/openstack/#provisioning-prerequisites", 
            "text": "", 
            "title": "Provisioning Prerequisites"
        }, 
        {
            "location": "/openstack/#generate-a-new-ssh-key", 
            "text": "All the instances created by Cloudbreak are configured to allow key-based SSH,\nso you'll need to provide an SSH public key that can be used later to SSH onto the instances in the clusters you'll create with Cloudbreak.\nYou can use one of your existing keys or you can generate a new one.  To generate a new SSH keypair:  ssh-keygen -t rsa -b 4096 -C  your_email@example.com \n# Creates a new ssh key, using the provided email as a label\n# Generating public/private rsa key pair.  # Enter file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]\nYou'll be asked to enter a passphrase, but you can leave it empty.\n\n# Enter passphrase (empty for no passphrase): [Type a passphrase]\n# Enter same passphrase again: [Type passphrase again]  After you enter a passphrase the keypair is generated. The output should look something like below.   # Your identification has been saved in /Users/you/.ssh/id_rsa.\n# Your public key has been saved in /Users/you/.ssh/id_rsa.pub.\n# The key fingerprint is:\n# 01:0f:f4:3b:ca:85:sd:17:sd:7d:sd:68:9d:sd:a2:sd your_email@example.com  Later you'll need to pass the  .pub  file's contents to Cloudbreak and use the private part to SSH to the instances", 
            "title": "Generate a New SSH Key"
        }, 
        {
            "location": "/openstack/#provisioning-via-browser", 
            "text": "You can log into the Cloudbreak application at  https:// Public_IP / .  The main goal of the Cloudbreak UI is to easily create clusters on your own cloud provider account.\nThis description details the OpenStack setup - if you'd like to use a different cloud provider check out its manual.  This document explains the four steps that need to be followed to create Cloudbreak clusters from the UI:   connect your OpenStack account with Cloudbreak  create some template resources on the UI that describe the infrastructure of your clusters  create a blueprint that describes the HDP services in your clusters  launch the cluster itself based on these resources    IMPORTANT  Make sure that you have sufficient qouta (CPU, network, etc) for the requested cluster size", 
            "title": "Provisioning via Browser"
        }, 
        {
            "location": "/openstack/#setting-up-openstack-credentials", 
            "text": "Cloudbreak works by connecting your OpenStack account through so called  Credentials , and then uses these credentials\n to create resources on your behalf. The credentials can be configured on the  manage credentials  panel on the \nCloudbreak Dashboard.  To create a new OpenStack credential follow these steps:   Select the  Keystone Version . For instance, select the  v2  Fill out the new credential  Name  Only alphanumeric and lowercase characters (min 5, max 100 characters) can be applied    Copy your OpenStack user name to the  User  field  Copy your OpenStack user password to the  Password  field  Copy your OpenStack tenant name to the  Tenant Name  field  Copy your OpenStack identity service (Keystone) endpoint (e.g. http://PUBLIC_IP:5000/v2.0) to the  Endpoint  field  Copy your SSH public key to the  SSH public key  field  The SSH public key must be in OpenSSH format and it's private keypair can be used later to  SSH onto every \ninstance  of every cluster you'll create with this credential.  The  SSH username  for the OpenStack instances is  cloudbreak .      Any other parameter is optional here. You can read more about Keystone v3  here .  API Facing  is the URL perspective in which the API is accessing data.  Public in account  means that all the users belonging to your account will be able to use this credential to create \nclusters, but cannot delete it.    Full size  here .", 
            "title": "Setting up OpenStack credentials"
        }, 
        {
            "location": "/openstack/#infrastructure-templates", 
            "text": "After your OpenStack account is linked to Cloudbreak you can start creating resource templates that describe your \nclusters' infrastructure:   templates  networks  security groups   When you create one of the above resources,  Cloudbreak does not make any requests to OpenStack. Resources are only\ncreated on OpenStack after the  create cluster  button has pushed.  These templates are saved to Cloudbreak's \ndatabase and can be reused with multiple clusters to describe the infrastructure.  Templates  Templates describe the  instances of your cluster  - the instance type and the attached volumes. A typical setup is\n to combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple\n large disks to the datanodes or have memory optimized instances for Spark nodes.  The instance templates can be configured on the  manage templates  panel on the Cloudbreak Dashboard.  If  Public in account  is checked all the users belonging to your account will be able to use this resource to create clusters, but cannot delete it.  Networks  Your clusters can be created in their own  networks  or in one of your already existing one. If you choose an\nexisting network, it is possible to create a new subnet within the network. The subnet's IP range must be defined in\nthe  Subnet (CIDR)  field using the general CIDR notation. Here you can read more about  OpenStack networking .  Custom OpenStack Network  If you'd like to deploy a cluster to your OpenStack network you'll have to  create a new network  template on the manage networks  panel on the Cloudbreak Dashboard.   \"Before launching an instance, you must create the necessary virtual network infrastructure...an instance uses a\npublic provider virtual network that connects to the physical network infrastructure...This network includes a DHCP\nserver that provides IP addresses to instances...The admin or other privileged user must create this network because\nit connects directly to the physical network infrastructure.\"  Here you can read more about OpenStack  virtual network  and  public provider network .   You have the following options to create a new network:   Create a new network and a new subnet : Every time a cluster is created with this kind of network setup a new network and a new subnet with the specified IP range will be created for the instances on OpenStack.  Create a new subnet in an existing network : Use this kind of network setup if you already have a network on OpenStack where you'd like to put the Cloudbreak created cluster but you'd like to have a separate subnet for it.  Use an existing subnet in an existing network : Use this kind of network setup if you have an existing network with one or more subnets on OpenStack and you'd like to start the instances of a cluster in one of those subnets.   Explanation of the parameters:   Name  the name of the new network  Length must be between 5 and 100 characters  Starts with a lowercase alphabetic character  Can contain lowercase alphanumeric and hyphens only    Subnet (CIDR)  With this field you define the IP address space usable by your VMs within the cluster. Cloudbreak supports the private address space defined in  RFC1918 . E.g. you can use 10.0.0.0/24  Floating Pool ID   Floating IPs   are not automatically allocated to instances by default, they needs to be attached to instances after creation. The Floating IPs are used to provide access to your VMs running on OpenStack. You can figure out the available network pools and their IDs by using the  nova floating-ip-pool-list  and  neutron net-external-list  or copy-pasting it from OpenStack Horizon UI. Such networks have the  External Network  field set to  Yes . If you are unable to find the ID then just consult with your OpenStack network administrator. Please note that if you do not set this field then your cluster might not be accessible.  Virtual Network Identifier  This is the ID of an existing virtual network on OpenStack where you would like to launch the cluster. (Must be provided for  Create a new subnet in an existing network  and  Use an existing subnet in an existing network )  Router Identifier  Specify the router ID that shall interconnect your existing Network with the Subnet which will be created by CLoudbreak. (Must be provided for  Create a new subnet in an existing network ).  Subnet Identifier  This is the ID of an existing subnet on OpenStack where you would like to launch the cluster. (Must be provided for  Use an existing subnet in an existing network )    IMPORTANT  Please make sure the defined subnet here doesn't overlap with any of your already deployed subnet in the\n network, because the validation only happens after the cluster creation starts.  In case of existing subnet make sure you have enough room within your network space for the new instances. The\nprovided subnet CIDR will be ignored, but a proper CIDR range will be used.   If  Public in account  is checked all the users belonging to your account will be able to use this network template\nto create clusters, but cannot delete it.   NOTE  The new networks are created on OpenStack only after the the cluster provisioning starts with the selected\nnetwork template.    Full size  here .  Security groups  Security group templates are very similar to the  Security Groups on OpenStack .  They describe the allowed inbound traffic \nto the instances in the cluster.  Currently only one security group template can be selected for a Cloudbreak cluster \nand all the instances have a public IP address so all the instances in the cluster will belong to the same security \ngroup. This may change in a later release.  Default Security Group  You can also use the two pre-defined security groups in Cloudbreak.  only-ssh-and-ssl:  all ports are locked down except for SSH and the selected Ambari Server HTTPS (you can't access Hadoop services \noutside of the network):   SSH (22)  HTTPS (443)   Custom Security Group  You can define your own security group by adding all the ports, protocols and CIDR range you'd like to use. The rules\n defined here doesn't need to contain the internal rules, those are automatically added by Cloudbreak to the security\n  group on OpenStack.  Hadoop services :  Ambari (8080)  Consul (8500)  NN (50070)  RM Web (8088)  Scheduler (8030RM)  IPC (8050RM)  Job history server (19888)  HBase master (60000)  HBase master web (60010)  HBase RS (16020)  HBase RS info (60030)  Falcon (15000)  Storm (8744)  Hive metastore (9083)  Hive server (10000)  Hive server HTTP (10001)  Accumulo master (9999)  Accumulo Tserver (9997)  Atlas (21000)  KNOX (8443)  Oozie (11000)  Spark HS (18080)  NM Web (8042)  Zeppelin WebSocket (9996)  Zeppelin UI (9995)  Kibana (3080)\n* Elasticsearch (9200)   IMPORTANT  443, 9443, and 22 ports needs to be there in every security group otherwise Cloudbreak won't be able to communicate with the provisioned cluster.   If  Public in account  is checked all the users belonging to your account will be able to use this security group \ntemplate to create clusters, but cannot delete it.   NOTE  The security groups are created on OpenStack only after the cluster provisioning starts with the selected \nsecurity group template.    Full size  here . /sub", 
            "title": "Infrastructure templates"
        }, 
        {
            "location": "/openstack/#defining-cluster-services", 
            "text": "", 
            "title": "Defining Cluster Services"
        }, 
        {
            "location": "/openstack/#blueprints", 
            "text": "Blueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are  used by Ambari .  You can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file, URL (an  example blueprint ) or the \nwhole JSON can be written in the  JSON text  box.  The host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.   NOTE:  It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will \nfill that with a default value.   If  Public in account  is checked all the users belonging to your account will be able to use this blueprint to \ncreate clusters, but cannot delete or modify it.   Full size  here .  A blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications. \nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations...etc. that won't be applicable to the Cloudbreak cluster", 
            "title": "Blueprints"
        }, 
        {
            "location": "/openstack/#cluster-deployment", 
            "text": "After all the cluster resources are configured you can deploy a new HDP cluster.  Here is a  basic flow for cluster creation on Cloudbreak Web UI :   Start by selecting a previously created OpenStack credential in the header.    Full size  here .   Open  create cluster   Configure Cluster  tab   Fill out the new cluster  name  The name must be between 5 and 40 characters long and must satisfy the followings:  Starts with a lowercase alphabetic character  Can contain lowercase alphanumeric and hyphens only      Select one of your  Region  where you like your cluster be provisioned  Click on the  Setup Network and Security  button  If  Public in account  is checked all the users belonging to your account will be able to see the created cluster on\n the UI, but cannot delete or modify it.     Setup Network and Security  tab   Select one of your previously created networks  Click on the  Choose Blueprint  button  If  Enable security  is checked as well, Cloudbreak will install Key Distribution Center (KDC) and the cluster will \nbe Kerberized. See more about it in the  Kerberos  section of this documentation.     Choose Blueprint  tab   Select one of the blueprints  After you've selected a  Blueprint , you should be able to configure:  the templates  the securitygroups  the number of nodes for all of the host groups in the blueprint    You need to select where you want to install the Ambari server to. Only 1 host group can be selected.\n   If you want to install the Ambari server to a separate node, you need to extend your blueprint with a new host group\n   which contains only 1 service: HDFS_CLIENT and select this host group for the Ambari server. Note: this host group cannot be scaled so \n   it is not advised to select a 'slave' host group for this purpose.  Click on the  Review and Launch  button   Review and Launch  tab   After the  create and start cluster  button has clicked Cloudbreak will start to create the cluster's resources on \n your OpenStack account.   Cloudbreak uses  OpenStack  to create the resources - you can check out the resources created by Cloudbreak\n on the  Instances  page of your OpenStack  Project .  Full size  here .  Besides these you can check the progress on the Cloudbreak Web UI itself if you open the new cluster's  Event History .  Full size  here .  Advanced options  Ambari Username  This user will be used as admin user in Ambari. You can log in using this username on the Ambari UI.  Ambari Password  The password associated with the Ambari username. This password will be also the default password for all required passwords which are not specified in the blueprint. E.g: hive DB password.  Connector Variant  Cloudbreak provides two implementation for creating OpenStack cluster   HEAT  using  HEAT  template to create the resources  NATIVE  using API calls to create the resources    The HEAT variant utilizes the Heat templating to launch a stack, but the NATIVE variant starts the cluster\n  by using a sequence of API calls without Heat to achieve the same result, although both of them are using the same \n  authentication and credential management.   Minimum cluster size  The provisioning strategy in case the cloud provider cannot allocate all the requested nodes.  Validate blueprint  This is selected by default. Cloudbreak validates the Ambari blueprint in this case.  Custom Image  If you enable this, you can override the default image for provision.  Shipyard enabled cluster  This is selected by default. Cloudbreak will start a  Shipyard  container which helps you to manage your containers.  Config recommendation strategy  Strategy for how configuration recommendations will be applied. Recommended \nconfigurations gathered by the response of the stack advisor.    NEVER_APPLY                Configuration recommendations are ignored with this option.  ONLY_STACK_DEFAULTS_APPLY  Applies only on the default configurations for all included services.  ALWAYS_APPLY               Applies on all configuration properties.", 
            "title": "Cluster deployment"
        }, 
        {
            "location": "/openstack/#cluster-termination", 
            "text": "You can terminate running or stopped clusters with the  terminate  button in the cluster details.   IMPORTANT  Always use Cloudbreak to terminate the cluster. If that fails for some reason, try to delete the \nOpenStack instances first. Instances are started in an Auto Scaling Group so they may be restarted if you terminate an \ninstance manually!   Sometimes Cloudbreak cannot synchronize its state with the cluster state at the cloud provider and the cluster can't\n be terminated. In this case the  Forced termination  option can help to terminate the cluster at the Cloudbreak \n side.  If it has happened:   You should check the related resources at the OpenStack  If it is needed you need to manually remove resources from there    Full size  here .", 
            "title": "Cluster termination"
        }, 
        {
            "location": "/openstack/#interactive-mode-cloudbreak-shell", 
            "text": "The goal with the Cloudbreak Shell (Cloudbreak CLI) was to provide an interactive command line tool which supports:   all functionality available through the REST API or Cloudbreak Web UI  makes possible complete automation of management task via scripts  context aware command availability  tab completion  required/optional parameter support  hint command to guide you on the usual path", 
            "title": "Interactive mode / Cloudbreak Shell"
        }, 
        {
            "location": "/openstack/#start-cloudbreak-shell", 
            "text": "To start the Cloudbreak CLI use the following commands:   Open your  cloudbreak-deployment  directory if it is needed. For example:      cd cloudbreak-deployment   Start the  cbd  from here if it is needed      cbd start   In the root of your  cloudbreak-deployment  folder apply:      cbd util cloudbreak-shell   At the very first time it will take for a while, because of need to download all the necessary docker images.   This will launch the Cloudbreak shell inside a Docker container then it is ready to use.  Full size  here .   IMPORTANT You have to copy all your files into the  cbd  working directory, what you would like to use in shell.  For \nexample if your  cbd  working directory is  ~/cloudbreak-deployment  then copy your  blueprint JSON, public ssh key \nfile...etc.  to here. You can refer to these files with their names from the shell.", 
            "title": "Start Cloudbreak Shell"
        }, 
        {
            "location": "/openstack/#autocomplete-and-hints", 
            "text": "Cloudbreak Shell helps you with  hint messages  from the very beginning, for example:  cloudbreak-shell hint\nHint: Add a blueprint with the 'blueprint create' command or select an existing one with 'blueprint select'\ncloudbreak-shell   Beyond this you can use the  autocompletion (double-TAB)  as well:  cloudbreak-shell credential create --\ncredential create --AWS          credential create --AZURE        credential create --EC2          credential create --GCP          credential create --OPENSTACK", 
            "title": "Autocomplete and Hints"
        }, 
        {
            "location": "/openstack/#provisioning-via-cli", 
            "text": "", 
            "title": "Provisioning via CLI"
        }, 
        {
            "location": "/openstack/#setting-up-openstack-credential", 
            "text": "Cloudbreak works by connecting your OpenStack account through so called Credentials, and then uses these credentials to \ncreate resources on your behalf. Credentials can be configured with the following command for example:  credential create --OPENSTACK --name my-os-credential --description  sample description  --userName  OpenStack username  --password  OpenStack password  --tenantName  OpenStack tenant name  --endPoint  OpenStack Identity Service (Keystone) endpoint  --sshKeyString  ssh-rsa AAAAB****etc    NOTE  that Cloudbreak  does not set your cloud user details  - we work around the concept of  OpenStack's \nauthentication . You should have already valid OpenStack credentials. You can \nfind further details  here .   Alternatives to provide  SSH Key :   you can upload your public key from an url:  \u2014sshKeyUrl    or you can add the path of your public key:  \u2014sshKeyPath   Other available option:  --facing  URL perspective in which the API is accessing data, allowed types are: public, admin and internal.   NOTE  If facing not specified OpenStack default value will be applied.   You can check whether the credential was created successfully  credential list  You can switch between your existing credentials  credential select --name my-os-credential", 
            "title": "Setting up OpenStack credential"
        }, 
        {
            "location": "/openstack/#infrastructure-templates_1", 
            "text": "After your OpenStack account is linked to Cloudbreak you can start creating resource templates that describe your \nclusters' infrastructure:   security groups  networks  templates   When you create one of the above resources,  Cloudbreak does not make any requests to OpenStack. Resources are only \ncreated on OpenStack after the  cluster create  has applied.  These templates are saved to Cloudbreak's database and\n can be reused with multiple clusters to describe the infrastructure.  Templates  Templates describe the  instances of your cluster  - the instance type and the attached volumes. A typical setup is\n to combine multiple templates in a cluster for the different types of nodes. For example you may want to attach multiple\n large disks to the datanodes or have memory optimized instances for Spark nodes.  A template can be used repeatedly to create identical copies of the same stack (or to use as a foundation to start a \nnew stack). Templates can be configured with the following command for example:  template create --OPENSTACK --name my-os-template --description  sample description  --instanceType m1.medium \n--volumeSize 100 --volumeCount 1  Other available option here is  --publicInAccount . If it is true, all the users belonging to your account will be able\n to use this template to create clusters, but cannot delete it.  You can check whether the template was created successfully  template list  Networks  Your clusters can be created in their own  networks  or in one of your already existing one. If you choose an \nexisting network, it is possible to create a new subnet within the network. The subnet's IP range must be defined in \nthe  Subnet (CIDR)  field using the general CIDR notation. Here you can read more about  OpenStack networking .  Custom OpenStack Network  If you'd like to deploy a cluster to your OpenStack network you'll have to  create a new network  template.  A network also can be used repeatedly to create identical copies of the same stack (or to use as a foundation to \nstart a new stack).   \"Before launching an instance, you must create the necessary virtual network infrastructure...an instance uses a \npublic provider virtual network that connects to the physical network infrastructure...This network includes a DHCP \nserver that provides IP addresses to instances...The admin or other privileged user must create this network because \nit connects directly to the physical network infrastructure.\"  Here you can read more about OpenStack  virtual network  and  public provider network .   network create --OPENSTACK --name my-os-network --description openstack-network --publicNetID  id of an OpenStack \npublic network  --subnet 10.0.0.0/16   IMPORTANT   In case of existing subnet all three parameters must be provided, with new subnet only two are required.  Please make sure the defined subnet here doesn't overlap with any of your already deployed subnet in the\n network, because the validation only happens after the cluster creation starts.  In case of existing subnet make sure you have enough room within your network space for the new instances. The \nprovided subnet CIDR will be ignored, but a proper CIDR range will be used.   NOTE  The new networks are created on OpenStack only after the the cluster provisioning starts with the selected \nnetwork template.   Other available options here:  --networkId  This must be an ID of an existing OpenStack virtual network.  --routerId  Your virtual network router ID (must be provided in case of existing virtual network).  --subnetId  Your subnet ID within your virtual network. If the identifier is provided, the  Subnet \n(CIDR)  will be ignored. Leave it blank if you'd like to create a new subnet within the virtual network with the \nprovided  Subnet (CIDR)  range.  --publicInAccount  If it is true, all the users belonging to your account will be able to use this template to create clusters, but cannot delete it.  You can check whether the network was created successfully  network list", 
            "title": "Infrastructure templates"
        }, 
        {
            "location": "/openstack/#defining-cluster-services_1", 
            "text": "", 
            "title": "Defining Cluster Services"
        }, 
        {
            "location": "/openstack/#blueprints_1", 
            "text": "Blueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are  used by Ambari .  You can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file or URL (an  example blueprint ).  The host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.   NOTE:  It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will fill that with a default value.   blueprint create --name my-blueprint --description  sample description  --file  the path of the blueprint   Other available options:  --url  the url of the blueprint  --publicInAccount  If it is true, all the users belonging to your account will be able to use this blueprint to create \nclusters, but cannot delete it.  You can check whether the blueprint was created successfully  blueprint list  A blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications. \nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations..etc. that won't be applicable to the Cloudbreak cluster.", 
            "title": "Blueprints"
        }, 
        {
            "location": "/openstack/#metadata-show", 
            "text": "You can check the stack metadata with  stack metadata --name myawsstack --instancegroup master  Other available options:  --id  In this case you can select a stack with id.  --outputType  In this case you can modify the outputformat of the command (RAW or JSON).", 
            "title": "Metadata Show"
        }, 
        {
            "location": "/openstack/#cluster-deployment_1", 
            "text": "After all the cluster resources are configured you can deploy a new HDP cluster. The following sub-sections show \nyou a  basic flow for cluster creation with Cloudbreak Shell .  Select credential  Select one of your previously created OpenStack credential:  credential select --name my-os-credential  Select blueprint  Select one of your previously created blueprint which fits your needs:  blueprint select --name multi-node-hdfs-yarn  Configure instance groups  You must configure instance groups before provisioning. An instance group define a group of nodes with a specified \ntemplate and security group. Usually we create instance groups for host groups in the blueprint. For Ambari server only 1 host group can be specified.\nIf you want to install the Ambari server to a separate node, you need to extend your blueprint with a new host group\nwhich contains only 1 service: HDFS_CLIENT and select this host group for the Ambari server. Note: this host group cannot be scaled so \nit is not advised to select a 'slave' host group for this purpose.  instancegroup configure --instanceGroup master --nodecount 1 --templateName minviable-aws --securityGroupName all-services-port --ambariServer true\ninstancegroup configure --instanceGroup slave_1 --nodecount 1 --templateName minviable-aws --securityGroupName all-services-port --ambariServer false  Other available option:  --templateId  Id of the template  Select network  Select one of your previously created network which fits your needs or a default one:  network select --name my-os-network  Create stack / Create cloud infrastructure  Stack means the running cloud infrastructure that is created based on the instance groups configured earlier \n( credential ,  instancegroups ,  network ,  securitygroup ). Same as in case of the API or UI the new cluster will \nuse your templates and by using OpenStack will launch your cloud stack. Use the following command to create a \nstack to be used with your Hadoop cluster:  stack create --OPENSTACK --name myosstack --region local  The infrastructure is created asynchronously, the state of the stack can be checked with the stack  show command . If \nit reports AVAILABLE, it means that the virtual machines and the corresponding infrastructure is running at the cloud provider.  Other available option is:  --wait  - in this case the create command will return only after the process has finished.   Create a Hadoop cluster / Cloud provisioning  You are almost done! One more command and your Hadoop cluster is starting!  Cloud provisioning is done once the \ncluster is up and running. The new cluster will use your selected blueprint and install your custom Hadoop cluster \nwith the selected components and services.  cluster create --description  my first cluster   Other available option is  --wait  - in this case the create command will return only after the process has finished.   You are done!  You have several opportunities to check the progress during the infrastructure creation then \nprovisioning:   Cloudbreak uses  OpenStack  to create the resources - you can check out the resources created by Cloudbreak on\n the OpenStack Console Instances page.   For example:  Full size  here .   If stack then cluster creation have successfully done, you can check the Ambari Web UI. However you need to know the \nAmbari IP (for example:  http://172.16.252.59:8080 ):   You can get the IP from the CLI as a result ( ambariServerIp 172.16.252.59 ) of the following command:              cluster show  For example:  Full size  here .   Besides these you can check the entire progress and the Ambari IP as well on the Cloudbreak Web UI itself. Open the \nnew cluster's  details  and its  Event History  here.   For example:  Full size  here .", 
            "title": "Cluster deployment"
        }, 
        {
            "location": "/openstack/#stop-cluster", 
            "text": "You have the ability to  stop your existing stack then its cluster  if you want to suspend the work on it.  Select a stack for example with its name:  stack select --name my-stack  Other available option to define a stack is its  --id .  Every time you should stop the  cluster  first then the  stack . So apply following commands to stop the previously \nselected stack:  cluster stop\nstack stop", 
            "title": "Stop Cluster"
        }, 
        {
            "location": "/openstack/#restart-cluster", 
            "text": "Select your stack that you would like to restart  after this you can apply:  stack start  After the stack has successfully restarted, you can  restart the related cluster as well :  cluster start", 
            "title": "Restart Cluster"
        }, 
        {
            "location": "/openstack/#upscale-cluster", 
            "text": "If you need more instances to your infrastructure, you can  upscale your selected stack :  stack node --ADD --instanceGroup host_group_slave_1 --adjustment 6  Other available option is  --withClusterUpScale  - this indicates also a cluster upscale after the stack upscale. You\n can upscale the related cluster separately if you want to do this:  cluster node --ADD --hostgroup host_group_slave_1 --adjustment 6", 
            "title": "Upscale Cluster"
        }, 
        {
            "location": "/openstack/#downscale-cluster", 
            "text": "You also can reduce the number of instances in your infrastructure.  After you selected your stack :  cluster node --REMOVE  --hostgroup host_group_slave_1 --adjustment -2  Other available option is  --withStackDownScale  - this indicates also a stack downscale after the cluster downscale.\n You can downscale the related stack separately if you want to do this:  stack node --REMOVE  --instanceGroup host_group_slave_1 --adjustment -2", 
            "title": "Downscale Cluster"
        }, 
        {
            "location": "/openstack/#cluster-termination_1", 
            "text": "You can terminate running or stopped clusters with  stack delete --name myawsstack  Other available option is  --wait  - in this case the terminate command will return only after the process has finished.    IMPORTANT:  Always use Cloudbreak to terminate the cluster. If that fails for some reason, try to delete the \nCloudFormation stack first. Instances are started in an Auto Scaling Group so they may be restarted if you terminate an instance manually!   Sometimes Cloudbreak cannot synchronize its state with the cluster state at the cloud provider and the cluster can't\n be terminated. In this case the  Forced termination  option on the Cloudbreak Web UI can help to terminate the cluster\n  at the Cloudbreak side.  If it has happened:   You should check the related resources at the AWS CloudFormation  If it is needed you need to manually remove resources from there", 
            "title": "Cluster Termination"
        }, 
        {
            "location": "/openstack/#silent-mode", 
            "text": "With Cloudbreak Shell you can execute script files as well. A script file contains shell commands and can \nbe executed with the  script  cloudbreak shell command  script  your script file   or with the  cbd util cloudbreak-shell-quiet  command  cbd util cloudbreak-shell-quiet   example.sh   IMPORTANT:  You have to copy all your files into the  cbd  working directory, what you would like to use in shell.\n For example if your  cbd  working directory is ~/cloudbreak-deployment then copy your script file to here.", 
            "title": "Silent Mode"
        }, 
        {
            "location": "/openstack/#example", 
            "text": "The following example creates a hadoop cluster with  hdp-small-default  blueprint on  m1.large  instances with 2X100G\n attached disks on  osnetwork  network using  all-services-port  security group. You should copy your ssh public key \n file into your  cbd  working directory with name  id_rsa.pub  and change the  ...  parts with your OpenStack \n credential and network details.  credential create --OPENSTACK --name my-os-credential --description  credentail description  --userName  OpenStack username  --password  OpenStack password  --tenantName  OpenStack tenant name  --endPoint  OpenStack Identity Service (Keystone) endpoint  --sshKeyPath  path of your public SSH key file \ncredential select --name my-os-credential\ntemplate create --OPENSTACK --name ostemplate --description openstack-template --instanceType m1.large --volumeSize 100 --volumeCount 2\nblueprint select --name hdp-small-default\ninstancegroup configure --instanceGroup host_group_master_1 --nodecount 1 --templateName ostemplate --securityGroupName all-services-port --ambariServer true\ninstancegroup configure --instanceGroup host_group_master_2 --nodecount 1 --templateName ostemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_master_3 --nodecount 1 --templateName ostemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_client_1  --nodecount 1 --templateName ostemplate --securityGroupName all-services-port --ambariServer false\ninstancegroup configure --instanceGroup host_group_slave_1 --nodecount 3 --templateName ostemplate --securityGroupName all-services-port --ambariServer false\nnetwork create --OPENSTACK --name osnetwork --description openstack-network --publicNetID  id of an OpenStack public network  --subnet 10.0.0.0/16\nnetwork select --name osnetwork\nstack create --OPENSTACK --name my-first-stack --region local --wait true\ncluster create --description  My first cluster  --wait true  Congratulations!  Your cluster should now be up and running on this way as well. To learn more about Cloudbreak and \nprovisioning, we have some  interesting insights  for you.", 
            "title": "Example"
        }, 
        {
            "location": "/api/", 
            "text": "API Documentation\n\n\nCloudbreak is a RESTful application development platform whose goal is to help developers deploy HDP clusters in different environments. Once Cloudbreak is deployed in your favorite servlet container, it exposes a REST API, allowing you to spin up Hadoop clusters of any size with your chosen cloud provider.\n\n\nThe \nAPI documentation\n was generated from the code using \nSwagger\n.", 
            "title": "API"
        }, 
        {
            "location": "/api/#api-documentation", 
            "text": "Cloudbreak is a RESTful application development platform whose goal is to help developers deploy HDP clusters in different environments. Once Cloudbreak is deployed in your favorite servlet container, it exposes a REST API, allowing you to spin up Hadoop clusters of any size with your chosen cloud provider.  The  API documentation  was generated from the code using  Swagger .", 
            "title": "API Documentation"
        }, 
        {
            "location": "/shell/", 
            "text": "Cloudbreak Shell\n\n\nThe Cloudbreak Shell is an interactive command line tool which supports:\n\n\n\n\nAll functionality available through the REST API or Cloudbreak web UI\n\n\nComplete automation of management tasks via \nscripts\n\n\nContext-aware commands\n\n\nRequired/optional parameters\n\n\nTab completion\n\n\nThe \nhint\n command that guides you when you need help\n\n\n\n\nInstall and Start Cloudbreak Shell\n\n\nInstall Cloudbreak shell using one of the following options:\n\n\n\n\nInstall Cloudbreak Shell Using Cloudreak Deployer\n (Recommended) \n\n\nUse Our Prepared Docker Image\n\n\nBuild From Source\n\n\n\n\n\n\nInstall Cloudbreak Shell Using Cloudbreak Deployer\n\n\nStart the shell with \ncbd util cloudbreak-shell\n. This will launch the Cloudbreak shell inside a Docker container, and you can start using it.\n\n\n\n\nUse Our Prepared Docker image\n\n\nYou can find the docker image and its documentation \nhere\n.\n\n\n\n\nBuild from Source\n\n\nIf want to use the code or extend it with new commands, follow the steps below.\n\n\nPrerequisites:\n JDK 1.8.  \n\n\nExecute the folowing commands:\n\n\ngit clone https://github.com/hortonworks/cloudbreak.git\ncd cloudbreak/shell\n../gradlew clean build\n\n\n\n\n\n\nNote: \n\nIf you use the hosted version of Cloudbreak, use \nlatest-release.sh\n to get the right version of the CLI.\n\n\n\n\nStart Cloudbreak-shell from the build source using:\n\n\nUsage:\n  java -jar cloudbreak-shell-0.5-SNAPSHOT.jar                  : Starts Cloudbreak Shell in interactive mode.\n  java -jar cloudbreak-shell-0.5-SNAPSHOT.jar --cmdfile=\nFILE\n : Cloudbreak executes commands read from the file.\n\nOptions:\n  --cloudbreak.address=\nhttp[s]://HOSTNAME:PORT\n  Address of the Cloudbreak Server [default: https://cloudbreak-api.sequenceiq.com].\n  --identity.address=\nhttp[s]://HOSTNAME:PORT\n    Address of the SequenceIQ identity server [default: https://identity.sequenceiq.com].\n  --sequenceiq.user=\nUSER\n                        Username of the SequenceIQ user [default: user@sequenceiq.com].\n  --sequenceiq.password=\nPASSWORD\n                Password of the SequenceIQ user [default: password].\n\n\n\n\n\n\nNote: \n\nYou should specify at least your username and password.\n\n\n\n\nOnce you are connected, you can create a cluster. Use \nhint\n if you get lost or need guidance through the process. Use \nTAB\n for completion.\n\n\n\n\nNote: \n\nAll commands are \ncontext-aware\n, which means that they are available only when they are relevant. This way the system guides you nad keeps you on the right path.\n\n\n\n\nConnect Cloudbreak Shell with a Remote Cloudbreak Instance\n\n\nPrerequisites:\n Docker is installed and running on the local machine\n\n\n\n\nExecute \ncbd util cloudbreak-shell-remote\n on the remote host.\n\n\nExecute the result of the previous command on the local machine.\n\n\n\n\nDocumentation\n\n\nFor \ncomplete documentation\n of the Cloudbreak shell, see Cloudbreak  \ngithub repository\n.\n\n\nFor \nProvider-specific Documentation\n, see:\n\n\n\n\nAWS\n\n\nAzure\n\n\nGCP\n\n\nOpenStack", 
            "title": "CLI/Shell"
        }, 
        {
            "location": "/shell/#cloudbreak-shell", 
            "text": "The Cloudbreak Shell is an interactive command line tool which supports:   All functionality available through the REST API or Cloudbreak web UI  Complete automation of management tasks via  scripts  Context-aware commands  Required/optional parameters  Tab completion  The  hint  command that guides you when you need help", 
            "title": "Cloudbreak Shell"
        }, 
        {
            "location": "/shell/#install-and-start-cloudbreak-shell", 
            "text": "Install Cloudbreak shell using one of the following options:   Install Cloudbreak Shell Using Cloudreak Deployer  (Recommended)   Use Our Prepared Docker Image  Build From Source", 
            "title": "Install and Start Cloudbreak Shell"
        }, 
        {
            "location": "/shell/#install-cloudbreak-shell-using-cloudbreak-deployer", 
            "text": "Start the shell with  cbd util cloudbreak-shell . This will launch the Cloudbreak shell inside a Docker container, and you can start using it.", 
            "title": "Install Cloudbreak Shell Using Cloudbreak Deployer"
        }, 
        {
            "location": "/shell/#use-our-prepared-docker-image", 
            "text": "You can find the docker image and its documentation  here .", 
            "title": "Use Our Prepared Docker image"
        }, 
        {
            "location": "/shell/#build-from-source", 
            "text": "If want to use the code or extend it with new commands, follow the steps below.  Prerequisites:  JDK 1.8.    Execute the folowing commands:  git clone https://github.com/hortonworks/cloudbreak.git\ncd cloudbreak/shell\n../gradlew clean build   Note:  \nIf you use the hosted version of Cloudbreak, use  latest-release.sh  to get the right version of the CLI.   Start Cloudbreak-shell from the build source using:  Usage:\n  java -jar cloudbreak-shell-0.5-SNAPSHOT.jar                  : Starts Cloudbreak Shell in interactive mode.\n  java -jar cloudbreak-shell-0.5-SNAPSHOT.jar --cmdfile= FILE  : Cloudbreak executes commands read from the file.\n\nOptions:\n  --cloudbreak.address= http[s]://HOSTNAME:PORT   Address of the Cloudbreak Server [default: https://cloudbreak-api.sequenceiq.com].\n  --identity.address= http[s]://HOSTNAME:PORT     Address of the SequenceIQ identity server [default: https://identity.sequenceiq.com].\n  --sequenceiq.user= USER                         Username of the SequenceIQ user [default: user@sequenceiq.com].\n  --sequenceiq.password= PASSWORD                 Password of the SequenceIQ user [default: password].   Note:  \nYou should specify at least your username and password.   Once you are connected, you can create a cluster. Use  hint  if you get lost or need guidance through the process. Use  TAB  for completion.   Note:  \nAll commands are  context-aware , which means that they are available only when they are relevant. This way the system guides you nad keeps you on the right path.", 
            "title": "Build from Source"
        }, 
        {
            "location": "/shell/#connect-cloudbreak-shell-with-a-remote-cloudbreak-instance", 
            "text": "Prerequisites:  Docker is installed and running on the local machine   Execute  cbd util cloudbreak-shell-remote  on the remote host.  Execute the result of the previous command on the local machine.", 
            "title": "Connect Cloudbreak Shell with a Remote Cloudbreak Instance"
        }, 
        {
            "location": "/shell/#documentation", 
            "text": "For  complete documentation  of the Cloudbreak shell, see Cloudbreak   github repository .  For  Provider-specific Documentation , see:   AWS  Azure  GCP  OpenStack", 
            "title": "Documentation"
        }, 
        {
            "location": "/security/", 
            "text": "Cloudbreak Security\n\n\nSecurity is very important in general, but it is the most important in production environments. Cloudbreak comes with default settings, but those settings are aiming for easy first dating, not strict security. So first of all you can block all communication ports except 443 on the firewall / security group / whatever you use. It is strongly recommended to open SSH port (usually 22) if you have to log in to the Cloudbreak host remotely.\n\n\nThe second step is to configure the Profile file before starting Cloudbreak for the first time. As a starting point, execute the following command in the directory where you want to store Cloudbreak related files:\n\n\necho export PUBLIC_IP=[the ip or hostname to bind] \n Profile\n\n\n\n\nAfter you have a base Profile you should add custom properties to the Profile file:\n\n\nexport UAA_DEFAULT_SECRET='[custom secret]'\nexport UAA_DEFAULT_USER_EMAIL='[default admin email address]'\nexport UAA_DEFAULT_USER_PW='[default admin password]'\nexport UAA_DEFAULT_USER_FIRSTNAME='[default admin first name]'\nexport UAA_DEFAULT_USER_LASTNAME='[default admin last name]'\n\n\n\n\nCloudbreak has more additional secrets which by default inherits their values from \nUAA_DEFAULT_SECRET\n, but you should also define different ones in the Profile for each of the service clients:\n\n\nexport UAA_CLOUDBREAK_SECRET='[cloudbreak secret]'\nexport UAA_PERISCOPE_SECRET='[auto scaling secret]'\nexport UAA_ULUWATU_SECRET='[web ui secret]'\nexport UAA_SULTANS_SECRET='[authenticator secret]'\n\n\n\n\nYou can change secrets any time except \nUAA_CLOUDBREAK_SECRET\n, because it is used to encrypt sensitive information at database level. Client secret changes are applied during startup so a restart is required after a change.\n\n\nAs you see \nUAA_DEFAULT_USER_PW\n is stored in plain text format, but if \nUAA_DEFAULT_USER_PW\n is missing from the Profile, it gets a default value. Because default password is not an option if you set an empty password explicitly in the Profile, Cloudbreak deployer will ask for password all the time when it is needed for the operation.\n\n\nexport UAA_DEFAULT_USER_PW=''\n\n\n\n\nIn this case Cloudbreak deployer wouldn't be able to add the default user, so you have to do it manually by executing the following command:\n\n\ncbd util add-default-user", 
            "title": "Cloudbreak Security"
        }, 
        {
            "location": "/security/#cloudbreak-security", 
            "text": "Security is very important in general, but it is the most important in production environments. Cloudbreak comes with default settings, but those settings are aiming for easy first dating, not strict security. So first of all you can block all communication ports except 443 on the firewall / security group / whatever you use. It is strongly recommended to open SSH port (usually 22) if you have to log in to the Cloudbreak host remotely.  The second step is to configure the Profile file before starting Cloudbreak for the first time. As a starting point, execute the following command in the directory where you want to store Cloudbreak related files:  echo export PUBLIC_IP=[the ip or hostname to bind]   Profile  After you have a base Profile you should add custom properties to the Profile file:  export UAA_DEFAULT_SECRET='[custom secret]'\nexport UAA_DEFAULT_USER_EMAIL='[default admin email address]'\nexport UAA_DEFAULT_USER_PW='[default admin password]'\nexport UAA_DEFAULT_USER_FIRSTNAME='[default admin first name]'\nexport UAA_DEFAULT_USER_LASTNAME='[default admin last name]'  Cloudbreak has more additional secrets which by default inherits their values from  UAA_DEFAULT_SECRET , but you should also define different ones in the Profile for each of the service clients:  export UAA_CLOUDBREAK_SECRET='[cloudbreak secret]'\nexport UAA_PERISCOPE_SECRET='[auto scaling secret]'\nexport UAA_ULUWATU_SECRET='[web ui secret]'\nexport UAA_SULTANS_SECRET='[authenticator secret]'  You can change secrets any time except  UAA_CLOUDBREAK_SECRET , because it is used to encrypt sensitive information at database level. Client secret changes are applied during startup so a restart is required after a change.  As you see  UAA_DEFAULT_USER_PW  is stored in plain text format, but if  UAA_DEFAULT_USER_PW  is missing from the Profile, it gets a default value. Because default password is not an option if you set an empty password explicitly in the Profile, Cloudbreak deployer will ask for password all the time when it is needed for the operation.  export UAA_DEFAULT_USER_PW=''  In this case Cloudbreak deployer wouldn't be able to add the default user, so you have to do it manually by executing the following command:  cbd util add-default-user", 
            "title": "Cloudbreak Security"
        }, 
        {
            "location": "/update/", 
            "text": "Update Cloudbreak Deployer\n\n\nTo update Cloudbreak Deployer to the newest version, run the following commands on the console where your \nProfile\n is located:\n\n\nStep 1:\n Stop all of the running Cloudbreak components:\n\n\ncbd kill\n\n\n\n\nStep 2:\n Update Cloudbreak Deployer:\n\n\ncbd update\n\n\n\n\nStep 3:\n Update the \ndocker-compose.yml\n file with new Docker containers needed for the \ncbd\n:\n\n\ncbd regenerate\n\n\n\n\nStep 4:\n If there are no other Cloudbreak instances that still use old Cloudbreak versions, remove the obsolete containers:\n\n\ncbd util cleanup\n\n\n\n\nStep 5:\n Check the health and version of the updated \ncbd\n: \n\n\ncbd doctor\n\n\n\n\nStep 6:\n Start the new version of the \ncbd\n:\n\n\ncbd start\n\n\n\n\n\n\nCloudbreak needs to download updated docker images for the new version, so this step may take a while.\n\n\n\n\nUpdate existing clusters\n\n\nUpgrading from version \n1.4.0\n to newer versions (\n1.5.0\n or \n1.6.0\n) doesn't require any manual modification from the users.\n\n\nIf Cloudbreak has been updated from \n1.3.0\n to \n1.4.0\n version then existing clusters need to be updated to be still managable through Cloudbreak.\nTo update existing clusters from \n1.3.0\n to \n1.4.0\n or newer versions, run the following commands on the \ncbgateway\n node of the cluster:\n\n\n\n\nUpdate the version of the Salt-Bootsrap tool on the nodes:\n\n\n\n\nsalt '*' cmd.run 'curl -Ls https://github.com/hortonworks/salt-bootstrap/releases/download/v0.1.2/salt-bootstrap_0.1.2_Linux_x86_64.tgz | tar -zx -C /usr/sbin/ salt-bootstrap'\n\n\n\n\n\n\nTrigger restart of tool on the nodes:\n\n\n\n\nsalt '*' service.dead salt-bootstrap\n\n\n\n\n\n\nNOTE\n Checking the version of the Salt-Bootsrap on the nodes:\n\n\nsalt '*' cmd.run 'salt-bootstrap --version'", 
            "title": "Update Cloudbreak"
        }, 
        {
            "location": "/update/#update-cloudbreak-deployer", 
            "text": "To update Cloudbreak Deployer to the newest version, run the following commands on the console where your  Profile  is located:  Step 1:  Stop all of the running Cloudbreak components:  cbd kill  Step 2:  Update Cloudbreak Deployer:  cbd update  Step 3:  Update the  docker-compose.yml  file with new Docker containers needed for the  cbd :  cbd regenerate  Step 4:  If there are no other Cloudbreak instances that still use old Cloudbreak versions, remove the obsolete containers:  cbd util cleanup  Step 5:  Check the health and version of the updated  cbd :   cbd doctor  Step 6:  Start the new version of the  cbd :  cbd start   Cloudbreak needs to download updated docker images for the new version, so this step may take a while.", 
            "title": "Update Cloudbreak Deployer"
        }, 
        {
            "location": "/update/#update-existing-clusters", 
            "text": "Upgrading from version  1.4.0  to newer versions ( 1.5.0  or  1.6.0 ) doesn't require any manual modification from the users.  If Cloudbreak has been updated from  1.3.0  to  1.4.0  version then existing clusters need to be updated to be still managable through Cloudbreak.\nTo update existing clusters from  1.3.0  to  1.4.0  or newer versions, run the following commands on the  cbgateway  node of the cluster:   Update the version of the Salt-Bootsrap tool on the nodes:   salt '*' cmd.run 'curl -Ls https://github.com/hortonworks/salt-bootstrap/releases/download/v0.1.2/salt-bootstrap_0.1.2_Linux_x86_64.tgz | tar -zx -C /usr/sbin/ salt-bootstrap'   Trigger restart of tool on the nodes:   salt '*' service.dead salt-bootstrap   NOTE  Checking the version of the Salt-Bootsrap on the nodes:  salt '*' cmd.run 'salt-bootstrap --version'", 
            "title": "Update existing clusters"
        }, 
        {
            "location": "/ui_account/", 
            "text": "Account Management\n\n\nYou can use the Cloudbreak web UI to view and manage your settings.\n\n\nAccount Details\n\n\nClick on \naccount\n in the header menu to go the \naccount\n page and expand the \naccount details\n tab.\n\n\nSecurity Scopes\n\n\nExpand the \naccount details\n tab to check your security scopes.\nEven administrator users cannot modify the list of scopes.\n\n\nCloudbreak has distinct security scopes for the following resources:\n\n\n\n\nBlueprints\n\n\nTemplates\n\n\nCredentials\n\n\nStacks\n\n\nNetworks\n\n\nSecurity Groups\n\n\n\n\n\n\nNote: \n In the future, the list of security scopes may be extended to include new resources.\n\n\n\n\nCloud Platforms\n\n\nThe \nCloud platforms\n table lists cloud platforms supported by Cloudbreak.\n\n\nOnly administrator users can set the cloud platforms used by the group. For example, if the administrator selects AWS cloud platform, only AWS networks, resources, and credentials will be displayed and can be created for users in the account (including managed users).\n\n\nThe following cloud platforms are supported:\n\n\n\n\nAWS\n\n\nAzure RM\n\n\nGCP\n\n\nOpenStack", 
            "title": "Account Management"
        }, 
        {
            "location": "/ui_account/#account-management", 
            "text": "You can use the Cloudbreak web UI to view and manage your settings.", 
            "title": "Account Management"
        }, 
        {
            "location": "/ui_account/#account-details", 
            "text": "Click on  account  in the header menu to go the  account  page and expand the  account details  tab.", 
            "title": "Account Details"
        }, 
        {
            "location": "/ui_account/#security-scopes", 
            "text": "Expand the  account details  tab to check your security scopes.\nEven administrator users cannot modify the list of scopes.  Cloudbreak has distinct security scopes for the following resources:   Blueprints  Templates  Credentials  Stacks  Networks  Security Groups    Note:   In the future, the list of security scopes may be extended to include new resources.", 
            "title": "Security Scopes"
        }, 
        {
            "location": "/ui_account/#cloud-platforms", 
            "text": "The  Cloud platforms  table lists cloud platforms supported by Cloudbreak.  Only administrator users can set the cloud platforms used by the group. For example, if the administrator selects AWS cloud platform, only AWS networks, resources, and credentials will be displayed and can be created for users in the account (including managed users).  The following cloud platforms are supported:   AWS  Azure RM  GCP  OpenStack", 
            "title": "Cloud Platforms"
        }, 
        {
            "location": "/periscope/", 
            "text": "Auto-Scaling\n\n\nThe goal of \nauto-scaling\n is to apply Service Level Agreement (SLA) scaling policies to a Cloudbreak-managed HDP cluster.\n\n\nThe auto-scaling capability is based on \nAmbari Metrics\n and \nAmbari Alerts\n. Based on the blueprint\nused and the services running, Cloudbreak accesses all available metrics from the subsystem and defines alerts based on these metrics.\n\n\nIn addition to the default Ambari Metrics, Cloudbreak includes two custom metrics: \nPending YARN containers\n and \nPending applications\n. These two custom metrics work with the YARN subsystem in order to bring application-level QoS to the cluster.\n\n\nEnable Auto-scaling through Cloudbreak UI\n\n\nChoose \nenable\n to enable auto-scaling:\n\n\n\n\nFull size \nhere\n.\n\n\nAlerts\n\n\nAuto-scaling supports two alert types: \nmetric\n and \ntime\n based.\n\n\nMetric-based Alerts\n\n\nMetric-based alerts use Ambari metrics. These metrics have a default \nThreshold\n value configured in Ambari, which you can modify in Ambari web UI.\n\n\nChange Default Threshold for an Ambari Metric\n\n\nTo change default threshold for an Ambari metric:\n\n\n\n\nLog in to Ambari web UI. \n\n\nFrom the header menu, select \nAlerts\n to open the \nAlerts\n page. \n\n\nSelect an alert from the list. \n\n\nIn the \nConfiguration\n panel, click on \nEdit\n. \n\n\nNow you can modify the values in the \nThreshold\n section. \n\n\n\n\n\n\nFull size \nhere\n.\n\n\nCreate a New Metric-based Alert\n\n\nTo create a new Cloudbreak metric-based alert in the Cloudbreak web UI:\n\n\n\n\nEnter the \nalert name\n. Only alphanumeric characters (min 5, max 100 characters) are allowed.\n\n\nEnter a \ndescription\n for the new alert.\n\n\nSelect a \nmetric\n, and then its \ndesired state\n. The Ambari metrics available are based on installed services and their state is based on the Ambari threshold value:\n\n\nOK\n\n\nWARN \n\n\nCRITICAL \n\n\n\n\n\n\nEnter the \nperiod\n (in minutes) to define the metric state endurance after the alert has been triggered. Only numeric characters are allowed.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nTime-based Alerts\n\n\nTime-based alerts are based on \ncron\n expressions, allowing alerts to be triggered based on time.\n\n\nCreate a Time-based Alert\n\n\nTo create a new Cloudbreak time-based alert in the Cloudbreak UI::\n\n\n\n\nEnter \nalert name\n. Only alphanumeric characters (min 5, max 100 characters) are allowed.\n\n\nEnter \ndescription\n for the new alert.\n\n\nSelect a \ntime zone\n for the new alert.\n\n\nProvide the \ncron expression\n to define the time-based job scheduler (\ncron\n expression) for this alert.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nScaling Policies\n\n\nScaling is the ability to increase or decrease the capacity of the HDP cluster or an application running on it based on an alert and according to the policy definition. After you set up your alerts and a scaling policy linked to them, Cloudbreak will execute the policy. \n\n\nScaling granularity is at the \nhost group\n level; Thus you have an option to scale services or components only, not the whole cluster.\n\n\nCreate a New Scaling Policy\n\n\nTo create a new Cloudbreak scaling policy:\n\n\n\n\nEnter the \npolicy name\n. Only alphanumeric characters (min 5, max 100 characters) are allowed.\n\n\nSelect a type first, and then a value for the \nscaling adjustment\n:\n\n\nnode count\n - number of nodes (added or removed)\n\n\npercentage\n - computed percentage adjustment based on the cluster size\n\n\nexact\n - given size of the cluster\n\n\n\n\n\n\nSelect the Ambari \nhost group\n where the cluster is to be scaled.\n\n\nSelect the previously created Cloudbreak \nalert\n to apply the scaling policy to it.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nCluster Scaling Configurations\n\n\nAn SLA scaling policy can contain multiple alerts. When an alert is triggered, a \nscaling adjustment\n is applied. \n\n\nTo make sure the scaling this adjustemnt doesn't oversize or undersize your cluster, you can keep the cluster size within defined boundaries using \ncluster size min.\n and \ncluster size max.\n\n\nTo avoid stressing the cluster, we have introduced a \ncooldown time\n period (in minutes). When an alert is raised and there is an associated scaling policy, the system will not apply the policy within the configured cooldown timeframe.\n\n\n\n\nNote:\n In an SLA scaling policy the triggered rules are applied in order.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nExplanation of the parameters:\n\n\n\n\ncooldown time\n - the cluster lockdown period (in minutes) between scaling events\n\n\ncluster size min.\n - the minimum cluster size limit, despite scaling adjustments\n\n\ncluster size max.\n - the maximum cluster size limit, despite scaling adjustments\n\n\n\n\nDownscale Scaling Considerations\n\n\nTo keep your cluster healthy, Cloudbreak auto-scaling runs several background checks during \ndownscale\n operation.\n\n\n\n\nCloudbreak will never remove \napplication master nodes\n from a cluster. In order to make sure that a node running Ambari Metrics is not \nremoved, Cloudbreak has to be able to access the YARN Resource Manager. When creating a cluster using the \n\ndefault\n secure network template, make sure that the RM's port is open on that node.\n\n\nIn order to keep a healthy HDFS during downscale, Cloudbreak always keeps the \nreplication factor\n configured and makes sure that there is enough \nspace\n on HDFS to rebalance data.\n\n\nDuring downscale, in order to minimize the rebalancing, replication, and HDFS storms, Cloudbreak checks block locations \nand computes the least costly operations.\n\n\n\n\nThe \nAPI documentation\n was generated from the code using \nSwagger\n.", 
            "title": "Auto-Scaling"
        }, 
        {
            "location": "/periscope/#auto-scaling", 
            "text": "The goal of  auto-scaling  is to apply Service Level Agreement (SLA) scaling policies to a Cloudbreak-managed HDP cluster.  The auto-scaling capability is based on  Ambari Metrics  and  Ambari Alerts . Based on the blueprint\nused and the services running, Cloudbreak accesses all available metrics from the subsystem and defines alerts based on these metrics.  In addition to the default Ambari Metrics, Cloudbreak includes two custom metrics:  Pending YARN containers  and  Pending applications . These two custom metrics work with the YARN subsystem in order to bring application-level QoS to the cluster.", 
            "title": "Auto-Scaling"
        }, 
        {
            "location": "/periscope/#enable-auto-scaling-through-cloudbreak-ui", 
            "text": "Choose  enable  to enable auto-scaling:   Full size  here .", 
            "title": "Enable Auto-scaling through Cloudbreak UI"
        }, 
        {
            "location": "/periscope/#alerts", 
            "text": "Auto-scaling supports two alert types:  metric  and  time  based.", 
            "title": "Alerts"
        }, 
        {
            "location": "/periscope/#metric-based-alerts", 
            "text": "Metric-based alerts use Ambari metrics. These metrics have a default  Threshold  value configured in Ambari, which you can modify in Ambari web UI.", 
            "title": "Metric-based Alerts"
        }, 
        {
            "location": "/periscope/#change-default-threshold-for-an-ambari-metric", 
            "text": "To change default threshold for an Ambari metric:   Log in to Ambari web UI.   From the header menu, select  Alerts  to open the  Alerts  page.   Select an alert from the list.   In the  Configuration  panel, click on  Edit .   Now you can modify the values in the  Threshold  section.     Full size  here .", 
            "title": "Change Default Threshold for an Ambari Metric"
        }, 
        {
            "location": "/periscope/#create-a-new-metric-based-alert", 
            "text": "To create a new Cloudbreak metric-based alert in the Cloudbreak web UI:   Enter the  alert name . Only alphanumeric characters (min 5, max 100 characters) are allowed.  Enter a  description  for the new alert.  Select a  metric , and then its  desired state . The Ambari metrics available are based on installed services and their state is based on the Ambari threshold value:  OK  WARN   CRITICAL     Enter the  period  (in minutes) to define the metric state endurance after the alert has been triggered. Only numeric characters are allowed.    Full size  here .", 
            "title": "Create a New Metric-based Alert"
        }, 
        {
            "location": "/periscope/#time-based-alerts", 
            "text": "Time-based alerts are based on  cron  expressions, allowing alerts to be triggered based on time.", 
            "title": "Time-based Alerts"
        }, 
        {
            "location": "/periscope/#create-a-time-based-alert", 
            "text": "To create a new Cloudbreak time-based alert in the Cloudbreak UI::   Enter  alert name . Only alphanumeric characters (min 5, max 100 characters) are allowed.  Enter  description  for the new alert.  Select a  time zone  for the new alert.  Provide the  cron expression  to define the time-based job scheduler ( cron  expression) for this alert.    Full size  here .", 
            "title": "Create a Time-based Alert"
        }, 
        {
            "location": "/periscope/#scaling-policies", 
            "text": "Scaling is the ability to increase or decrease the capacity of the HDP cluster or an application running on it based on an alert and according to the policy definition. After you set up your alerts and a scaling policy linked to them, Cloudbreak will execute the policy.   Scaling granularity is at the  host group  level; Thus you have an option to scale services or components only, not the whole cluster.", 
            "title": "Scaling Policies"
        }, 
        {
            "location": "/periscope/#create-a-new-scaling-policy", 
            "text": "To create a new Cloudbreak scaling policy:   Enter the  policy name . Only alphanumeric characters (min 5, max 100 characters) are allowed.  Select a type first, and then a value for the  scaling adjustment :  node count  - number of nodes (added or removed)  percentage  - computed percentage adjustment based on the cluster size  exact  - given size of the cluster    Select the Ambari  host group  where the cluster is to be scaled.  Select the previously created Cloudbreak  alert  to apply the scaling policy to it.    Full size  here .", 
            "title": "Create a New Scaling Policy"
        }, 
        {
            "location": "/periscope/#cluster-scaling-configurations", 
            "text": "An SLA scaling policy can contain multiple alerts. When an alert is triggered, a  scaling adjustment  is applied.   To make sure the scaling this adjustemnt doesn't oversize or undersize your cluster, you can keep the cluster size within defined boundaries using  cluster size min.  and  cluster size max.  To avoid stressing the cluster, we have introduced a  cooldown time  period (in minutes). When an alert is raised and there is an associated scaling policy, the system will not apply the policy within the configured cooldown timeframe.   Note:  In an SLA scaling policy the triggered rules are applied in order.    Full size  here .  Explanation of the parameters:   cooldown time  - the cluster lockdown period (in minutes) between scaling events  cluster size min.  - the minimum cluster size limit, despite scaling adjustments  cluster size max.  - the maximum cluster size limit, despite scaling adjustments", 
            "title": "Cluster Scaling Configurations"
        }, 
        {
            "location": "/periscope/#downscale-scaling-considerations", 
            "text": "To keep your cluster healthy, Cloudbreak auto-scaling runs several background checks during  downscale  operation.   Cloudbreak will never remove  application master nodes  from a cluster. In order to make sure that a node running Ambari Metrics is not \nremoved, Cloudbreak has to be able to access the YARN Resource Manager. When creating a cluster using the  default  secure network template, make sure that the RM's port is open on that node.  In order to keep a healthy HDFS during downscale, Cloudbreak always keeps the  replication factor  configured and makes sure that there is enough  space  on HDFS to rebalance data.  During downscale, in order to minimize the rebalancing, replication, and HDFS storms, Cloudbreak checks block locations \nand computes the least costly operations.   The  API documentation  was generated from the code using  Swagger .", 
            "title": "Downscale Scaling Considerations"
        }, 
        {
            "location": "/recipes/", 
            "text": "Recipes\n\n\nAlthough Cloudbreak lets you provision Hadoop clusters in the cloud from Ambari blueprints, Cloudbreak built-in provisioning doesn't contain all possible use cases. For that reason, we introduced recipes.\n\n\nA \nrecipe\n is a script extension to a cluster that runs on all nodes before or after the Ambari cluster installation. For example, you can use a recipe to put a JAR file on the Hadoop classpath. Recipes are uploaded and stored in Cloudbreak through the web UI or shell.\n\n\nThe easiest way to create a custom recipe is to:\n\n\n\n\nCreate your own pre and/or post scripts\n\n\nUpload them using the web UI or shell \n\n\n\n\nAdding Recipes\n\n\nTo add recipe via the web UI, in the \nmanage recipes\n section, choose \ncreate new recipe\n. Next, select either SCRIPT or FILE type plugin and fill in required fields.\n\n\nTo add recipe via shell, use the following command:\n\n\nrecipe create --name [recipe-name] --type [PRE|POST] --scriptFile /path/of/the/recipe-script\n\n\n\n\nThis command has optional parameters:\n\n\n--description\n \"string\" description of the recipe\n\n\n--scriptUrl\n \"string\" remote location of the recipe\n\n\n--publicInAccount\n \"flag\" flags if the recipe is public in the account\n\n\nSample Recipe for Yum Proxy Setting\n\n\nWe've created a sample recipe that can be used to set proxy for yum:\n\n\n#!/bin/bash\ncat \n /etc/yum.conf \nENDOF\nproxy=http://10.0.0.133:3128\nENDOF\n\n\n\n\n\n\nYou can add this recipe to hostgroups:", 
            "title": "Recipes"
        }, 
        {
            "location": "/recipes/#recipes", 
            "text": "Although Cloudbreak lets you provision Hadoop clusters in the cloud from Ambari blueprints, Cloudbreak built-in provisioning doesn't contain all possible use cases. For that reason, we introduced recipes.  A  recipe  is a script extension to a cluster that runs on all nodes before or after the Ambari cluster installation. For example, you can use a recipe to put a JAR file on the Hadoop classpath. Recipes are uploaded and stored in Cloudbreak through the web UI or shell.  The easiest way to create a custom recipe is to:   Create your own pre and/or post scripts  Upload them using the web UI or shell", 
            "title": "Recipes"
        }, 
        {
            "location": "/recipes/#adding-recipes", 
            "text": "To add recipe via the web UI, in the  manage recipes  section, choose  create new recipe . Next, select either SCRIPT or FILE type plugin and fill in required fields.  To add recipe via shell, use the following command:  recipe create --name [recipe-name] --type [PRE|POST] --scriptFile /path/of/the/recipe-script  This command has optional parameters:  --description  \"string\" description of the recipe  --scriptUrl  \"string\" remote location of the recipe  --publicInAccount  \"flag\" flags if the recipe is public in the account", 
            "title": "Adding Recipes"
        }, 
        {
            "location": "/recipes/#sample-recipe-for-yum-proxy-setting", 
            "text": "We've created a sample recipe that can be used to set proxy for yum:  #!/bin/bash\ncat   /etc/yum.conf  ENDOF\nproxy=http://10.0.0.133:3128\nENDOF   You can add this recipe to hostgroups:", 
            "title": "Sample Recipe for Yum Proxy Setting"
        }, 
        {
            "location": "/blueprints/", 
            "text": "Blueprints\n\n\nFor your convenience, Cloudbreak provides a list of default HDP cluster blueprints. You can also build and use your own blueprint.\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nServices\n\n\nSource\n\n\n\n\n\n\n\n\n\n\nhdp-small-default\n\n\nLaunch a multi-node HDP 2.4 cluster.\n\n\nHDFS, YARN, MAPREDUCE2, KNOX, HBASE, HIVE, HCATALOG, WEBHCAT, SLIDER, OOZIE, PIG, SQOOP, METRICS, TEZ, FALCON, ZOOKEEPER\n\n\nhdp-small-default.bp\n\n\n\n\n\n\nhdp-streaming-cluster\n\n\nLaunch a multi-node HDP 2.4 cluster optimized for streaming.\n\n\nHDFS, YARN, MAPREDUCE2, STORM, KNOX, HBASE, HIVE, HCATALOG, WEBHCAT, SLIDER, OOZIE, PIG, SQOOP, METRICS, TEZ, FALCON, ZOOKEEPER\n\n\nhdp-streaming-cluster.bp\n\n\n\n\n\n\nhdp-spark-cluster\n\n\nLaunch a multi-node HDP 2.4 cluster optimized for Spark analytic jobs.\n\n\nHDFS, YARN, MAPREDUCE2, SPARK, ZEPPELIN, KNOX, HBASE, HIVE, HCATALOG, WEBHCAT, SLIDER, OOZIE, PIG, SQOOP, METRICS, TEZ, FALCON, ZOOKEEPER\n\n\nhdp-spark-cluster.bp\n\n\n\n\n\n\n\n\nComponents\n\n\nAmbari supports the concept of stacks and associated services in a stack definition. By leveraging the stack definition, Ambari has a consistent and defined interface to install, manage, and monitor a set of services, and provides extensibility model for new stacks and services to be introduced.\n\n\nAt a high level, the supported components can be grouped into two main categories: master and slave. The components are bundled together, forming specific services:\n\n\n\n\n\n\n\n\nServices\n\n\nComponents\n\n\n\n\n\n\n\n\n\n\nHDFS\n\n\nDATANODE, HDFS_CLIENT, JOURNALNODE, NAMENODE, SECONDARY_NAMENODE, ZKFC\n\n\n\n\n\n\nYARN\n\n\nAPP_TIMELINE_SERVER, NODEMANAGER, RESOURCEMANAGER, YARN_CLIENT\n\n\n\n\n\n\nMAPREDUCE2\n\n\nHISTORYSERVER, MAPREDUCE2_CLIENT\n\n\n\n\n\n\nHBASE\n\n\nHBASE_CLIENT, HBASE_MASTER, HBASE_REGIONSERVER\n\n\n\n\n\n\nHIVE\n\n\nHIVE_CLIENT, HIVE_METASTORE, HIVE_SERVER, MYSQL_SERVER\n\n\n\n\n\n\nHCATALOG\n\n\nHCAT\n\n\n\n\n\n\nWEBHCAT\n\n\nWEBHCAT_SERVER\n\n\n\n\n\n\nOOZIE\n\n\nOOZIE_CLIENT, OOZIE_SERVER\n\n\n\n\n\n\nPIG\n\n\nPIG\n\n\n\n\n\n\nSQOOP\n\n\nSQOOP\n\n\n\n\n\n\nSTORM\n\n\nDRPC_SERVER, NIMBUS, STORM_REST_API, STORM_UI_SERVER, SUPERVISOR\n\n\n\n\n\n\nTEZ\n\n\nTEZ_CLIENT\n\n\n\n\n\n\nFALCON\n\n\nFALCON_CLIENT, FALCON_SERVER\n\n\n\n\n\n\nZOOKEEPER\n\n\nZOOKEEPER_CLIENT, ZOOKEEPER_SERVER\n\n\n\n\n\n\nSPARK\n\n\nSPARK_JOBHISTORYSERVER, SPARK_CLIENT\n\n\n\n\n\n\nRANGER\n\n\nRANGER_USERSYNC, RANGER_ADMIN\n\n\n\n\n\n\nAMBARI_METRICS\n\n\nAMBARI_METRICS, METRICS_COLLECTOR, METRICS_MONITOR\n\n\n\n\n\n\nKERBEROS\n\n\nKERBEROS_CLIENT\n\n\n\n\n\n\nFLUME\n\n\nFLUME_HANDLER\n\n\n\n\n\n\nKAFKA\n\n\nKAFKA_BROKER\n\n\n\n\n\n\nKNOX\n\n\nKNOX_GATEWAY\n\n\n\n\n\n\nATLAS\n\n\nATLAS\n\n\n\n\n\n\nCLOUDBREAK\n\n\nCLOUDBREAK", 
            "title": "Blueprints"
        }, 
        {
            "location": "/blueprints/#blueprints", 
            "text": "For your convenience, Cloudbreak provides a list of default HDP cluster blueprints. You can also build and use your own blueprint.     Name  Description  Services  Source      hdp-small-default  Launch a multi-node HDP 2.4 cluster.  HDFS, YARN, MAPREDUCE2, KNOX, HBASE, HIVE, HCATALOG, WEBHCAT, SLIDER, OOZIE, PIG, SQOOP, METRICS, TEZ, FALCON, ZOOKEEPER  hdp-small-default.bp    hdp-streaming-cluster  Launch a multi-node HDP 2.4 cluster optimized for streaming.  HDFS, YARN, MAPREDUCE2, STORM, KNOX, HBASE, HIVE, HCATALOG, WEBHCAT, SLIDER, OOZIE, PIG, SQOOP, METRICS, TEZ, FALCON, ZOOKEEPER  hdp-streaming-cluster.bp    hdp-spark-cluster  Launch a multi-node HDP 2.4 cluster optimized for Spark analytic jobs.  HDFS, YARN, MAPREDUCE2, SPARK, ZEPPELIN, KNOX, HBASE, HIVE, HCATALOG, WEBHCAT, SLIDER, OOZIE, PIG, SQOOP, METRICS, TEZ, FALCON, ZOOKEEPER  hdp-spark-cluster.bp", 
            "title": "Blueprints"
        }, 
        {
            "location": "/blueprints/#components", 
            "text": "Ambari supports the concept of stacks and associated services in a stack definition. By leveraging the stack definition, Ambari has a consistent and defined interface to install, manage, and monitor a set of services, and provides extensibility model for new stacks and services to be introduced.  At a high level, the supported components can be grouped into two main categories: master and slave. The components are bundled together, forming specific services:     Services  Components      HDFS  DATANODE, HDFS_CLIENT, JOURNALNODE, NAMENODE, SECONDARY_NAMENODE, ZKFC    YARN  APP_TIMELINE_SERVER, NODEMANAGER, RESOURCEMANAGER, YARN_CLIENT    MAPREDUCE2  HISTORYSERVER, MAPREDUCE2_CLIENT    HBASE  HBASE_CLIENT, HBASE_MASTER, HBASE_REGIONSERVER    HIVE  HIVE_CLIENT, HIVE_METASTORE, HIVE_SERVER, MYSQL_SERVER    HCATALOG  HCAT    WEBHCAT  WEBHCAT_SERVER    OOZIE  OOZIE_CLIENT, OOZIE_SERVER    PIG  PIG    SQOOP  SQOOP    STORM  DRPC_SERVER, NIMBUS, STORM_REST_API, STORM_UI_SERVER, SUPERVISOR    TEZ  TEZ_CLIENT    FALCON  FALCON_CLIENT, FALCON_SERVER    ZOOKEEPER  ZOOKEEPER_CLIENT, ZOOKEEPER_SERVER    SPARK  SPARK_JOBHISTORYSERVER, SPARK_CLIENT    RANGER  RANGER_USERSYNC, RANGER_ADMIN    AMBARI_METRICS  AMBARI_METRICS, METRICS_COLLECTOR, METRICS_MONITOR    KERBEROS  KERBEROS_CLIENT    FLUME  FLUME_HANDLER    KAFKA  KAFKA_BROKER    KNOX  KNOX_GATEWAY    ATLAS  ATLAS    CLOUDBREAK  CLOUDBREAK", 
            "title": "Components"
        }, 
        {
            "location": "/images/", 
            "text": "Custom Cloud Images\n\n\n\n\nCustom Images support is part of \nTECHNICAL PREVIEW\n. It may not be suitable for production use.\n\n\n\n\nEvery cloud platform comes with default images that contain packages required to build an Ambari and HDP stack. These default images are declared in yml files, which Cloudbreak loads upon start. You can customize these images and use them instead of the defaults. \n\n\nTo overwrite the default yml files, place files declaring your custom images in the \n/var/lib/cloudbreak-deployment/etc\n directory. The etc directory does not exist by default so you need to create it.\n\n\nThe format of the yml files is platform-specific and described in the following sections.  \n\n\n\n\nNote:\n If you wish to change the images after Cloudbreak has been launched, you need to restart the application after updating the images.\n\n\n\n\nAWS\n\n\nTo override the default images, create the following file: \n/var/lib/cloudbreak-deployment/etc/aws-images.yml\n and replace its content by region as desired. The default content of the yml file is:\n\n\naws:\n  ap-northeast-1: ami-76729917\n  ap-northeast-2: ami-7c1ad112\n  ap-southeast-1: ami-a7ac7fc4\n  ap-southeast-2: ami-acf7decf\n  eu-central-1: ami-71da331e\n  eu-west-1: ami-cba43bb8\n  sa-east-1: ami-f8901a94\n  us-east-1: ami-bde327d0\n  us-west-1: ami-b76421d7\n  us-west-2: ami-d541bbb5\n\n\n\n\nAzure\n\n\nTo override the default images, create the following file: \n/var/lib/cloudbreak-deployment/etc/arm-images.yml\n and replace its content by region as desired. The default content of the yml file is:\n\n\nazure_rm:\n  East Asia: https://sequenceiqeastasia2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  East US: https://sequenceiqeastus2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  Central US: https://sequenceiqcentralus2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  North Europe: https://sequenceiqnortheurope2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  South Central US: https://sequenceiqouthcentralus2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  North Central US: https://sequenceiqorthcentralus2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  East US 2: https://sequenceiqeastus22.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  Japan East: https://sequenceiqjapaneast2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  Japan West: https://sequenceiqjapanwest2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  Southeast Asia: https://sequenceiqsoutheastasia2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  West US: https://sequenceiqwestus2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  West Europe: https://sequenceiqwesteurope2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  Brazil South: https://sequenceiqbrazilsouth2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n\n\n\n\nGCP\n\n\nTo override the default images, create the following file: \n/var/lib/cloudbreak-deployment/etc/gcp-images.yml\n and replace its content as desired. It is not required to have an image in every region, as the \ndefault\n is used everywhere. The default content of the yml file is:\n\n\ngcp:\n  default: sequenceiqimage/cb-2016-06-14-03-27.tar.gz\n\n\n\n\nOpenStack\n\n\nTo override the default images, create the following file: \n/var/lib/cloudbreak-deployment/etc/os-images.yml\n and replace its content as desired. It is not required to have an image in every region, as the \ndefault\n is used everywhere. The default content of the yml file is:\n\n\nopenstack:\n  default: cloudbreak-2016-06-14-10-58", 
            "title": "Cloud Images (TP)"
        }, 
        {
            "location": "/images/#custom-cloud-images", 
            "text": "Custom Images support is part of  TECHNICAL PREVIEW . It may not be suitable for production use.   Every cloud platform comes with default images that contain packages required to build an Ambari and HDP stack. These default images are declared in yml files, which Cloudbreak loads upon start. You can customize these images and use them instead of the defaults.   To overwrite the default yml files, place files declaring your custom images in the  /var/lib/cloudbreak-deployment/etc  directory. The etc directory does not exist by default so you need to create it.  The format of the yml files is platform-specific and described in the following sections.     Note:  If you wish to change the images after Cloudbreak has been launched, you need to restart the application after updating the images.", 
            "title": "Custom Cloud Images"
        }, 
        {
            "location": "/images/#aws", 
            "text": "To override the default images, create the following file:  /var/lib/cloudbreak-deployment/etc/aws-images.yml  and replace its content by region as desired. The default content of the yml file is:  aws:\n  ap-northeast-1: ami-76729917\n  ap-northeast-2: ami-7c1ad112\n  ap-southeast-1: ami-a7ac7fc4\n  ap-southeast-2: ami-acf7decf\n  eu-central-1: ami-71da331e\n  eu-west-1: ami-cba43bb8\n  sa-east-1: ami-f8901a94\n  us-east-1: ami-bde327d0\n  us-west-1: ami-b76421d7\n  us-west-2: ami-d541bbb5", 
            "title": "AWS"
        }, 
        {
            "location": "/images/#azure", 
            "text": "To override the default images, create the following file:  /var/lib/cloudbreak-deployment/etc/arm-images.yml  and replace its content by region as desired. The default content of the yml file is:  azure_rm:\n  East Asia: https://sequenceiqeastasia2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  East US: https://sequenceiqeastus2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  Central US: https://sequenceiqcentralus2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  North Europe: https://sequenceiqnortheurope2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  South Central US: https://sequenceiqouthcentralus2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  North Central US: https://sequenceiqorthcentralus2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  East US 2: https://sequenceiqeastus22.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  Japan East: https://sequenceiqjapaneast2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  Japan West: https://sequenceiqjapanwest2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  Southeast Asia: https://sequenceiqsoutheastasia2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  West US: https://sequenceiqwestus2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  West Europe: https://sequenceiqwesteurope2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd\n  Brazil South: https://sequenceiqbrazilsouth2.blob.core.windows.net/images/cb-2016-06-14-03-27.vhd", 
            "title": "Azure"
        }, 
        {
            "location": "/images/#gcp", 
            "text": "To override the default images, create the following file:  /var/lib/cloudbreak-deployment/etc/gcp-images.yml  and replace its content as desired. It is not required to have an image in every region, as the  default  is used everywhere. The default content of the yml file is:  gcp:\n  default: sequenceiqimage/cb-2016-06-14-03-27.tar.gz", 
            "title": "GCP"
        }, 
        {
            "location": "/images/#openstack", 
            "text": "To override the default images, create the following file:  /var/lib/cloudbreak-deployment/etc/os-images.yml  and replace its content as desired. It is not required to have an image in every region, as the  default  is used everywhere. The default content of the yml file is:  openstack:\n  default: cloudbreak-2016-06-14-10-58", 
            "title": "OpenStack"
        }, 
        {
            "location": "/topologies/", 
            "text": "Platform Tagging\n\n\n\n\nThis feature is part of \nTECHNICAL PREVIEW\n.\n\n\n\n\nYou can define platform tags and attach them to credentials, networks, and templates to bundle together different configurations.\n\n\nData Locality and Topologies\n\n\nThe \nOpenStack documentation\n says this about data locality: \"It is extremely important for data processing to do locally (on the same rack, OpenStack compute node or even VM) as much work as possible. Hadoop supports data-locality feature and can schedule jobs to task tracker nodes that are local for input stream. In this case task tracker could communicate directly with local data node.\"\n\n\nOpenStack Topology Mapping\n\n\nYou can create a topology mapping, which associates hypervisors with racks, and then attach it to the platform definition. \nYou can set the mapping in the Cloudbreak UI or in CLI by defining it line by line or uploading the mapping in a file.\n\n\nThe \nmapping file\n should have the following format:\n\n\nhypervisor1 /rack1\nhypervisor2 /rack2\nhypervisor3 /rack2\n\n\n\nBased on this mapping, the Cloudbreak application ensures that the rack information of the started VMs will be passed to Hadoop services via Ambari.\n\n\nPlatform Configuration Through Cloudbreak UI\n\n\nManage Platform Configuration\n\n\n\n\nYou can log in to the Cloudbreak application at https://PUBLIC_IP. You can find the provider-specific documentation here:\n\n\n\n\nAWS\n\n\nAzure\n\n\nGCP\n\n\nOpenStack\n\n\n\n\n\n\nTo create a new platform configuration:\n\n\n\n\nGo to the \nmanage platforms\n panel. \n\n\nSelect \nOpenStack\n from cloud provider tabs.\n\n\nFill out the new configuration \nName\n.\n\n\nComplete the \nTopology Mapping\n section based on the above examples. Add mapping line by line or upload a mapping file. \n\n\n\n\n\n\nFull size \nhere\n.\n\n\n\n\nNOTE:\n Platform name is the only required parameter.\n\n\n\n\nExplanation of the parameters:\n\n\nRequired parameters:\n\n\n\n\nName\n - name for the new configuration\n\n\nStarts with a lowercase alphabetic character \n\n\nContains lowercase alphanumeric and hyphens only\n\n\nIncludes min 5 and max 100 characters\n\n\n\n\n\n\n\n\nOptional parameters:\n\n\n\n\nDescription\n - description for the new configuration (Up to 1000 characters)\n\n\nUpload Mapping File\n - file containing mapping definition\n\n\nFor details, see \nOpenstack Topology Mapping section\n\n\n\n\n\n\nTopology Mapping\n:\n\n\nHypervisor\n - your hypervisor name\n\n\nRack\n - the rack name for hypervisor\n\n\n\n\n\n\n\n\nEnable Platform Configuration\n\n\nYou can apply your Cloudbreak platform configuration in the following panels:\n\n\n\n\ncreate network\n\n\ncreate credential\n\n\ncreate template\n\n\n\n\nTo create a new network with a previously created configuration, follow these steps in the \ncreate network\n panel:\n\n\n\n\nFrom cloud provider tabs, select \nOpenStack\n.\n\n\nEnter the new network \nName\n.\n\n\nEnter your network \nSubnet (CIDR)\n.\n\n\nEnter your \nPublic Network ID\n.\n\n\nUder \nSelect Platform\n, select your previously created platform.\n\n\n\n\n\n\nFull size \nhere\n.\n\n\n\n\nIMOPRTANT:\n If you assign a platform to a selected credential, then only networks and templates associated with that credential can\n be selected during cluster creation.\n\n\n\n\nPlatform Configuration via CLI\n\n\nManage Platform Configuration\n\n\n\n\nStart the shell with \ncbd util cloudbreak-shell\n on a console. This will launch the Cloudbreak shell inside a Docker\n container and you can start using it. For more information, see \nCloudbreak Shell\n.\n\n\n\n\nHere are two examples:\nFor \nAWS\n:\n\n\n# Creating a Platform\nplatform create --AWS --name platform-name --description 'description of the platform'\n\n\n\n\nFor \nOPENSTACK\n:\n\n\n# Creating OpenStack Platform with topology mapping\nplatform create --OPENSTACK --name platform-name --description 'openstack platform' --file file_path\nplatform create --OPENSTACK --name platform-name --description 'openstack platform' --url url_to_file\n\n\n\n\nEnable Platform Configuration\n\n\nYou can use the following Cloudbreak shell commands to set a platform for a resource:\n\n\n\n\nnetwork create\n\n\ncredential create\n\n\ntemplate create\n\n\n\n\nHere is an example shell command to create a new network with a connected platform:\n\n\nnetwork create --AWS --name aws-network --subnet 10.10.10.0/24 --description 'example network' --platformId 26\n\n\n\n\n\n\nIMOPRTANT:\n If you assign a platform to a selected credential, then only networks and templates associated with that credential can\n be selected during cluster creation.", 
            "title": "Platforms (TP)"
        }, 
        {
            "location": "/topologies/#platform-tagging", 
            "text": "This feature is part of  TECHNICAL PREVIEW .   You can define platform tags and attach them to credentials, networks, and templates to bundle together different configurations.", 
            "title": "Platform Tagging"
        }, 
        {
            "location": "/topologies/#data-locality-and-topologies", 
            "text": "The  OpenStack documentation  says this about data locality: \"It is extremely important for data processing to do locally (on the same rack, OpenStack compute node or even VM) as much work as possible. Hadoop supports data-locality feature and can schedule jobs to task tracker nodes that are local for input stream. In this case task tracker could communicate directly with local data node.\"", 
            "title": "Data Locality and Topologies"
        }, 
        {
            "location": "/topologies/#openstack-topology-mapping", 
            "text": "You can create a topology mapping, which associates hypervisors with racks, and then attach it to the platform definition. \nYou can set the mapping in the Cloudbreak UI or in CLI by defining it line by line or uploading the mapping in a file.  The  mapping file  should have the following format:  hypervisor1 /rack1\nhypervisor2 /rack2\nhypervisor3 /rack2  Based on this mapping, the Cloudbreak application ensures that the rack information of the started VMs will be passed to Hadoop services via Ambari.", 
            "title": "OpenStack Topology Mapping"
        }, 
        {
            "location": "/topologies/#platform-configuration-through-cloudbreak-ui", 
            "text": "", 
            "title": "Platform Configuration Through Cloudbreak UI"
        }, 
        {
            "location": "/topologies/#manage-platform-configuration", 
            "text": "You can log in to the Cloudbreak application at https://PUBLIC_IP. You can find the provider-specific documentation here:   AWS  Azure  GCP  OpenStack    To create a new platform configuration:   Go to the  manage platforms  panel.   Select  OpenStack  from cloud provider tabs.  Fill out the new configuration  Name .  Complete the  Topology Mapping  section based on the above examples. Add mapping line by line or upload a mapping file.     Full size  here .   NOTE:  Platform name is the only required parameter.   Explanation of the parameters:  Required parameters:   Name  - name for the new configuration  Starts with a lowercase alphabetic character   Contains lowercase alphanumeric and hyphens only  Includes min 5 and max 100 characters     Optional parameters:   Description  - description for the new configuration (Up to 1000 characters)  Upload Mapping File  - file containing mapping definition  For details, see  Openstack Topology Mapping section    Topology Mapping :  Hypervisor  - your hypervisor name  Rack  - the rack name for hypervisor", 
            "title": "Manage Platform Configuration"
        }, 
        {
            "location": "/topologies/#enable-platform-configuration", 
            "text": "You can apply your Cloudbreak platform configuration in the following panels:   create network  create credential  create template   To create a new network with a previously created configuration, follow these steps in the  create network  panel:   From cloud provider tabs, select  OpenStack .  Enter the new network  Name .  Enter your network  Subnet (CIDR) .  Enter your  Public Network ID .  Uder  Select Platform , select your previously created platform.    Full size  here .   IMOPRTANT:  If you assign a platform to a selected credential, then only networks and templates associated with that credential can\n be selected during cluster creation.", 
            "title": "Enable Platform Configuration"
        }, 
        {
            "location": "/topologies/#platform-configuration-via-cli", 
            "text": "", 
            "title": "Platform Configuration via CLI"
        }, 
        {
            "location": "/topologies/#manage-platform-configuration_1", 
            "text": "Start the shell with  cbd util cloudbreak-shell  on a console. This will launch the Cloudbreak shell inside a Docker\n container and you can start using it. For more information, see  Cloudbreak Shell .   Here are two examples:\nFor  AWS :  # Creating a Platform\nplatform create --AWS --name platform-name --description 'description of the platform'  For  OPENSTACK :  # Creating OpenStack Platform with topology mapping\nplatform create --OPENSTACK --name platform-name --description 'openstack platform' --file file_path\nplatform create --OPENSTACK --name platform-name --description 'openstack platform' --url url_to_file", 
            "title": "Manage Platform Configuration"
        }, 
        {
            "location": "/topologies/#enable-platform-configuration_1", 
            "text": "You can use the following Cloudbreak shell commands to set a platform for a resource:   network create  credential create  template create   Here is an example shell command to create a new network with a connected platform:  network create --AWS --name aws-network --subnet 10.10.10.0/24 --description 'example network' --platformId 26   IMOPRTANT:  If you assign a platform to a selected credential, then only networks and templates associated with that credential can\n be selected during cluster creation.", 
            "title": "Enable Platform Configuration"
        }, 
        {
            "location": "/kerberos/", 
            "text": "Kerberos Security\n\n\n\n\nThis feature is part of \nTECHNICAL PREVIEW\n.\n\n\n\n\nCloudbreak Supports 3 different way for provision Kerberos enabled clusters all the possibilities described above:\n\n\nCreate new MIT Kerberos at provisioning time\n\n\nCloudbreak supports using Kerberos security on the cluster. When creating a cluster, provide your Kerberos configuration details, and Cloudbreak will install an MIT KDC and enable Kerberos on the cluster.\n\n\nEnable Kerberos\n\n\nTo enable Kerberos on a cluster, do the following when creating your cluster via Cloudbreak web UI:\n\n\n\n\nIn the \nCreate cluster\n wizard, in the \nSetup Network and Security\n tab, check the \nEnable security\n option and select \nCreate New MIT Kerberos\n.\n\n\nFill in the following fields:\n\n\n\n\n\n\n\n\n\n\nField\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nKerberos master key\n\n\nThe master key to use for the KDC.\n\n\n\n\n\n\nKerberos admin\n\n\nThe KDC admin username to use for the KDC.\n\n\n\n\n\n\nKerberos password\n\n\nThe KDC admin password to use for the KDC.\n\n\n\n\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nTesting Kerberos\n\n\nTo run a job on the cluster, you can use one of the default Hadoop users, like \nambari-qa\n.\nOnce kerberos is enabled, you need a \nticket\n to execute any job on the cluster. \n\n\nHere's an example of how to get a ticket:\n\n\nkinit -V -kt /etc/security/keytabs/smokeuser.headless.keytab ambari-qa-sparktest-rec@NODE.DC1.CONSUL\n\n\n\n\nHere is an example job:\n\n\nexport HADOOP_LIBS=/usr/hdp/current/hadoop-mapreduce-client\nexport JAR_EXAMPLES=$HADOOP_LIBS/hadoop-mapreduce-examples.jar\nexport JAR_JOBCLIENT=$HADOOP_LIBS/hadoop-mapreduce-client-jobclient.jar\n\nhadoop jar $JAR_EXAMPLES teragen 10000000 /user/ambari-qa/terasort-input\n\nhadoop jar $JAR_JOBCLIENT mrbench -baseDir /user/ambari-qa/smallJobsBenchmark -numRuns 5 -maps 10 -reduces 5 -inputLines 10 -inputType ascending\n\n\n\n\nUse your Existing MIT Kerberos server with a Cloudbreak provisioned cluster.\n\n\nCloudbreak supports using Kerberos security on the cluster with an existing MIT Kerberos. When creating a cluster, provide your Kerberos configuration details, and Cloudbreak will automatically extend your blueprint configuration with the defined properties. \nSetup an exiting MIT KDC\n\n\nTo enable Kerberos on a cluster, do the following when creating your cluster via Cloudbreak web UI:\n\n\n\n\nIn the \nCreate cluster\n wizard, in the \nSetup Network and Security\n tab, check the \nEnable security\n option and select \nUse Existing MIT Kerberos\n.\n\n\nFill in the following fields:\n\n\n\n\n\n\n\n\n\n\nField\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nKerberos Password\n\n\nThe KDC admin password to use for the KDC.\n\n\n\n\n\n\nExisting Kerberos Principal\n\n\nThe KDC principal in your existing MIT KDC.\n\n\n\n\n\n\nExisting Kerberos URL\n\n\nThe location of your existing MIT KDC.\n\n\n\n\n\n\nUse Tcp Connection\n\n\nThe connection type for your existing MIT KDC (default is \nUDP\n).\n\n\n\n\n\n\nExisting Kerberos Realm\n\n\nThe realm in your existing MIT KDC.\n\n\n\n\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nTo enable Kerberos on a cluster, do the following when creating your cluster via Cloudbreak shell:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n--kerberosPassword\n\n\nThe KDC admin password to use for the KDC.\n\n\n\n\n\n\n--kerberosPrincipal\n\n\nThe KDC principal in your existing MIT KDC.\n\n\n\n\n\n\n--kerberosUrl\n\n\nThe location of your existing MIT KDC.\n\n\n\n\n\n\n--kerberosTcpAllowed\n\n\nThe connection type for your existing MIT KDC (default is \nUDP\n).\n\n\n\n\n\n\n--kerberosRealm\n\n\nThe realm in your existing MIT KDC.\n\n\n\n\n\n\n\n\nUse your Existing Active Directory with a Cloudbreak provisioned cluster.\n\n\nCloudbreak supports using Kerberos security on the cluster with an existing Active Directory. When creating a cluster, provide your Kerberos configuration details, and Cloudbreak will automatically extend your blueprint configuration with the defined properties. \nSetup an Active Directory for Kerberos\n\n\nEnable Kerberos\n\n\nTo enable Kerberos on a cluster, do the following when creating your cluster via Cloudbreak web UI:\n\n\n\n\nIn the \nCreate cluster\n wizard, in the \nSetup Network and Security\n tab, check the \nEnable security\n option and select \nUse Existing Active Directory\n.\n\n\nFill in the following fields:\n\n\n\n\n\n\n\n\n\n\nField\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nKerberos Password\n\n\nThe KDC admin password to use for the KDC.\n\n\n\n\n\n\nExisting Kerberos Principal\n\n\nThe KDC principal in your existing MIT KDC.\n\n\n\n\n\n\nExisting Kerberos URL\n\n\nThe location of your existing MIT KDC.\n\n\n\n\n\n\nUse Tcp Connection\n\n\nThe connection type for your existing MIT KDC (default is \nUDP\n).\n\n\n\n\n\n\nExisting Kerberos Realm\n\n\nThe realm in your existing MIT KDC.\n\n\n\n\n\n\nExisting Kerberos Ldap AD Url\n\n\nThe url of the existing secure ldap (eg. ldaps://10.1.1.5).\n\n\n\n\n\n\nExisting Kerberos AD Container DN\n\n\nActive Directory User container for principals. For example, \"OU=Hadoop,OU=People,dc=apache,dc=org\".\n\n\n\n\n\n\n\n\n\n\nFull size \nhere\n.\n\n\nTo enable Kerberos on a cluster, do the following when creating your cluster via Cloudbreak shell:\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n--kerberosPassword\n\n\nThe KDC admin password to use for the KDC.\n\n\n\n\n\n\n--kerberosPrincipal\n\n\nThe KDC principal in your existing MIT KDC.\n\n\n\n\n\n\n--kerberosUrl\n\n\nThe location of your existing MIT KDC.\n\n\n\n\n\n\n--kerberosTcpAllowed\n\n\nThe connection type for your existing MIT KDC (default is \nUDP\n).\n\n\n\n\n\n\n--kerberosRealm\n\n\nThe realm in your existing MIT KDC.\n\n\n\n\n\n\n--kerberosLdapUrl\n\n\nThe url of the existing secure ldap (eg. ldaps://10.1.1.5).\n\n\n\n\n\n\n--kerberosContainerDn\n\n\nActive Directory User container for principals. For example, \"OU=Hadoop,OU=People,dc=apache,dc=org\".\n\n\n\n\n\n\n\n\nCreate Hadoop Users\n\n\nTo create Hadoop users, follow the steps below.\n\n\n\n\nLog in via SSH to the node where the Ambari Server is (IP address is the same as the Ambari UI) and run:\n\n\n\n\nkadmin -p [admin_user]/[admin_user]@NODE.DC1.CONSUL (type admin password)\naddprinc custom-user (type user password twice)\n\n\n\n\n\n\nLog in via SSH to all other nodes and, on each node, run:\n\n\n\n\nuseradd custom-user\n\n\n\n\n\n\nLog in via SSH to one of the nodes and run:\n\n\n\n\nsu custom-user\nkinit -p custom-user (type user password)\nhdfs dfs -mkdir input\nhdfs dfs -put /tmp/wait-for-host-number.sh input\nyarn jar $(find /usr/hdp -name hadoop-mapreduce-examples.jar) wordcount input output\nhdfs dfs -cat output/*", 
            "title": "Kerberos (TP)"
        }, 
        {
            "location": "/kerberos/#kerberos-security", 
            "text": "This feature is part of  TECHNICAL PREVIEW .   Cloudbreak Supports 3 different way for provision Kerberos enabled clusters all the possibilities described above:", 
            "title": "Kerberos Security"
        }, 
        {
            "location": "/kerberos/#create-new-mit-kerberos-at-provisioning-time", 
            "text": "Cloudbreak supports using Kerberos security on the cluster. When creating a cluster, provide your Kerberos configuration details, and Cloudbreak will install an MIT KDC and enable Kerberos on the cluster.", 
            "title": "Create new MIT Kerberos at provisioning time"
        }, 
        {
            "location": "/kerberos/#enable-kerberos", 
            "text": "To enable Kerberos on a cluster, do the following when creating your cluster via Cloudbreak web UI:   In the  Create cluster  wizard, in the  Setup Network and Security  tab, check the  Enable security  option and select  Create New MIT Kerberos .  Fill in the following fields:      Field  Description      Kerberos master key  The master key to use for the KDC.    Kerberos admin  The KDC admin username to use for the KDC.    Kerberos password  The KDC admin password to use for the KDC.      Full size  here .", 
            "title": "Enable Kerberos"
        }, 
        {
            "location": "/kerberos/#testing-kerberos", 
            "text": "To run a job on the cluster, you can use one of the default Hadoop users, like  ambari-qa .\nOnce kerberos is enabled, you need a  ticket  to execute any job on the cluster.   Here's an example of how to get a ticket:  kinit -V -kt /etc/security/keytabs/smokeuser.headless.keytab ambari-qa-sparktest-rec@NODE.DC1.CONSUL  Here is an example job:  export HADOOP_LIBS=/usr/hdp/current/hadoop-mapreduce-client\nexport JAR_EXAMPLES=$HADOOP_LIBS/hadoop-mapreduce-examples.jar\nexport JAR_JOBCLIENT=$HADOOP_LIBS/hadoop-mapreduce-client-jobclient.jar\n\nhadoop jar $JAR_EXAMPLES teragen 10000000 /user/ambari-qa/terasort-input\n\nhadoop jar $JAR_JOBCLIENT mrbench -baseDir /user/ambari-qa/smallJobsBenchmark -numRuns 5 -maps 10 -reduces 5 -inputLines 10 -inputType ascending", 
            "title": "Testing Kerberos"
        }, 
        {
            "location": "/kerberos/#use-your-existing-mit-kerberos-server-with-a-cloudbreak-provisioned-cluster", 
            "text": "Cloudbreak supports using Kerberos security on the cluster with an existing MIT Kerberos. When creating a cluster, provide your Kerberos configuration details, and Cloudbreak will automatically extend your blueprint configuration with the defined properties.  Setup an exiting MIT KDC  To enable Kerberos on a cluster, do the following when creating your cluster via Cloudbreak web UI:   In the  Create cluster  wizard, in the  Setup Network and Security  tab, check the  Enable security  option and select  Use Existing MIT Kerberos .  Fill in the following fields:      Field  Description      Kerberos Password  The KDC admin password to use for the KDC.    Existing Kerberos Principal  The KDC principal in your existing MIT KDC.    Existing Kerberos URL  The location of your existing MIT KDC.    Use Tcp Connection  The connection type for your existing MIT KDC (default is  UDP ).    Existing Kerberos Realm  The realm in your existing MIT KDC.      Full size  here .  To enable Kerberos on a cluster, do the following when creating your cluster via Cloudbreak shell:     Parameter  Description      --kerberosPassword  The KDC admin password to use for the KDC.    --kerberosPrincipal  The KDC principal in your existing MIT KDC.    --kerberosUrl  The location of your existing MIT KDC.    --kerberosTcpAllowed  The connection type for your existing MIT KDC (default is  UDP ).    --kerberosRealm  The realm in your existing MIT KDC.", 
            "title": "Use your Existing MIT Kerberos server with a Cloudbreak provisioned cluster."
        }, 
        {
            "location": "/kerberos/#use-your-existing-active-directory-with-a-cloudbreak-provisioned-cluster", 
            "text": "Cloudbreak supports using Kerberos security on the cluster with an existing Active Directory. When creating a cluster, provide your Kerberos configuration details, and Cloudbreak will automatically extend your blueprint configuration with the defined properties.  Setup an Active Directory for Kerberos", 
            "title": "Use your Existing Active Directory with a Cloudbreak provisioned cluster."
        }, 
        {
            "location": "/kerberos/#enable-kerberos_1", 
            "text": "To enable Kerberos on a cluster, do the following when creating your cluster via Cloudbreak web UI:   In the  Create cluster  wizard, in the  Setup Network and Security  tab, check the  Enable security  option and select  Use Existing Active Directory .  Fill in the following fields:      Field  Description      Kerberos Password  The KDC admin password to use for the KDC.    Existing Kerberos Principal  The KDC principal in your existing MIT KDC.    Existing Kerberos URL  The location of your existing MIT KDC.    Use Tcp Connection  The connection type for your existing MIT KDC (default is  UDP ).    Existing Kerberos Realm  The realm in your existing MIT KDC.    Existing Kerberos Ldap AD Url  The url of the existing secure ldap (eg. ldaps://10.1.1.5).    Existing Kerberos AD Container DN  Active Directory User container for principals. For example, \"OU=Hadoop,OU=People,dc=apache,dc=org\".      Full size  here .  To enable Kerberos on a cluster, do the following when creating your cluster via Cloudbreak shell:     Parameter  Description      --kerberosPassword  The KDC admin password to use for the KDC.    --kerberosPrincipal  The KDC principal in your existing MIT KDC.    --kerberosUrl  The location of your existing MIT KDC.    --kerberosTcpAllowed  The connection type for your existing MIT KDC (default is  UDP ).    --kerberosRealm  The realm in your existing MIT KDC.    --kerberosLdapUrl  The url of the existing secure ldap (eg. ldaps://10.1.1.5).    --kerberosContainerDn  Active Directory User container for principals. For example, \"OU=Hadoop,OU=People,dc=apache,dc=org\".", 
            "title": "Enable Kerberos"
        }, 
        {
            "location": "/kerberos/#create-hadoop-users", 
            "text": "To create Hadoop users, follow the steps below.   Log in via SSH to the node where the Ambari Server is (IP address is the same as the Ambari UI) and run:   kadmin -p [admin_user]/[admin_user]@NODE.DC1.CONSUL (type admin password)\naddprinc custom-user (type user password twice)   Log in via SSH to all other nodes and, on each node, run:   useradd custom-user   Log in via SSH to one of the nodes and run:   su custom-user\nkinit -p custom-user (type user password)\nhdfs dfs -mkdir input\nhdfs dfs -put /tmp/wait-for-host-number.sh input\nyarn jar $(find /usr/hdp -name hadoop-mapreduce-examples.jar) wordcount input output\nhdfs dfs -cat output/*", 
            "title": "Create Hadoop Users"
        }, 
        {
            "location": "/ldap/", 
            "text": "LDAP/AD configuration\n\n\nThere are cases where it might be useful to authenticate Cloudbreak users against an existing enterprise LDAP/AD server as it might already have all the users preconfigured. Cloudbreak supports this without the need to modify the existing LDAP schema.\n\n\nTo setup LDAP/AD authentication for Cloudbreak, the \n/var/lib/cloudbreak-deployment/uaa.yml\n must be changed as it is described in \nCloudfoundry's documentation\n.\n\n\nSample for LDAP authentication (the CN of the users in LDAP is the e-mail address in this case, as Cloudbreak uses an e-mail address as identifier):\n\n\nspring_profiles: postgresql,ldap\n\nldap:\n  profile:\n    file: ldap/ldap-search-and-bind.xml\n  base:\n    url: 'ldap://10.0.3.138:389/'\n    userDn: 'CN=Administrator,CN=Users,DC=ad,DC=hortonworks,DC=com'\n    password: 'Admin123!'\n    searchBase: 'DC=ad,DC=hortonworks,DC=com'\n    searchFilter: 'cn={0}'\n  groups:\n    file: ldap/ldap-groups-map-to-scopes.xml\n    searchBase: ou=scopes,dc=ad,dc=hortonworks,dc=com\n    searchSubtree: true\n    groupSearchFilter: member={0}\n    maxSearchDepth: 10\n    autoAdd: true\n\n... rest of the content of uaa.yml\n\n\n\n\nAn ldapsearch query can be run to verify the Administrator's credentials and to be able to bind (sample):\n\n\nldapsearch -x -h 10.0.3.138 -D \nCN=Administrator,CN=Users,DC=ad,DC=hortonworks,DC=com\n -W -b \nuid=user,cn=Users,dc=ad,dc=hortonworks,dc=com\n\n\n\n\n\nIf the user cannot bind, then it is possible to use password comparison method as well as described \nhere\n.\n\n\nOnce the changes are made the following property must be set in the Profile file:\n\n\nCBD_FORCE_START=true\n\n\n\n\nThis will ensure that the application will start with the modified uaa.yml. After that changes are made restart the application:\n\n\ncbd kill\ncbd start\n\n\n\n\nNote:\n DO NOT use the \ncbd restart\n command as it regenerates all the yml files so the changes will be lost in uaa.yml.\n\n\nMapping Oauth2 scopes to LDAP groups\n\n\nIn order for the users to have access to Cloudbreak resources and to be able to create clusters the Oauth2 scopes must be mapped to LDAP groups. At the moment Cloudbreak only supports \none LDAP group per user\n scenario.\nTo see the Oauth2 scopes, execute the following command:\n\n\ndocker exec -it cbreak_commondb_1 psql -U postgres -d uaadb -c 'select displayname from groups;'\n\n\n\n\nTo save them to a \ngroups.txt\n file:\n\n\ndocker exec cbreak_commondb_1 psql -U postgres -d uaadb -c 'select displayname from groups;' | tail -n +3 | grep -v rows | xargs -I@ echo @ \n groups.txt\n\n\n\n\nTo generate the SQL commands for the mapping we'll use \nsigil\n, which is a string interpolator and template processor. It is a single binary written in Golang and you can download it from the \nreleases\n page.\nSave the following in a file called: \ntemplate.sig\n (cn=admin,ou=scopes,dc=ad,dc=hortonworks,dc=com depends on your LDAP group, it must be inside searchBase parameter configured in the first step in UAA.yml):\n\n\n{{ range $k, $v := stdin|split \n\\n\n}}\n INSERT INTO external_group_mapping (group_id, external_group, added, origin) VALUES ((select id from groups where displayname='{{$v}}'), 'cn=admin,ou=scopes,dc=ad,dc=hortonworks,dc=com', '2016-09-30 19:28:24.255', 'ldap');{{end}}\n\n\n\n\nthen generate the SQL commands into \nmapping.sql\n:\n\n\ncat groups.txt | sigil -f template.sig \n mapping.sql\n\n\n\n\nand remove lines with empty displayname:\n\n\nsed -i.bak \n/displayname=''/d\n mapping.sql\n\n\n\n\nthen execute the commands:\n\n\ndocker cp mapping.sql cbreak_commondb_1:/tmp/mapping.sql\ndocker exec cbreak_commondb_1 psql -U postgres -d uaadb -f /tmp/mapping.sql\n\n\n\n\nAfter the mapping is successfully done, you can log in with users authenticated against LDAP.", 
            "title": "LDAP/AD (TP)"
        }, 
        {
            "location": "/ldap/#ldapad-configuration", 
            "text": "There are cases where it might be useful to authenticate Cloudbreak users against an existing enterprise LDAP/AD server as it might already have all the users preconfigured. Cloudbreak supports this without the need to modify the existing LDAP schema.  To setup LDAP/AD authentication for Cloudbreak, the  /var/lib/cloudbreak-deployment/uaa.yml  must be changed as it is described in  Cloudfoundry's documentation .  Sample for LDAP authentication (the CN of the users in LDAP is the e-mail address in this case, as Cloudbreak uses an e-mail address as identifier):  spring_profiles: postgresql,ldap\n\nldap:\n  profile:\n    file: ldap/ldap-search-and-bind.xml\n  base:\n    url: 'ldap://10.0.3.138:389/'\n    userDn: 'CN=Administrator,CN=Users,DC=ad,DC=hortonworks,DC=com'\n    password: 'Admin123!'\n    searchBase: 'DC=ad,DC=hortonworks,DC=com'\n    searchFilter: 'cn={0}'\n  groups:\n    file: ldap/ldap-groups-map-to-scopes.xml\n    searchBase: ou=scopes,dc=ad,dc=hortonworks,dc=com\n    searchSubtree: true\n    groupSearchFilter: member={0}\n    maxSearchDepth: 10\n    autoAdd: true\n\n... rest of the content of uaa.yml  An ldapsearch query can be run to verify the Administrator's credentials and to be able to bind (sample):  ldapsearch -x -h 10.0.3.138 -D  CN=Administrator,CN=Users,DC=ad,DC=hortonworks,DC=com  -W -b  uid=user,cn=Users,dc=ad,dc=hortonworks,dc=com   If the user cannot bind, then it is possible to use password comparison method as well as described  here .  Once the changes are made the following property must be set in the Profile file:  CBD_FORCE_START=true  This will ensure that the application will start with the modified uaa.yml. After that changes are made restart the application:  cbd kill\ncbd start  Note:  DO NOT use the  cbd restart  command as it regenerates all the yml files so the changes will be lost in uaa.yml.", 
            "title": "LDAP/AD configuration"
        }, 
        {
            "location": "/ldap/#mapping-oauth2-scopes-to-ldap-groups", 
            "text": "In order for the users to have access to Cloudbreak resources and to be able to create clusters the Oauth2 scopes must be mapped to LDAP groups. At the moment Cloudbreak only supports  one LDAP group per user  scenario.\nTo see the Oauth2 scopes, execute the following command:  docker exec -it cbreak_commondb_1 psql -U postgres -d uaadb -c 'select displayname from groups;'  To save them to a  groups.txt  file:  docker exec cbreak_commondb_1 psql -U postgres -d uaadb -c 'select displayname from groups;' | tail -n +3 | grep -v rows | xargs -I@ echo @   groups.txt  To generate the SQL commands for the mapping we'll use  sigil , which is a string interpolator and template processor. It is a single binary written in Golang and you can download it from the  releases  page.\nSave the following in a file called:  template.sig  (cn=admin,ou=scopes,dc=ad,dc=hortonworks,dc=com depends on your LDAP group, it must be inside searchBase parameter configured in the first step in UAA.yml):  {{ range $k, $v := stdin|split  \\n }}\n INSERT INTO external_group_mapping (group_id, external_group, added, origin) VALUES ((select id from groups where displayname='{{$v}}'), 'cn=admin,ou=scopes,dc=ad,dc=hortonworks,dc=com', '2016-09-30 19:28:24.255', 'ldap');{{end}}  then generate the SQL commands into  mapping.sql :  cat groups.txt | sigil -f template.sig   mapping.sql  and remove lines with empty displayname:  sed -i.bak  /displayname=''/d  mapping.sql  then execute the commands:  docker cp mapping.sql cbreak_commondb_1:/tmp/mapping.sql\ndocker exec cbreak_commondb_1 psql -U postgres -d uaadb -f /tmp/mapping.sql  After the mapping is successfully done, you can log in with users authenticated against LDAP.", 
            "title": "Mapping Oauth2 scopes to LDAP groups"
        }, 
        {
            "location": "/mesos/", 
            "text": "Mesos Introduction\n\n\n\n\nMesos support is part of \nTECHNICAL PREVIEW\n. It may not be suitable for production use.\n\n\n\n\nAt a high level, Cloudbreak deployment on Mesos is similar to Cloudbreak implementations on other cloud providers: HDP clusters are provisioned through Ambari with the help of blueprints, and Ambari server and agents run in Docker containers. However, there are a few major differences that you should consider before you start working with Cloudbreak on Mesos.\n\n\nDifferences with Other Cloud Provider Implementations\n\n\nThe Mesos integration doesn't start new instances and doesn't build new infrastructure on a cloud provider.\n\n\nCloudbreak expects a \"bring your own Mesos\" infrastructure, which means that you have to deploy Mesos first and then configure access to the existing Mesos deployment in Cloudbreak. \n\n\nOn other cloud providers, Cloudbreak first builds the infrastructure where Hadoop components are later deployed through Ambari. This involves creating or reusing the networking layer (virtual networks, subnets, and so on), provisioning new virtual machines in these networks from pre-existing cloud images, and starting docker containers on these VMs (nodes). However, the Mesos integration was designed \nnot\n to include these steps, because in most cases users already have their own Mesos infrastructure on which they would like to deploy their cluster. \n\n\nA Mesos credential in the Cloudbreak UI provides access to the Marathon API.\n\n\nMarathon is a standard application scheduling framework for services in Mesos. Cloudbreak uses Marathon API to communicate with Mesos, so you need to deploy Marathon on the Mesos cluster and, when setting up access to Mesos in Cloudbreak, specify a Marathon API endpoint. Basic authentication and TLS on the Marathon API are not supported in the technical preview.\n\n\nA Mesos template in the Cloudbreak UI means resource constraints instead of new resources.\n\n\nThrough the Cloudbreak UI, you can create Cloudbreak templates that define the virtual machines in a cluster's hostgroup that will be provisioned through the cloud provider API. You can create such templates for Mesos and you can link the VMs to a hostgroup, but for Mesos these templates mean resource constraints that will be demanded through the Marathon API, not resources that will created. \n\n\nFor example, consider these two scenarios:\n\n- An AWS template with an instance type of \nm4.large\n and 4 pieces of 50 GB attached magnetic volumes will create a VM with these specs when Cloudbreak is building the cluster infrastructure.\n- A Mesos template with 2 CPU cores and 4 GB memory means that Cloudbreak will request the Marathon API to schedule the Ambari container on a node where these resources can be satisfied.\n\n\nOn Mesos, Cloudbreak doesn't start a gateway instance.\n\n\nOn other cloud providers, Cloudbreak deploys a gateway VM for every new cluster. The gateway VM runs a few containers, such as Ambari server, and, most importantly, it runs an Nginx server. All communication between Cloudbreak Deployer and a cluster deployed by Cloudbreak hsppens through this Nginx instance. This is done through a two-way TLS channel where the Nginx server is responsible for the TLS termination. Communication inside the cluster (for example, between Ambari server and agents) is not encrypted, but all communication from outside is secure. This allows Cloudbreak to be deployed outside of the private network of the cluster. The Mesos integration doesn't have a solution like this, so all communication between Cloudbreak and the Mesos cluster happens through an unencrypted channel. For this reason, on Mesos, Cloudbreak should be deployed inside the same private network (or in the same Mesos cluster) where the clusters will be deployed.\n\n\nLimitations of the Technical Preview\n\n\nNo support for Consul or other custom DNS solution.\n\n\nUnlike on other cloud providers where Cloudbreak uses Consul, on Mesos, Cloudbreak does not provide a custom DNS solution. In this technical preview, containers are deployed with \nnet=host\n, so Mesos nodes must be set up manually in order to resolve hostnames to IP addresses and vice versa with reserve DNS. To manually resolve them, create the \n/etc/hosts\n file on each node in the cluster.\n\n\nFor example, consider this scenario:\n\n- There are five nodes in the Mesos cluster: \nnode1, node2, node3, node4 and node5\n with IP addresses ranging from \n10.0.0.1\n to \n10.0.0.5\n.\n- The \n/etc/hosts\n file on \nnode1\n should contain these entries that match IP addresses with hostnames:\n\n\n    10.0.0.2 node2\n    10.0.0.3 node3\n    10.0.0.4 node4\n    10.0.0.5 node5\n\n\n\n\nCloudbreak must be able to resolve the addresses of the Mesos slaves.\n\n\nTo make API requests (for example, to create a cluster), Cloudbreak must communicate with the Ambari server deployed in the Mesos cluster. After Cloudbreak instructs Marathon to deploy the Ambari server container somewhere in the Mesos cluster, it asks Marathon for the address of the node where the Ambari server was deployed and then tries to communicate with the Ambari server through that address. For example, consider the following scenario where Mesos cluster has 5 registered nodes: \nnode1, node2, node3, node4, node5\n:\n\n\n\n\nCloudbreak makes a \nPOST\n request to the Marathon API to deploy the Ambari server container somewhere with enough resources.\n\n\nMarathon starts an Ambari server container on \nnode4\n, then return the node address to Cloudbreak.\n\n\nCloudbreak tries to access \nnode4:8080\n to make sure that Ambari server is running.\n\n\n\n\nConsidering that there is no gateway node and so the communication between Cloudbreak and the clusters is unencrypted, we suggest that you deploy Cloudbreak in the same private network as the clusters. If Cloudbreak is not in the same network as the clusters, add the addresses with a reachable IP to the \n/etc/hosts\n file on the machine where Cloudbreak is deployed.\n\n\nStorage management needs to be improved\n\n\nThis is one of the two biggest limitations of the current Mesos integration. The current integration doesn't offer volume management, which means that data is stored inside Docker containers. This solution has a few problems that will be addressed in future releases:\n\n\n\n\nData can only be stored on the volumes where Docker is installed (typically the root volume), and not on attached volumes\n\n\nAfter the container is destroyed, the data is destroyed as well\n\n\nThere is no data locality\n\n\n\n\nIP-per-task is not supported yet\n\n\nThe second big limitation of the current Mesos integration is the lack of IP-per-task support. IP-per-task means that every task of an app (all the containers) deployed through Marathon will get their own network interface and an IP address. \nThis feature\n is already available in Marathon but does not work in combination with Docker containers. In our current Mesos integration, containers are deployed with \nnet=host\n, which means that to avoid port collisions only one container can be deployed per Mesos host; this is the case even with multiple clusters.\n\n\nRecipes are not supported\n\n\nRecipes (script extensions to an HDP cluster installation, supported by Cloudbreak) are not supported in the Mesos integration. Recipes are dependent on Consul's HTTP API, and the Mesos integration does not support Consul.\n\n\nCloudbreak Deployer\n\n\nBefore configuring Cloudbreak Deployer, you should know that:\n\n\n\n\nAll \ncbd\n actions must be executed from the \ncbd\n root folder.\n\n\nMost of the \ncbd\n commands require \nroot\n permissions, so you may want to apply \nsudo su\n.\n\n\n\n\nCloudbreak Deployer Installation\n\n\nInstall CLoudbreak Deployer\n\n\nFirst, \ninstall the Cloudbreak Deployer\n manually on a VM inside your Mesos cluster's private network.\n\n\nIf you have your own installed VM, check the \nInitialize your Profile\n section here before starting the provisioning.\n\n\nOpen the \ncloudbreak-deployment\n directory:\n\n\ncd cloudbreak-deployment\n\n\n\n\nThis directory contains configuration files and the supporting binaries for Cloudbreak Deployer.\n\n\nInitialize your Profile\n\n\nFirst, initialize deployer by creating a \nProfile\n file with the following content:\n\n\nexport UAA_DEFAULT_SECRET='[SECRET]'\nexport UAA_DEFAULT_USER_PW='[PASSWORD]'\nexport PUBLIC_IP='[PUBLIC_IP]'\n\n\n\n\nThe \nPUBLIC_IP\n is mandatory, because it is used to access the Cloudbreak UI.\n\n\nStart Cloudbreak Deployer\n\n\nTo start the Cloudbreak application use the following command:  \n\n\ncbd start\n\n\n\n\nThis will start all the Docker containers and initialize the application. \n\n\n\n\nThe first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.\n\n\n\n\nThe \ncbd start\n command includes the \ncbd generate\n command which applies the following steps:\n\n\n\n\ncreates the \ndocker-compose.yml\n file that describes the configuration of all the Docker containers needed for the Cloudbreak deployment.\n\n\ncreates the \nuaa.yml\n file that holds the configuration of the identity server used to authenticate users to Cloudbreak.\n\n\n\n\nValidate that Cloudbreak Deployer Has Started\n\n\nAfter the \ncbd start\n command finishes, check the following:\n\n\n\n\nPre-installed Cloudbreak Deployer version and health:\n\n\n\n\n   cbd doctor\n\n\n\n\n\n\nIf you need to run \ncbd update\n, refer to \nCloudbreak Deployer Update\n. Most of the \ncbd\n commands require \nroot\n permissions.\n\n\n\n\n\n\nLogs of the Cloudbreak Application:\n\n\n\n\n   cbd logs cloudbreak\n\n\n\n\n\n\nYou should see a mesage like this in the log: \nStarted CloudbreakApplication in 36.823 seconds\n. Cloudbreak normally takes less than a minute to start.\n\n\n\n\nProvisioning Prerequisites\n\n\nA working Mesos cluster with Marathon\n\n\nIt is not the scope of Cloudbreak to provision a new Mesos cluster so it needs an already working Mesos cluster where it will be able to start HDP clusters. It is also required to have Marathon installed because Cloudbreak uses its API to schedule Docker containers.\n\n\nHostnames must be resolvable inside the Mesos cluster and also by Cloudbreak\n\n\nCloudbreak does not deploy a custom DNS solution like on other cloud providers, where Consul is used to provide addresses for every node. Containers are deployed with \nnet=host\n and Mesos nodes must be set up manually in a way to be able to resolve each other's hostnames to IP addresses and vice versa with reserve DNS. This is a requirement of Hadoop and it is usually accomplished by setting up the \n/etc/hosts\n file on each node in the cluster, but it can also be provided by some DNS servers like Amazon's default DNS server in a virtual network.\n\n\nExample:\n\n\n\n\nIf you have 5 nodes in the Mesos cluster: \nnode1, node2, node3, node4 and node5\n with private IP addresses of \n10.0.0.1 to 10.0.0.5\n respectively, the \n/etc/hosts\n file on \nnode1\n should contain these entries:\n\n\n\n\n    10.0.0.2 node2\n    10.0.0.3 node3\n    10.0.0.4 node4\n    10.0.0.5 node5\n\n\n\n\nDocker must be installed on Mesos slave nodes and Docker containerizer must be enabled\n\n\nTo be able to use the Docker containerizer, Docker must be installed on all the Mesos slave nodes. To install Docker, follow the instructions in their documentation \nhere\n.\n\n\nAfter Docker is installed, it can be configured for the Mesos slave, by adding the \nDocker containerizer\n to each Mesos slave configuration. To configure it, add \ndocker,mesos\n to the file \n/etc/mesos-slave/containerizers\n on each of the slave nodes (or start mesos-slave with the \n--containerizers=mesos,docker\n flag, or set the environment variable MESOS_CONTAINERIZERS=\"mesos,docker\"). You may also want to increase the executor timeout to 10 mins by adding \n10mins\n to \n/etc/mesos-slave/executor_registration_timeout\n because it will allow time for pulling large Docker images.\n\n\nProvisioning via Browser\n\n\nYou can log into the Cloudbreak application at \nhttps://\nPUBLIC_IP\n.\n\n\nThe main goal of the Cloudbreak UI is to easily create clusters on your own cloud provider, or on your existing Mesos cluster.\nThis description details the Mesos setup - if you'd like to use a different cloud provider check out its manual.\n\n\nThis document explains the four steps that need to be followed to create Cloudbreak clusters from the UI:\n\n\n\n\nconnect your Marathon API with Cloudbreak\n\n\ncreate some resource constraints on the UI that describe the resources needed by your cluster\n\n\ncreate a blueprint that describes the HDP services in your clusters\n\n\nlaunch the cluster itself based on the resource constraints and the HDP blueprint\n\n\n\n\n\n\nIMPORTANT\n Make sure that you have sufficient quota (CPU, memory) in your Mesos cluster for the requested cluster size.\n\n\n\n\nSetting up Marathon credentials\n\n\nCloudbreak works by connecting your Marathon API through so called \nCredentials\n, and then uses the API to schedule containers on your Mesos cluster. The credentials can be configured on the \nmanage credentials\n panel on the Cloudbreak Dashboard.\n\n\nTo create a new Marathon credential follow these steps:\n\n\n\n\nFill out the new credential \nName\n\n\nOnly alphanumeric and lowercase characters (min 5, max 100 characters) can be applied\n\n\n\n\n\n\nAdd an optional description\n\n\nSpecify the endpoint of your Marathon API in this format: \nhttp://\nmarathon-address\n:\nport\n. Example: \nhttp://172.16.252.31:8080\n.\n\n\n\n\n\n\nPublic in account\n means that all the users belonging to your account will be able to use this credential to create \nclusters, but cannot delete it.\n\n\n\n\nAuthentication and HTTPS to a Marathon API is not yet supported by Cloudbreak\n\n\nResource constraints\n\n\nAfter your Marathon API is linked to Cloudbreak you can start creating resource constraint templates that describe the resources requested through the Marathon API when starting an Ambari container.\n\n\nWhen you create a resource constraint template, \nCloudbreak does not make any requests to Marathon. Resources are only requested after the \ncreate cluster\n button was pushed and Cloudbreak starts to orchestrate containers.\n These templates are saved to Cloudbreak's database and can be reused with multiple clusters to describe the same resource constraints.\n\n\nA typical setup is to combine multiple templates in a cluster for the different types of nodes. For example you may want to request more memory for Spark nodes.\n\n\nThe resource contraint templates can be configured on the \nmanage templates\n panel on the Cloudbreak Dashboard under the Mesos tab. You can specify the memory, CPU and disk needed by the nodes in a hostgroup. If \nPublic in account\n is checked all the users belonging to your account will be able to use this resource to create clusters, but cannot delete it.\n\n\nDefining Cluster Services\n\n\nBlueprints\n\n\nBlueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are \nused by Ambari\n.\n\n\nYou can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file, URL (an \nexample blueprint\n) or the \nwhole JSON can be written in the \nJSON text\n box.\n\n\nThe host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.\n\n\n\n\nNOTE:\n It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will \nfill that with a default value.\n\n\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to use this blueprint to \ncreate clusters, but cannot delete or modify it.\n\n\n\n\nFull size \nhere\n.\n\n\nA blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications.\n\nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations...etc. that won't be applicable to the Cloudbreak cluster\n\n\nCluster deployment\n\n\nAfter all the cluster resources are configured you can deploy a new HDP cluster.\n\n\nHere is a \nbasic flow for cluster creation on Cloudbreak's Web UI\n:\n\n\n\n\n\n\nStart by selecting a previously created Mesos credential in the header.\n\n\n\n\n\n\nClick on \ncreate cluster\n\n\n\n\n\n\nConfigure Cluster\n tab\n\n\n\n\nFill out the new cluster \nname\n\n\nCluster name must start with a lowercase alphabetic character then you can apply lowercase alphanumeric and \n   hyphens only (min 5, max 40 characters)\n\n\n\n\n\n\nClick on the \nChoose Blueprint\n button\n\n\nIf \nPublic in account\n is checked all the users belonging to your account will be able to see the created cluster on\n the UI, but cannot delete or modify it.\n\n\n\n\n\n\n\n\nChoose Blueprint\n tab\n\n\n\n\nSelect one of the blueprints\n\n\nAfter you've selected a \nBlueprint\n, you should be able to configure:\n\n\nthe resource constraints\n\n\nthe number of nodes for all of the host groups in the blueprint\n\n\n\n\n\n\nClick on the \nReview and Launch\n button\n\n\n\n\nReview and Launch\n tab\n\n\n\n\nAfter the \ncreate and start cluster\n button was clicked Cloudbreak will start to orchestrate the Ambari containers through your Marathon API.\n\n\n\n\nYou can check the progress on the Cloudbreak Web UI if you open the new cluster's \nEvent History\n. It is available if you click on the cluster's name.\n\n\nAdvanced options\n\n\nThere are some advanced features when deploying a new cluster, these are the following:\n\n\nValidate blueprint\n This is selected by default. Cloudbreak validates the Ambari blueprint in this case.\n\n\nCustom Image\n If you enable this, you can override the default image for provision.\n\n\nConfig recommendation strategy\n Strategy for how configuration recommendations will be applied. Recommended \nconfigurations gathered by the response of the stack advisor. \n\n\n\n\nNEVER_APPLY\n               Configuration recommendations are ignored with this option.\n\n\nONLY_STACK_DEFAULTS_APPLY\n Applies only on the default configurations for all included services.\n\n\nALWAYS_APPLY\n              Applies on all configuration properties.\n\n\n\n\nCluster termination\n\n\nYou can terminate running or stopped clusters with the \nterminate\n button in the cluster details.\n\n\n\n\nIMPORTANT\n Always use Cloudbreak to terminate the cluster instead of deleting the containers through the Marathon API. Deleting them first would cause inconsistencies between Cloudbreak's database and the real state and that could lead to errors", 
            "title": "Mesos (TP)"
        }, 
        {
            "location": "/mesos/#mesos-introduction", 
            "text": "Mesos support is part of  TECHNICAL PREVIEW . It may not be suitable for production use.   At a high level, Cloudbreak deployment on Mesos is similar to Cloudbreak implementations on other cloud providers: HDP clusters are provisioned through Ambari with the help of blueprints, and Ambari server and agents run in Docker containers. However, there are a few major differences that you should consider before you start working with Cloudbreak on Mesos.", 
            "title": "Mesos Introduction"
        }, 
        {
            "location": "/mesos/#differences-with-other-cloud-provider-implementations", 
            "text": "", 
            "title": "Differences with Other Cloud Provider Implementations"
        }, 
        {
            "location": "/mesos/#the-mesos-integration-doesnt-start-new-instances-and-doesnt-build-new-infrastructure-on-a-cloud-provider", 
            "text": "Cloudbreak expects a \"bring your own Mesos\" infrastructure, which means that you have to deploy Mesos first and then configure access to the existing Mesos deployment in Cloudbreak.   On other cloud providers, Cloudbreak first builds the infrastructure where Hadoop components are later deployed through Ambari. This involves creating or reusing the networking layer (virtual networks, subnets, and so on), provisioning new virtual machines in these networks from pre-existing cloud images, and starting docker containers on these VMs (nodes). However, the Mesos integration was designed  not  to include these steps, because in most cases users already have their own Mesos infrastructure on which they would like to deploy their cluster.", 
            "title": "The Mesos integration doesn't start new instances and doesn't build new infrastructure on a cloud provider."
        }, 
        {
            "location": "/mesos/#a-mesos-credential-in-the-cloudbreak-ui-provides-access-to-the-marathon-api", 
            "text": "Marathon is a standard application scheduling framework for services in Mesos. Cloudbreak uses Marathon API to communicate with Mesos, so you need to deploy Marathon on the Mesos cluster and, when setting up access to Mesos in Cloudbreak, specify a Marathon API endpoint. Basic authentication and TLS on the Marathon API are not supported in the technical preview.", 
            "title": "A Mesos credential in the Cloudbreak UI provides access to the Marathon API."
        }, 
        {
            "location": "/mesos/#a-mesos-template-in-the-cloudbreak-ui-means-resource-constraints-instead-of-new-resources", 
            "text": "Through the Cloudbreak UI, you can create Cloudbreak templates that define the virtual machines in a cluster's hostgroup that will be provisioned through the cloud provider API. You can create such templates for Mesos and you can link the VMs to a hostgroup, but for Mesos these templates mean resource constraints that will be demanded through the Marathon API, not resources that will created.   For example, consider these two scenarios: \n- An AWS template with an instance type of  m4.large  and 4 pieces of 50 GB attached magnetic volumes will create a VM with these specs when Cloudbreak is building the cluster infrastructure.\n- A Mesos template with 2 CPU cores and 4 GB memory means that Cloudbreak will request the Marathon API to schedule the Ambari container on a node where these resources can be satisfied.", 
            "title": "A Mesos template in the Cloudbreak UI means resource constraints instead of new resources."
        }, 
        {
            "location": "/mesos/#on-mesos-cloudbreak-doesnt-start-a-gateway-instance", 
            "text": "On other cloud providers, Cloudbreak deploys a gateway VM for every new cluster. The gateway VM runs a few containers, such as Ambari server, and, most importantly, it runs an Nginx server. All communication between Cloudbreak Deployer and a cluster deployed by Cloudbreak hsppens through this Nginx instance. This is done through a two-way TLS channel where the Nginx server is responsible for the TLS termination. Communication inside the cluster (for example, between Ambari server and agents) is not encrypted, but all communication from outside is secure. This allows Cloudbreak to be deployed outside of the private network of the cluster. The Mesos integration doesn't have a solution like this, so all communication between Cloudbreak and the Mesos cluster happens through an unencrypted channel. For this reason, on Mesos, Cloudbreak should be deployed inside the same private network (or in the same Mesos cluster) where the clusters will be deployed.", 
            "title": "On Mesos, Cloudbreak doesn't start a gateway instance."
        }, 
        {
            "location": "/mesos/#limitations-of-the-technical-preview", 
            "text": "", 
            "title": "Limitations of the Technical Preview"
        }, 
        {
            "location": "/mesos/#no-support-for-consul-or-other-custom-dns-solution", 
            "text": "Unlike on other cloud providers where Cloudbreak uses Consul, on Mesos, Cloudbreak does not provide a custom DNS solution. In this technical preview, containers are deployed with  net=host , so Mesos nodes must be set up manually in order to resolve hostnames to IP addresses and vice versa with reserve DNS. To manually resolve them, create the  /etc/hosts  file on each node in the cluster.  For example, consider this scenario: \n- There are five nodes in the Mesos cluster:  node1, node2, node3, node4 and node5  with IP addresses ranging from  10.0.0.1  to  10.0.0.5 .\n- The  /etc/hosts  file on  node1  should contain these entries that match IP addresses with hostnames:      10.0.0.2 node2\n    10.0.0.3 node3\n    10.0.0.4 node4\n    10.0.0.5 node5", 
            "title": "No support for Consul or other custom DNS solution."
        }, 
        {
            "location": "/mesos/#cloudbreak-must-be-able-to-resolve-the-addresses-of-the-mesos-slaves", 
            "text": "To make API requests (for example, to create a cluster), Cloudbreak must communicate with the Ambari server deployed in the Mesos cluster. After Cloudbreak instructs Marathon to deploy the Ambari server container somewhere in the Mesos cluster, it asks Marathon for the address of the node where the Ambari server was deployed and then tries to communicate with the Ambari server through that address. For example, consider the following scenario where Mesos cluster has 5 registered nodes:  node1, node2, node3, node4, node5 :   Cloudbreak makes a  POST  request to the Marathon API to deploy the Ambari server container somewhere with enough resources.  Marathon starts an Ambari server container on  node4 , then return the node address to Cloudbreak.  Cloudbreak tries to access  node4:8080  to make sure that Ambari server is running.   Considering that there is no gateway node and so the communication between Cloudbreak and the clusters is unencrypted, we suggest that you deploy Cloudbreak in the same private network as the clusters. If Cloudbreak is not in the same network as the clusters, add the addresses with a reachable IP to the  /etc/hosts  file on the machine where Cloudbreak is deployed.", 
            "title": "Cloudbreak must be able to resolve the addresses of the Mesos slaves."
        }, 
        {
            "location": "/mesos/#storage-management-needs-to-be-improved", 
            "text": "This is one of the two biggest limitations of the current Mesos integration. The current integration doesn't offer volume management, which means that data is stored inside Docker containers. This solution has a few problems that will be addressed in future releases:   Data can only be stored on the volumes where Docker is installed (typically the root volume), and not on attached volumes  After the container is destroyed, the data is destroyed as well  There is no data locality", 
            "title": "Storage management needs to be improved"
        }, 
        {
            "location": "/mesos/#ip-per-task-is-not-supported-yet", 
            "text": "The second big limitation of the current Mesos integration is the lack of IP-per-task support. IP-per-task means that every task of an app (all the containers) deployed through Marathon will get their own network interface and an IP address.  This feature  is already available in Marathon but does not work in combination with Docker containers. In our current Mesos integration, containers are deployed with  net=host , which means that to avoid port collisions only one container can be deployed per Mesos host; this is the case even with multiple clusters.", 
            "title": "IP-per-task is not supported yet"
        }, 
        {
            "location": "/mesos/#recipes-are-not-supported", 
            "text": "Recipes (script extensions to an HDP cluster installation, supported by Cloudbreak) are not supported in the Mesos integration. Recipes are dependent on Consul's HTTP API, and the Mesos integration does not support Consul.", 
            "title": "Recipes are not supported"
        }, 
        {
            "location": "/mesos/#cloudbreak-deployer", 
            "text": "Before configuring Cloudbreak Deployer, you should know that:   All  cbd  actions must be executed from the  cbd  root folder.  Most of the  cbd  commands require  root  permissions, so you may want to apply  sudo su .", 
            "title": "Cloudbreak Deployer"
        }, 
        {
            "location": "/mesos/#cloudbreak-deployer-installation", 
            "text": "", 
            "title": "Cloudbreak Deployer Installation"
        }, 
        {
            "location": "/mesos/#install-cloudbreak-deployer", 
            "text": "First,  install the Cloudbreak Deployer  manually on a VM inside your Mesos cluster's private network.  If you have your own installed VM, check the  Initialize your Profile  section here before starting the provisioning.  Open the  cloudbreak-deployment  directory:  cd cloudbreak-deployment  This directory contains configuration files and the supporting binaries for Cloudbreak Deployer.", 
            "title": "Install CLoudbreak Deployer"
        }, 
        {
            "location": "/mesos/#initialize-your-profile", 
            "text": "First, initialize deployer by creating a  Profile  file with the following content:  export UAA_DEFAULT_SECRET='[SECRET]'\nexport UAA_DEFAULT_USER_PW='[PASSWORD]'\nexport PUBLIC_IP='[PUBLIC_IP]'  The  PUBLIC_IP  is mandatory, because it is used to access the Cloudbreak UI.", 
            "title": "Initialize your Profile"
        }, 
        {
            "location": "/mesos/#start-cloudbreak-deployer", 
            "text": "To start the Cloudbreak application use the following command:    cbd start  This will start all the Docker containers and initialize the application.    The first time you start the Coudbreak app, the process will take longer than usual due to the download of all the necessary docker images.   The  cbd start  command includes the  cbd generate  command which applies the following steps:   creates the  docker-compose.yml  file that describes the configuration of all the Docker containers needed for the Cloudbreak deployment.  creates the  uaa.yml  file that holds the configuration of the identity server used to authenticate users to Cloudbreak.", 
            "title": "Start Cloudbreak Deployer"
        }, 
        {
            "location": "/mesos/#validate-that-cloudbreak-deployer-has-started", 
            "text": "After the  cbd start  command finishes, check the following:   Pre-installed Cloudbreak Deployer version and health:      cbd doctor   If you need to run  cbd update , refer to  Cloudbreak Deployer Update . Most of the  cbd  commands require  root  permissions.    Logs of the Cloudbreak Application:      cbd logs cloudbreak   You should see a mesage like this in the log:  Started CloudbreakApplication in 36.823 seconds . Cloudbreak normally takes less than a minute to start.", 
            "title": "Validate that Cloudbreak Deployer Has Started"
        }, 
        {
            "location": "/mesos/#provisioning-prerequisites", 
            "text": "", 
            "title": "Provisioning Prerequisites"
        }, 
        {
            "location": "/mesos/#a-working-mesos-cluster-with-marathon", 
            "text": "It is not the scope of Cloudbreak to provision a new Mesos cluster so it needs an already working Mesos cluster where it will be able to start HDP clusters. It is also required to have Marathon installed because Cloudbreak uses its API to schedule Docker containers.", 
            "title": "A working Mesos cluster with Marathon"
        }, 
        {
            "location": "/mesos/#hostnames-must-be-resolvable-inside-the-mesos-cluster-and-also-by-cloudbreak", 
            "text": "Cloudbreak does not deploy a custom DNS solution like on other cloud providers, where Consul is used to provide addresses for every node. Containers are deployed with  net=host  and Mesos nodes must be set up manually in a way to be able to resolve each other's hostnames to IP addresses and vice versa with reserve DNS. This is a requirement of Hadoop and it is usually accomplished by setting up the  /etc/hosts  file on each node in the cluster, but it can also be provided by some DNS servers like Amazon's default DNS server in a virtual network.  Example:   If you have 5 nodes in the Mesos cluster:  node1, node2, node3, node4 and node5  with private IP addresses of  10.0.0.1 to 10.0.0.5  respectively, the  /etc/hosts  file on  node1  should contain these entries:       10.0.0.2 node2\n    10.0.0.3 node3\n    10.0.0.4 node4\n    10.0.0.5 node5", 
            "title": "Hostnames must be resolvable inside the Mesos cluster and also by Cloudbreak"
        }, 
        {
            "location": "/mesos/#docker-must-be-installed-on-mesos-slave-nodes-and-docker-containerizer-must-be-enabled", 
            "text": "To be able to use the Docker containerizer, Docker must be installed on all the Mesos slave nodes. To install Docker, follow the instructions in their documentation  here .  After Docker is installed, it can be configured for the Mesos slave, by adding the  Docker containerizer  to each Mesos slave configuration. To configure it, add  docker,mesos  to the file  /etc/mesos-slave/containerizers  on each of the slave nodes (or start mesos-slave with the  --containerizers=mesos,docker  flag, or set the environment variable MESOS_CONTAINERIZERS=\"mesos,docker\"). You may also want to increase the executor timeout to 10 mins by adding  10mins  to  /etc/mesos-slave/executor_registration_timeout  because it will allow time for pulling large Docker images.", 
            "title": "Docker must be installed on Mesos slave nodes and Docker containerizer must be enabled"
        }, 
        {
            "location": "/mesos/#provisioning-via-browser", 
            "text": "You can log into the Cloudbreak application at  https:// PUBLIC_IP .  The main goal of the Cloudbreak UI is to easily create clusters on your own cloud provider, or on your existing Mesos cluster.\nThis description details the Mesos setup - if you'd like to use a different cloud provider check out its manual.  This document explains the four steps that need to be followed to create Cloudbreak clusters from the UI:   connect your Marathon API with Cloudbreak  create some resource constraints on the UI that describe the resources needed by your cluster  create a blueprint that describes the HDP services in your clusters  launch the cluster itself based on the resource constraints and the HDP blueprint    IMPORTANT  Make sure that you have sufficient quota (CPU, memory) in your Mesos cluster for the requested cluster size.", 
            "title": "Provisioning via Browser"
        }, 
        {
            "location": "/mesos/#setting-up-marathon-credentials", 
            "text": "Cloudbreak works by connecting your Marathon API through so called  Credentials , and then uses the API to schedule containers on your Mesos cluster. The credentials can be configured on the  manage credentials  panel on the Cloudbreak Dashboard.  To create a new Marathon credential follow these steps:   Fill out the new credential  Name  Only alphanumeric and lowercase characters (min 5, max 100 characters) can be applied    Add an optional description  Specify the endpoint of your Marathon API in this format:  http:// marathon-address : port . Example:  http://172.16.252.31:8080 .    Public in account  means that all the users belonging to your account will be able to use this credential to create \nclusters, but cannot delete it.   Authentication and HTTPS to a Marathon API is not yet supported by Cloudbreak", 
            "title": "Setting up Marathon credentials"
        }, 
        {
            "location": "/mesos/#resource-constraints", 
            "text": "After your Marathon API is linked to Cloudbreak you can start creating resource constraint templates that describe the resources requested through the Marathon API when starting an Ambari container.  When you create a resource constraint template,  Cloudbreak does not make any requests to Marathon. Resources are only requested after the  create cluster  button was pushed and Cloudbreak starts to orchestrate containers.  These templates are saved to Cloudbreak's database and can be reused with multiple clusters to describe the same resource constraints.  A typical setup is to combine multiple templates in a cluster for the different types of nodes. For example you may want to request more memory for Spark nodes.  The resource contraint templates can be configured on the  manage templates  panel on the Cloudbreak Dashboard under the Mesos tab. You can specify the memory, CPU and disk needed by the nodes in a hostgroup. If  Public in account  is checked all the users belonging to your account will be able to use this resource to create clusters, but cannot delete it.", 
            "title": "Resource constraints"
        }, 
        {
            "location": "/mesos/#defining-cluster-services", 
            "text": "", 
            "title": "Defining Cluster Services"
        }, 
        {
            "location": "/mesos/#blueprints", 
            "text": "Blueprints are your declarative definition of a Hadoop cluster. These are the same blueprints that are  used by Ambari .  You can use the 3 default blueprints pre-defined in Cloudbreak or you can create your own ones.\nBlueprints can be added from file, URL (an  example blueprint ) or the \nwhole JSON can be written in the  JSON text  box.  The host groups in the JSON will be mapped to a set of instances when starting the cluster. Besides this the services and\n components will also be installed on the corresponding nodes. Blueprints can be modified later from the Ambari UI.   NOTE:  It is not necessary to define all the configuration in the blueprint. If a configuration is missing, Ambari will \nfill that with a default value.   If  Public in account  is checked all the users belonging to your account will be able to use this blueprint to \ncreate clusters, but cannot delete or modify it.   Full size  here .  A blueprint can be exported from a running Ambari cluster that can be reused in Cloudbreak with slight \nmodifications. \nThere is no automatic way to modify an exported blueprint and make it instantly usable in Cloudbreak, the \nmodifications have to be done manually.\nWhen the blueprint is exported some configurations are hardcoded for example domain names, memory configurations...etc. that won't be applicable to the Cloudbreak cluster", 
            "title": "Blueprints"
        }, 
        {
            "location": "/mesos/#cluster-deployment", 
            "text": "After all the cluster resources are configured you can deploy a new HDP cluster.  Here is a  basic flow for cluster creation on Cloudbreak's Web UI :    Start by selecting a previously created Mesos credential in the header.    Click on  create cluster    Configure Cluster  tab   Fill out the new cluster  name  Cluster name must start with a lowercase alphabetic character then you can apply lowercase alphanumeric and \n   hyphens only (min 5, max 40 characters)    Click on the  Choose Blueprint  button  If  Public in account  is checked all the users belonging to your account will be able to see the created cluster on\n the UI, but cannot delete or modify it.     Choose Blueprint  tab   Select one of the blueprints  After you've selected a  Blueprint , you should be able to configure:  the resource constraints  the number of nodes for all of the host groups in the blueprint    Click on the  Review and Launch  button   Review and Launch  tab   After the  create and start cluster  button was clicked Cloudbreak will start to orchestrate the Ambari containers through your Marathon API.   You can check the progress on the Cloudbreak Web UI if you open the new cluster's  Event History . It is available if you click on the cluster's name.  Advanced options  There are some advanced features when deploying a new cluster, these are the following:  Validate blueprint  This is selected by default. Cloudbreak validates the Ambari blueprint in this case.  Custom Image  If you enable this, you can override the default image for provision.  Config recommendation strategy  Strategy for how configuration recommendations will be applied. Recommended \nconfigurations gathered by the response of the stack advisor.    NEVER_APPLY                Configuration recommendations are ignored with this option.  ONLY_STACK_DEFAULTS_APPLY  Applies only on the default configurations for all included services.  ALWAYS_APPLY               Applies on all configuration properties.", 
            "title": "Cluster deployment"
        }, 
        {
            "location": "/mesos/#cluster-termination", 
            "text": "You can terminate running or stopped clusters with the  terminate  button in the cluster details.   IMPORTANT  Always use Cloudbreak to terminate the cluster instead of deleting the containers through the Marathon API. Deleting them first would cause inconsistencies between Cloudbreak's database and the real state and that could lead to errors", 
            "title": "Cluster termination"
        }, 
        {
            "location": "/spi/", 
            "text": "Service Provider Interface (SPI)\n\n\nCloudbreak already supports multiple cloud platforms and provides an easy way to integrate a new provider trough \nCloudbreak's Service Provider Interface (SPI)\n, a plugin mechanism that enables seamless integration of any cloud provider. The SPI plugin mechanism has been used to integrate all currently supported providers with Cloudbreak. Consequently, if you use SPI to integrate a new provider, the integration will be seamless.\n\n\n\n\nThe \ncloud-aws\n module integrates Amazon Web Services\n\n\nThe \ncloud-gcp\n module integrates Google Cloud Platform\n\n\nThe \ncloud-arm\n module integrates Microsoft Azure\n\n\nThe \ncloud-openstack\n module integrates OpenStack\n\n\n\n\nThe SPI interface is event-based, it scales well, and is decoupled from Cloudbreak. The core of Cloudbreak uses \nEventBus\n to communicate with the providers, but the complexity of event handling is hidden from the provider implementation.\n\n\nResource Management\n\n\nCloud providers support two kinds of deployment and resource management methods:\n\n\n\n\nTemplate-based deployments\n\n\nIndividual resource-based deployments\n\n\n\n\nCloudbreak's SPI supports both of these methods. It provides a well-defined interfaces, abstract classes, and helper classes, scheduling and polling of resources to aid the integration and to avoid any boilerplate code in the module of cloud provider.\n\n\nTemplate Based Deployments\n\n\nProviders with template-based deployments like \nAWS CloudFormation\n, \nAzure ARM\n or \nOpenStack Heat\n have the ability to create and manage a collection of related cloud resources, provisioning and updating them in an orderly and predictable fashion. \n\n\nIn such scenario, Cloudbreak needs a reference to the template itself because every change in the infrastructure (for example, creating new instance or deleting one) is managed through this templating mechanism.\n\n\nIf a provider has templating support, then the provider's \ngradle\n module depends on the \ncloud-api\n module:\n\n\napply plugin: 'java'\n\nsourceCompatibility = 1.7\n\nrepositories {\n    mavenCentral()\n}\n\njar {\n    baseName = 'cloud-new-provider'\n}\n\ndependencies {\n\n    compile project(':cloud-api')\n\n}\n\n\n\n\nThe entry point for the provider is the  \nCloudConnector\n interface and every interface that needs to be implemented is reachable trough this interface.\n\n\nIndividual Resource Based Deployments\n\n\nThere are providers such as GCP that do not support suitable templating mechanism, and customisable providers such as OpenStack where the Heat Orchestration (templating) component is optional and individual resources need to be handled separately. \n\n\nIn such scenarios, resources such as networks, discs, and compute instances need to be created and managed with an ordered sequence of API calls, and Cloudbreak needs to provide a solution to manage the collection of related cloud resources as a whole.\n\n\nIf the provider has no templating support, then the provider's \ngradle\n module typically depends on the \ncloud-template\n module, which includes Cloudbreak defined abstract template. This template is a set of abstract and utility classes to support provisioning and updating related resources in an orderly and predictable manner trough ordered sequences of cloud API calls:\n\n\napply plugin: 'java'\n\nsourceCompatibility = 1.7\n\nrepositories {\n    mavenCentral()\n}\n\njar {\n    baseName = 'cloud-new-provider'\n}\n\ndependencies {\n\n    compile project(':cloud-template')\n\n}\n\n\n\n\nVariants\n\n\nOpenStack is highly modular. It allows you to install different components, for example for volume storage or networking (Nova networking, Neutron, etc.). Or, in some scenarios, some components such as Heat may not installed at all.\n\n\nCloudbreak's SPI interface reflects this flexibility using so called variants. This means that if some part of cloud provider (typically OpenStack) is using different component, you don't need re-implement the complete stack but just use a different variant and re-implement the part that is different.\n\n\nThe reference implementation for this feature can be found in  \ncloud-openstack\n module which support a HEAT and NATIVE variants. The HEAT variant utilizes the Heat templating to launch a stack, but the NATIVE variant starts the cluster by using a sequence of API calls without Heat to achieve the same result, although both of them are using the same authentication and credential management.\n\n\nDevelopment\n\n\nFor instructions to set up your development environment, see \nLocal Development Setup\n.", 
            "title": "SPI"
        }, 
        {
            "location": "/spi/#service-provider-interface-spi", 
            "text": "Cloudbreak already supports multiple cloud platforms and provides an easy way to integrate a new provider trough  Cloudbreak's Service Provider Interface (SPI) , a plugin mechanism that enables seamless integration of any cloud provider. The SPI plugin mechanism has been used to integrate all currently supported providers with Cloudbreak. Consequently, if you use SPI to integrate a new provider, the integration will be seamless.   The  cloud-aws  module integrates Amazon Web Services  The  cloud-gcp  module integrates Google Cloud Platform  The  cloud-arm  module integrates Microsoft Azure  The  cloud-openstack  module integrates OpenStack   The SPI interface is event-based, it scales well, and is decoupled from Cloudbreak. The core of Cloudbreak uses  EventBus  to communicate with the providers, but the complexity of event handling is hidden from the provider implementation.", 
            "title": "Service Provider Interface (SPI)"
        }, 
        {
            "location": "/spi/#resource-management", 
            "text": "Cloud providers support two kinds of deployment and resource management methods:   Template-based deployments  Individual resource-based deployments   Cloudbreak's SPI supports both of these methods. It provides a well-defined interfaces, abstract classes, and helper classes, scheduling and polling of resources to aid the integration and to avoid any boilerplate code in the module of cloud provider.", 
            "title": "Resource Management"
        }, 
        {
            "location": "/spi/#template-based-deployments", 
            "text": "Providers with template-based deployments like  AWS CloudFormation ,  Azure ARM  or  OpenStack Heat  have the ability to create and manage a collection of related cloud resources, provisioning and updating them in an orderly and predictable fashion.   In such scenario, Cloudbreak needs a reference to the template itself because every change in the infrastructure (for example, creating new instance or deleting one) is managed through this templating mechanism.  If a provider has templating support, then the provider's  gradle  module depends on the  cloud-api  module:  apply plugin: 'java'\n\nsourceCompatibility = 1.7\n\nrepositories {\n    mavenCentral()\n}\n\njar {\n    baseName = 'cloud-new-provider'\n}\n\ndependencies {\n\n    compile project(':cloud-api')\n\n}  The entry point for the provider is the   CloudConnector  interface and every interface that needs to be implemented is reachable trough this interface.", 
            "title": "Template Based Deployments"
        }, 
        {
            "location": "/spi/#individual-resource-based-deployments", 
            "text": "There are providers such as GCP that do not support suitable templating mechanism, and customisable providers such as OpenStack where the Heat Orchestration (templating) component is optional and individual resources need to be handled separately.   In such scenarios, resources such as networks, discs, and compute instances need to be created and managed with an ordered sequence of API calls, and Cloudbreak needs to provide a solution to manage the collection of related cloud resources as a whole.  If the provider has no templating support, then the provider's  gradle  module typically depends on the  cloud-template  module, which includes Cloudbreak defined abstract template. This template is a set of abstract and utility classes to support provisioning and updating related resources in an orderly and predictable manner trough ordered sequences of cloud API calls:  apply plugin: 'java'\n\nsourceCompatibility = 1.7\n\nrepositories {\n    mavenCentral()\n}\n\njar {\n    baseName = 'cloud-new-provider'\n}\n\ndependencies {\n\n    compile project(':cloud-template')\n\n}", 
            "title": "Individual Resource Based Deployments"
        }, 
        {
            "location": "/spi/#variants", 
            "text": "OpenStack is highly modular. It allows you to install different components, for example for volume storage or networking (Nova networking, Neutron, etc.). Or, in some scenarios, some components such as Heat may not installed at all.  Cloudbreak's SPI interface reflects this flexibility using so called variants. This means that if some part of cloud provider (typically OpenStack) is using different component, you don't need re-implement the complete stack but just use a different variant and re-implement the part that is different.  The reference implementation for this feature can be found in   cloud-openstack  module which support a HEAT and NATIVE variants. The HEAT variant utilizes the Heat templating to launch a stack, but the NATIVE variant starts the cluster by using a sequence of API calls without Heat to achieve the same result, although both of them are using the same authentication and credential management.", 
            "title": "Variants"
        }, 
        {
            "location": "/spi/#development", 
            "text": "For instructions to set up your development environment, see  Local Development Setup .", 
            "title": "Development"
        }, 
        {
            "location": "/operations/", 
            "text": "Basic Operations\n\n\nDebugging\n\n\nTo get more detailed commnad prompt output, set the \nDEBUG\n environment variable to non-zero:  \n\n\nDEBUG=1 cbd \nsome_command\n\n\n\n\n\nTroubleshooting\n\n\nThe \ndoctor\n command helps you diagnose problems with your environment, such as common problems with your docker or boot2docker configuration. You can also use it to check cbd versions.  \n\n\ncbd doctor\n\n\n\n\nAccessing Logs\n\n\n\n\nTo check the aggregated logs for all the Cloudbreak components, use:  \n\n\n\n\ncbd logs\n\n\n\n\nYou can also check the logs of an individual docker container. \n\n\n\n\nTo view only the logs of the Cloudbreak backend, use:\n\n\n\n\ncbd logs cloudbreak\n\n\n\n\n\n\nYou can check the individual logs of \nuluwatu\n, \nperiscope\n, and \nidentity\n. For example, to check the \nuluwatu\n logs, use:\n\n\n\n\ncbd logs uluwatu\n\n\n\n\nSSH to the Hosts\n\n\nTo connect to a running VM through SSH, you need to know its public IP address and private key. \n\n\nYou can find the IP addresses of all the running VMs in the Cloudbreak UI, on the \nCluster details\n page, in the \nNodes\n section. Only key-based authentication is supported. The private key that you need to use to access the VM is the counterpart of the public key that you specified when creating a cloud credential.\n\n\nCloudbreak creates a \ncloudbreak\n user which can be used to ssh into the box. This user has passwordless sudo rights.\n\n\nFor example:\n\n\nssh -i ~/.ssh/your-private-key.pem cloudbreak@\npublic-ip\n\n\n\n\n\nData Volumes\n\n\nThe disks that are attached to the instances are automatically mounted to \n/hadoopfs/fs1\n, \n/hadoopfs/fs2\n, ... , \n/hadoopfs/fsN\n respectively.\n\n\nAmbari Server Node\n\n\nThe instance that serves as an Ambari Server node performs a few special tasks:\n\n\n\n\nIt runs the Ambari Server and its database.\n\n\nIt runs an NGINX proxy that is used by the Cloudbreak API to securely communicate with the cluster.\n\n\nIf Kerberos is configured, it runs a Kerberos KDC container.\n\n\n\n\nAccessing Hadoop and Ambari Logs\n\n\nYou can access \nHadoop logs\n from the host and from the container in the \n/hadoopfs/fs1/logs\n directory.\n\n\nYou can access \nAmbari logs\n from the host instance in the \n`/hadoopfs/fs1/logs\n folder.\n\n\nProxy Settings\n\n\nFor the cbd\n\n\nTo configure proxy settings for Cloudbreak Deployer, add the following configs to your \nProfile\n:\n\n\nexport http_proxy=\nhttp://YOUR_PROXY_ADDRESS:YOUR_PROXY_PORT/\n\nexport https_proxy=\nhttp(s)://YOUR_PROXY_ADDRESS:YOUR_PROXY_PORT/\n\nexport CB_HTTP_PROXY=\nhttp://YOUR_PROXY_ADDRESS:YOUR_PROXY_PORT/\n\nexport CB_HTTPS_PROXY=\nhttp(s)://YOUR_PROXY_ADDRESS:YOUR_PROXY_PORT/\n\nexport CB_JAVA_OPTS=\n-Dhttp.proxyHost=YOUR_PROXY_ADDRESS -Dhttp.proxyPort=YOUR_PROXY_PORT -Dhttps.proxyHost=YOUR_PROXY_ADDRESS -Dhttps.proxyPort=YOUR_PROXY_PORT -Dhttp.nonProxyHosts=172.17.0.1|*.service.consul|*.node.dc1.consul\n\n\n\n\n\nFor Docker\n\n\nTo download newer Docker images from the official repository, you need to configure proxy settings for the Docker service. You can do this by configuring the 'HTTP_PROXY' variable in your environment. Next, restart the docker service.\n\n\n\n\nNOTE\n For more information, see \nDocker documentation\n\n\n\n\nFor Provisioned Clusters\n\n\nFor a cluster to be provisioned to a (virtual) network that is behind a proxy, the \nyum\n on the provisioned machines needs to be configured to use that proxy. This is important because the Ambari install needs access to public repositories. You can configure \nyum\n proxy settings by using the recipe functionality of Cloudbreak. Use the following \nbash\n script to create a 'pre' recipe that will run on all of the nodes before the Ambari install:\n\n\n#!/bin/bash\ncat \n /etc/yum.conf \nENDOF\n\nproxy=http://YOUR_PROXY_ADDRESS:YOUR_PROXY_PORT\n\nENDOF\n\n\n\n\nTesting Your Proxy Settings\n\n\nYou can use the following \nCURL\n command to test your proxy settings:\n\n\nhttps_proxy=\nYOUR_PROXY_ADDRESS:YOUR_PROXY_PORT\n curl -X GET -I --insecure https://cloudbreak-api.sequenceiq.com/info\n\n\n\n\nIts output should start with:\n\n\nHTTP/1.1 200 OK", 
            "title": "Basic Operations"
        }, 
        {
            "location": "/operations/#basic-operations", 
            "text": "", 
            "title": "Basic Operations"
        }, 
        {
            "location": "/operations/#debugging", 
            "text": "To get more detailed commnad prompt output, set the  DEBUG  environment variable to non-zero:    DEBUG=1 cbd  some_command", 
            "title": "Debugging"
        }, 
        {
            "location": "/operations/#troubleshooting", 
            "text": "The  doctor  command helps you diagnose problems with your environment, such as common problems with your docker or boot2docker configuration. You can also use it to check cbd versions.    cbd doctor", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/operations/#accessing-logs", 
            "text": "To check the aggregated logs for all the Cloudbreak components, use:     cbd logs  You can also check the logs of an individual docker container.    To view only the logs of the Cloudbreak backend, use:   cbd logs cloudbreak   You can check the individual logs of  uluwatu ,  periscope , and  identity . For example, to check the  uluwatu  logs, use:   cbd logs uluwatu", 
            "title": "Accessing Logs"
        }, 
        {
            "location": "/operations/#ssh-to-the-hosts", 
            "text": "To connect to a running VM through SSH, you need to know its public IP address and private key.   You can find the IP addresses of all the running VMs in the Cloudbreak UI, on the  Cluster details  page, in the  Nodes  section. Only key-based authentication is supported. The private key that you need to use to access the VM is the counterpart of the public key that you specified when creating a cloud credential.  Cloudbreak creates a  cloudbreak  user which can be used to ssh into the box. This user has passwordless sudo rights.  For example:  ssh -i ~/.ssh/your-private-key.pem cloudbreak@ public-ip", 
            "title": "SSH to the Hosts"
        }, 
        {
            "location": "/operations/#data-volumes", 
            "text": "The disks that are attached to the instances are automatically mounted to  /hadoopfs/fs1 ,  /hadoopfs/fs2 , ... ,  /hadoopfs/fsN  respectively.", 
            "title": "Data Volumes"
        }, 
        {
            "location": "/operations/#ambari-server-node", 
            "text": "The instance that serves as an Ambari Server node performs a few special tasks:   It runs the Ambari Server and its database.  It runs an NGINX proxy that is used by the Cloudbreak API to securely communicate with the cluster.  If Kerberos is configured, it runs a Kerberos KDC container.", 
            "title": "Ambari Server Node"
        }, 
        {
            "location": "/operations/#accessing-hadoop-and-ambari-logs", 
            "text": "You can access  Hadoop logs  from the host and from the container in the  /hadoopfs/fs1/logs  directory.  You can access  Ambari logs  from the host instance in the  `/hadoopfs/fs1/logs  folder.", 
            "title": "Accessing Hadoop and Ambari Logs"
        }, 
        {
            "location": "/operations/#proxy-settings", 
            "text": "", 
            "title": "Proxy Settings"
        }, 
        {
            "location": "/operations/#for-the-cbd", 
            "text": "To configure proxy settings for Cloudbreak Deployer, add the following configs to your  Profile :  export http_proxy= http://YOUR_PROXY_ADDRESS:YOUR_PROXY_PORT/ \nexport https_proxy= http(s)://YOUR_PROXY_ADDRESS:YOUR_PROXY_PORT/ \nexport CB_HTTP_PROXY= http://YOUR_PROXY_ADDRESS:YOUR_PROXY_PORT/ \nexport CB_HTTPS_PROXY= http(s)://YOUR_PROXY_ADDRESS:YOUR_PROXY_PORT/ \nexport CB_JAVA_OPTS= -Dhttp.proxyHost=YOUR_PROXY_ADDRESS -Dhttp.proxyPort=YOUR_PROXY_PORT -Dhttps.proxyHost=YOUR_PROXY_ADDRESS -Dhttps.proxyPort=YOUR_PROXY_PORT -Dhttp.nonProxyHosts=172.17.0.1|*.service.consul|*.node.dc1.consul", 
            "title": "For the cbd"
        }, 
        {
            "location": "/operations/#for-docker", 
            "text": "To download newer Docker images from the official repository, you need to configure proxy settings for the Docker service. You can do this by configuring the 'HTTP_PROXY' variable in your environment. Next, restart the docker service.   NOTE  For more information, see  Docker documentation", 
            "title": "For Docker"
        }, 
        {
            "location": "/operations/#for-provisioned-clusters", 
            "text": "For a cluster to be provisioned to a (virtual) network that is behind a proxy, the  yum  on the provisioned machines needs to be configured to use that proxy. This is important because the Ambari install needs access to public repositories. You can configure  yum  proxy settings by using the recipe functionality of Cloudbreak. Use the following  bash  script to create a 'pre' recipe that will run on all of the nodes before the Ambari install:  #!/bin/bash\ncat   /etc/yum.conf  ENDOF\n\nproxy=http://YOUR_PROXY_ADDRESS:YOUR_PROXY_PORT\n\nENDOF", 
            "title": "For Provisioned Clusters"
        }, 
        {
            "location": "/operations/#testing-your-proxy-settings", 
            "text": "You can use the following  CURL  command to test your proxy settings:  https_proxy= YOUR_PROXY_ADDRESS:YOUR_PROXY_PORT  curl -X GET -I --insecure https://cloudbreak-api.sequenceiq.com/info  Its output should start with:  HTTP/1.1 200 OK", 
            "title": "Testing Your Proxy Settings"
        }, 
        {
            "location": "/configuration/", 
            "text": "Advanced Configuration\n\n\nCloudbreak Deployer configuration is based on environment variables. Cloudbreak Deployer always opens a new bash subprocess \nwithout inheriting environment variables\n. Only the following environment variables \nare\n inherited:\n\n\n\n\nHOME\n\n\nDEBUG\n\n\nTRACE\n\n\nCBD_DEFAULT_PROFILE\n\n\nall \nDOCKER_XXX\n\n\n\n\nTo set environment variables relevant for Cloudbreak Deployer, add them to a file called \nProfile\n.\n\n\nTo see all available environment variables with their default values, run:\n\n\ncbd env show\n\n\n\n\nThe \nProfile\n file is \nsourced\n, so you can use the usual syntax to set configuration values:\n\n\nexport MY_VAR=some_value\nexport OTHER_VAR=another_value\n\n\n\n\nEnvironment Specific Profiles\n\n\nLet\u2019s say that you want to use a different version of Cloudbreak for \nprod\n and \nqa\n profile. Since the \nProfile\n file is sourced, you will have to create two environment specific configurations that can be sourced:\n\n- \nProfile.prod\n\n- \nProfile.qa\n\n\nFor example, to create and use a \nprod\n profile, you need to:\n\n\n\n\nCreate a file called \nProfile.prod\n\n\nWrite the environment-specific \nexport DOCKER_TAG_CLOUDBREAK=0.3.99\n into \nProfile.prod\n to specify Docker image.\n\n\nSet the environment variable: \nCBD_DEFAULT_PROFILE=prod\n\n\n\n\nTo use the \nprod\n specific profile once, set:\n\n\nCBD_DEFAULT_PROFILE=prod cbd some_commands\n\n\n\n\nTo permanently use the  \nprod\n profile, set \nexport CBD_DEFAULT_PROFILE=prod\n in your \n.bash_profile\n.\n\n\nAvailable Configurations\n\n\nUsing Your Own SSL Certificate\n\n\nBy default Cloudbreak is available only via HTTPS and it generates its own self-signed certificate. For most use cases such as testing or staging instances this is secure enough. However, if you want to use your own trusted certificate, you must manually configure it on the Cloudbreak host by replacing the existing certificate with your own certificate.\n\n\nPrerequisites\n\n\n\n\nResolvable domain name for the Cloudbreak hosts' IP addresses\n\n\nGenerated valid certificate for the domain\n\n\n\n\nSteps\n\n\n\n\nFirst copy your private key and certificate to the host\n\n\nLog in to the host machine via ssh, usually \nssh cloudbreak@[IP-ADDRESS]\n\n\nMake sure the domain name is resolvable for the host: \nhost [HOST-NAME]\n\n\nChange the host name of the machine using steps specific for your operating system\n\n\nIdentify your Cloudbreak location, which usually is \n/var/lib/cloudbreak-deployer\n and navigate there\n\n\nEdit your \nProfile\n by adding or replacing \nPUBLIC_IP\n with \nexport PUBLIC_IP=[HOST-NAME]\n where \n[HOST-NAME]\n is your actual Cloudbreak host\n\n\nConfigure TLS details in your \nProfile\n by adding the following line \nexport CBD_TRAEFIK_TLS=\"[CERT-LOCATION],[PRIV-KEY-LOCATION]\"\n\n\nRestart Cloudbreak using the \ncbd restart\n command\n\n\n\n\nSMTP\n\n\nIf you want to change SMTP parameters, add them your \nProfile\n.  \n\n\nThe default values of the SMTP parameters are:\n\n\nexport CLOUDBREAK_SMTP_SENDER_USERNAME=\nexport CLOUDBREAK_SMTP_SENDER_PASSWORD=\nexport CLOUDBREAK_SMTP_SENDER_HOST=\nexport CLOUDBREAK_SMTP_SENDER_PORT=25\nexport CLOUDBREAK_SMTP_SENDER_FROM=\nexport CLOUDBREAK_SMTP_AUTH=true\nexport CLOUDBREAK_SMTP_STARTTLS_ENABLE=true\nexport CLOUDBREAK_SMTP_TYPE=smtp\n\n\n\n\nSMTPS\n\n\nIf your SMTP server uses SMTPS, you must set the protocol in your \nProfile\n to \nsmtps\n:\n\n\nexport CLOUDBREAK_SMTP_TYPE=smtps\n\n\n\n\nCertificates\n\n\nTrusted Certificates\n\n\nIf the certificate used by the SMTP server is self-signed or the Java's default trust store doesn't contain it, you can add it to the trust store by copying it to \ncerts/trusted\n inside the Cloudbreak Deployer directory, and start (or restart) the Cloudbreak container (with \ncbd start\n). On startup, the Cloudbreak container  automatically imports the certificates in that directory to its trust store.\n\n\nCloudbreak Certificate\n\n\nIf you would like to replace Cloudbreak's self-signed certificate with your own certificate then copy your certificate and the related private key under cloudbreak-deployment directory:\n\n\ncerts/traefik/mydomain.com.crt\ncerts/traefik/mydomain.com.key\n\n\n\n\nIf the traefik directory does not exsist then create it. After you have coped the cert and private key file, then add the following variable into the Profile file of cbd and restart cbd.\n\n\nexport CBD_TRAEFIK_TLS=\n/certs/traefik/mydomain.com.crt,/certs/traefik/mydomain.com.key\n\n\n\n\n\nAs a best practice we recommend to replace \nmydomain.com\n with the actual domain what you want to use, but make sure that the actual file names and the values in \nCBD_TRAEFIK_TLS\n are identical.  \n\n\nNote: password protected private key files can't be used by Cloudbreak\n  \n\n\nAccess from Custom Domains\n\n\nCloudbreak Deployer supports multitenancy and uses UAA as an identity provider. In UAA, multitenancy is managed through identity zones. An identity zone is accessed through a unique subdomain. For example, if the standard UAA responds to \nhttps://uaa.10.244.0.34.xip.io\n, a zone on this UAA can be accessed through a unique subdomain \nhttps://testzone1.uaa.10.244.0.34.xip.io\n.\n\n\nIf you want to use a custom domain for your identity or deployment, add the \nUAA_ZONE_DOMAIN\n line to your \nProfile\n:\n\n\nexport UAA_ZONE_DOMAIN=my-subdomain.example.com\n\n\n\n\nFor example, in our hosted deployment, the \nidentity.sequenceiq.com\n domain refers to our identity server; therefore, the \nUAA_ZONE_DOMAIN\n variable has to be set to that domain. This variable is necessary for UAA to identify which zone provider should handle the requests that arrive to that domain.\n\n\nConsul\n\n\nCloudbreak uses \nConsul\n for DNS resolution. All Cloudbreak-related services are registered as \nsomeservice.service.consul\n.\n\n\nConsul\u2019s built-in DNS server is able to fall back on another DNS server.\nThis option is called \n-recursor\n. Clodbreak Deployer first tries to discover the DNS settings of the host by looking for \nnameserver\n entry in the \n/etc/resolv.conf\n file. If it finds one, consul will use it as a recursor. Otherwise, it will use \n8.8.8.8\n .\n\n\nFor a full list of available consul config options, see Consul \ndocumentation\n.\n\n\nTo pass any additional Consul configuration, define a \nDOCKER_CONSUL_OPTIONS\n in the \nProfile\n file.\n\n\nSSH Fingerprint Verification\n\n\nCloudbreak is able to verify the SSH fingerprints of the provisioned virtual machines. We disable this feature by default for AWS and GCP, because we have experienced issues caused by the fact that Ccoud providers do not always print the SSH fingerprint into the provisioned machines console output. The fingerprint validation feature can be turned on by configuring the \nCB_AWS_HOSTKEY_VERIFY\n and/or the \nCB_GCP_HOSTKEY_VERIFY\n variables in your \nProfile\n. For example:\n\n\nexport CB_AWS_HOSTKEY_VERIFY=true\nexport CB_GCP_HOSTKEY_VERIFY=true\n\n\n\n\nProvider Specific Configurations\n\n\nAzure Resource Manager Command\n\n\n\n\ncbd azure configure-arm\n\n\n\n\nFor more information, see Azure \ndocumentation\n.", 
            "title": "Advanced Configuration"
        }, 
        {
            "location": "/configuration/#advanced-configuration", 
            "text": "Cloudbreak Deployer configuration is based on environment variables. Cloudbreak Deployer always opens a new bash subprocess  without inheriting environment variables . Only the following environment variables  are  inherited:   HOME  DEBUG  TRACE  CBD_DEFAULT_PROFILE  all  DOCKER_XXX   To set environment variables relevant for Cloudbreak Deployer, add them to a file called  Profile .  To see all available environment variables with their default values, run:  cbd env show  The  Profile  file is  sourced , so you can use the usual syntax to set configuration values:  export MY_VAR=some_value\nexport OTHER_VAR=another_value", 
            "title": "Advanced Configuration"
        }, 
        {
            "location": "/configuration/#environment-specific-profiles", 
            "text": "Let\u2019s say that you want to use a different version of Cloudbreak for  prod  and  qa  profile. Since the  Profile  file is sourced, you will have to create two environment specific configurations that can be sourced: \n-  Profile.prod \n-  Profile.qa  For example, to create and use a  prod  profile, you need to:   Create a file called  Profile.prod  Write the environment-specific  export DOCKER_TAG_CLOUDBREAK=0.3.99  into  Profile.prod  to specify Docker image.  Set the environment variable:  CBD_DEFAULT_PROFILE=prod   To use the  prod  specific profile once, set:  CBD_DEFAULT_PROFILE=prod cbd some_commands  To permanently use the   prod  profile, set  export CBD_DEFAULT_PROFILE=prod  in your  .bash_profile .", 
            "title": "Environment Specific Profiles"
        }, 
        {
            "location": "/configuration/#available-configurations", 
            "text": "", 
            "title": "Available Configurations"
        }, 
        {
            "location": "/configuration/#using-your-own-ssl-certificate", 
            "text": "By default Cloudbreak is available only via HTTPS and it generates its own self-signed certificate. For most use cases such as testing or staging instances this is secure enough. However, if you want to use your own trusted certificate, you must manually configure it on the Cloudbreak host by replacing the existing certificate with your own certificate.", 
            "title": "Using Your Own SSL Certificate"
        }, 
        {
            "location": "/configuration/#prerequisites", 
            "text": "Resolvable domain name for the Cloudbreak hosts' IP addresses  Generated valid certificate for the domain", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/configuration/#steps", 
            "text": "First copy your private key and certificate to the host  Log in to the host machine via ssh, usually  ssh cloudbreak@[IP-ADDRESS]  Make sure the domain name is resolvable for the host:  host [HOST-NAME]  Change the host name of the machine using steps specific for your operating system  Identify your Cloudbreak location, which usually is  /var/lib/cloudbreak-deployer  and navigate there  Edit your  Profile  by adding or replacing  PUBLIC_IP  with  export PUBLIC_IP=[HOST-NAME]  where  [HOST-NAME]  is your actual Cloudbreak host  Configure TLS details in your  Profile  by adding the following line  export CBD_TRAEFIK_TLS=\"[CERT-LOCATION],[PRIV-KEY-LOCATION]\"  Restart Cloudbreak using the  cbd restart  command", 
            "title": "Steps"
        }, 
        {
            "location": "/configuration/#smtp", 
            "text": "If you want to change SMTP parameters, add them your  Profile .    The default values of the SMTP parameters are:  export CLOUDBREAK_SMTP_SENDER_USERNAME=\nexport CLOUDBREAK_SMTP_SENDER_PASSWORD=\nexport CLOUDBREAK_SMTP_SENDER_HOST=\nexport CLOUDBREAK_SMTP_SENDER_PORT=25\nexport CLOUDBREAK_SMTP_SENDER_FROM=\nexport CLOUDBREAK_SMTP_AUTH=true\nexport CLOUDBREAK_SMTP_STARTTLS_ENABLE=true\nexport CLOUDBREAK_SMTP_TYPE=smtp", 
            "title": "SMTP"
        }, 
        {
            "location": "/configuration/#smtps", 
            "text": "If your SMTP server uses SMTPS, you must set the protocol in your  Profile  to  smtps :  export CLOUDBREAK_SMTP_TYPE=smtps", 
            "title": "SMTPS"
        }, 
        {
            "location": "/configuration/#certificates", 
            "text": "", 
            "title": "Certificates"
        }, 
        {
            "location": "/configuration/#trusted-certificates", 
            "text": "If the certificate used by the SMTP server is self-signed or the Java's default trust store doesn't contain it, you can add it to the trust store by copying it to  certs/trusted  inside the Cloudbreak Deployer directory, and start (or restart) the Cloudbreak container (with  cbd start ). On startup, the Cloudbreak container  automatically imports the certificates in that directory to its trust store.", 
            "title": "Trusted Certificates"
        }, 
        {
            "location": "/configuration/#cloudbreak-certificate", 
            "text": "If you would like to replace Cloudbreak's self-signed certificate with your own certificate then copy your certificate and the related private key under cloudbreak-deployment directory:  certs/traefik/mydomain.com.crt\ncerts/traefik/mydomain.com.key  If the traefik directory does not exsist then create it. After you have coped the cert and private key file, then add the following variable into the Profile file of cbd and restart cbd.  export CBD_TRAEFIK_TLS= /certs/traefik/mydomain.com.crt,/certs/traefik/mydomain.com.key   As a best practice we recommend to replace  mydomain.com  with the actual domain what you want to use, but make sure that the actual file names and the values in  CBD_TRAEFIK_TLS  are identical.    Note: password protected private key files can't be used by Cloudbreak", 
            "title": "Cloudbreak Certificate"
        }, 
        {
            "location": "/configuration/#access-from-custom-domains", 
            "text": "Cloudbreak Deployer supports multitenancy and uses UAA as an identity provider. In UAA, multitenancy is managed through identity zones. An identity zone is accessed through a unique subdomain. For example, if the standard UAA responds to  https://uaa.10.244.0.34.xip.io , a zone on this UAA can be accessed through a unique subdomain  https://testzone1.uaa.10.244.0.34.xip.io .  If you want to use a custom domain for your identity or deployment, add the  UAA_ZONE_DOMAIN  line to your  Profile :  export UAA_ZONE_DOMAIN=my-subdomain.example.com  For example, in our hosted deployment, the  identity.sequenceiq.com  domain refers to our identity server; therefore, the  UAA_ZONE_DOMAIN  variable has to be set to that domain. This variable is necessary for UAA to identify which zone provider should handle the requests that arrive to that domain.", 
            "title": "Access from Custom Domains"
        }, 
        {
            "location": "/configuration/#consul", 
            "text": "Cloudbreak uses  Consul  for DNS resolution. All Cloudbreak-related services are registered as  someservice.service.consul .  Consul\u2019s built-in DNS server is able to fall back on another DNS server.\nThis option is called  -recursor . Clodbreak Deployer first tries to discover the DNS settings of the host by looking for  nameserver  entry in the  /etc/resolv.conf  file. If it finds one, consul will use it as a recursor. Otherwise, it will use  8.8.8.8  .  For a full list of available consul config options, see Consul  documentation .  To pass any additional Consul configuration, define a  DOCKER_CONSUL_OPTIONS  in the  Profile  file.", 
            "title": "Consul"
        }, 
        {
            "location": "/configuration/#ssh-fingerprint-verification", 
            "text": "Cloudbreak is able to verify the SSH fingerprints of the provisioned virtual machines. We disable this feature by default for AWS and GCP, because we have experienced issues caused by the fact that Ccoud providers do not always print the SSH fingerprint into the provisioned machines console output. The fingerprint validation feature can be turned on by configuring the  CB_AWS_HOSTKEY_VERIFY  and/or the  CB_GCP_HOSTKEY_VERIFY  variables in your  Profile . For example:  export CB_AWS_HOSTKEY_VERIFY=true\nexport CB_GCP_HOSTKEY_VERIFY=true", 
            "title": "SSH Fingerprint Verification"
        }, 
        {
            "location": "/configuration/#provider-specific-configurations", 
            "text": "", 
            "title": "Provider Specific Configurations"
        }, 
        {
            "location": "/configuration/#azure-resource-manager-command", 
            "text": "cbd azure configure-arm   For more information, see Azure  documentation .", 
            "title": "Azure Resource Manager Command"
        }, 
        {
            "location": "/cloudbreak_database/", 
            "text": "Cloudbreak Database\n\n\nBy default, Cloudbreak uses a built-in PostgreSQL database to persist data. \n\n\n\n\nFor production environments, we suggest that you use an external database, an RDS served by your cloud provider.\n\n\n\n\nIf you choose to use the default database, you should know that Cloudbreak deployer includes features for dumping and restoring built-in databases.\n\n\nDump and Restore Database\n\n\nCloudbreak deployer uses Docker for the underlying infrastructure and uses Docker volume for storing data. There are two separate volumes: \n\n\n\n\na volume called \ncommon\n for storing live data  \n\n\na volume called \ncbreak_dump\n for database dumps \n\n\n\n\nYou can override default live data volume any time by extending your \nProfile\n with the following variable:\n\n\nexport COMMON_DB_VOL=\nmy-live-data-volume\n\n\n\n\n\nTo create database dumps, execute the following commands:\n\n\ncbd db dump common cbdb\ncbd db dump common uaadb\ncbd db dump common periscopedb\n\n\n\n\nThe dump command has an optional third parameter, the \nname\n of the dump. If you give your dump a name, Cloudbreak deployer will create a symbolic link which points to the SQL dump. For example: \n\n\ncbd db dump common cbdb name-of-the-dump\n\n\n\n\nTo list existing dumps, execute the \ncbd db list-dumps\n command.\n\n\nEach kind of database dump (cbdb, uaadb, periscopedb) has a link to the latest dump on the \ncbreak_dump\n volume. During the restore process, Cloudbreak deployer restores from latest dump. \n\n\nTo check which dump is the latest, execute:\n\n\ndocker run --rm -v cbreak_dump:/dump -it alpine ls -lsa /dump/cbdb/latest\n\n\n\n\nYou can set any of the existing dumps as latest with \nset-dump\n command. You can set both regular or named dumps. For example: \n\n\ncbd db set-dump cbdb 20170628_1805\n\n\n\n\nor\n\n\ncbd db set-dump cbdb name-of-the-dump\n\n\n\n\nTo remove the existing \ncommon\n volume, stop all the related Cloudbreak containers with \ncbd kill\n command, and then remove the volume:\n\n\ndocker volume rm common\n\n\n\n\nTo restore databases from dumps, execute:\n\n\ncbd db restore-volume-from-dump common cbdb\ncbd db restore-volume-from-dump common uaadb\ncbd db restore-volume-from-dump common periscopedb\n\n\n\n\nYou can easily save your dumps to the host machine by using the following commands:\n\n\ndocker run --rm -v cbreak_dump:/dump -it alpine cat /dump/cbdb/latest/dump.sql \n cbdb.sql\ndocker run --rm -v cbreak_dump:/dump -it alpine cat /dump/uaadb/latest/dump.sql \n uaadb.sql\ndocker run --rm -v cbreak_dump:/dump -it alpine cat /dump/periscopedb/latest/dump.sql \n periscopedb.sql", 
            "title": "Cloudbreak Database"
        }, 
        {
            "location": "/cloudbreak_database/#cloudbreak-database", 
            "text": "By default, Cloudbreak uses a built-in PostgreSQL database to persist data.    For production environments, we suggest that you use an external database, an RDS served by your cloud provider.   If you choose to use the default database, you should know that Cloudbreak deployer includes features for dumping and restoring built-in databases.", 
            "title": "Cloudbreak Database"
        }, 
        {
            "location": "/cloudbreak_database/#dump-and-restore-database", 
            "text": "Cloudbreak deployer uses Docker for the underlying infrastructure and uses Docker volume for storing data. There are two separate volumes:    a volume called  common  for storing live data    a volume called  cbreak_dump  for database dumps    You can override default live data volume any time by extending your  Profile  with the following variable:  export COMMON_DB_VOL= my-live-data-volume   To create database dumps, execute the following commands:  cbd db dump common cbdb\ncbd db dump common uaadb\ncbd db dump common periscopedb  The dump command has an optional third parameter, the  name  of the dump. If you give your dump a name, Cloudbreak deployer will create a symbolic link which points to the SQL dump. For example:   cbd db dump common cbdb name-of-the-dump  To list existing dumps, execute the  cbd db list-dumps  command.  Each kind of database dump (cbdb, uaadb, periscopedb) has a link to the latest dump on the  cbreak_dump  volume. During the restore process, Cloudbreak deployer restores from latest dump.   To check which dump is the latest, execute:  docker run --rm -v cbreak_dump:/dump -it alpine ls -lsa /dump/cbdb/latest  You can set any of the existing dumps as latest with  set-dump  command. You can set both regular or named dumps. For example:   cbd db set-dump cbdb 20170628_1805  or  cbd db set-dump cbdb name-of-the-dump  To remove the existing  common  volume, stop all the related Cloudbreak containers with  cbd kill  command, and then remove the volume:  docker volume rm common  To restore databases from dumps, execute:  cbd db restore-volume-from-dump common cbdb\ncbd db restore-volume-from-dump common uaadb\ncbd db restore-volume-from-dump common periscopedb  You can easily save your dumps to the host machine by using the following commands:  docker run --rm -v cbreak_dump:/dump -it alpine cat /dump/cbdb/latest/dump.sql   cbdb.sql\ndocker run --rm -v cbreak_dump:/dump -it alpine cat /dump/uaadb/latest/dump.sql   uaadb.sql\ndocker run --rm -v cbreak_dump:/dump -it alpine cat /dump/periscopedb/latest/dump.sql   periscopedb.sql", 
            "title": "Dump and Restore Database"
        }, 
        {
            "location": "/ambari_database/", 
            "text": "Ambari Database\n\n\n\n\nAmbari Database support is part of \nTECHNICAL PREVIEW\n. It may not be suitable for production use.\n\n\n\n\nBy default, Ambari uses an embedded database to store data. However, Ambari and Cloudbreak don't perform backups of this database, so although this database is sufficient for ephemeral or test clusters, it is not be sufficient for long-running production clusters. Therefore, you may need to configure a remote database for Ambari in Cloudbreak.  \n\n\nYou have two options for configuring a remote database: you can set up a supported database on your own or use a cloud provider's database service. Next, you need to pass the details to Cloudbreak during cluster creation, and Cloudbreak will configure Ambari to connect to that remote database. \n\n\nCloudbreak supports out of the box PostgreSQL, MariaDB and MySQL. This means that if you are using any of these databases, you only need to create the database itself and configure user permissions to create the cluster. Cloudbreak will initialize database tables, relations, default values, and will download JDBC driver for Ambari. For other databases, you have to execute create SQL on your database and deliver JDBC driver to \n/opt/jdbc-drivers\n directory on Ambari server node.\n\n\nImportant Considerations\n\n\nConsider these constraints when setting up your remote datatabse:   \n\n\n\n\nCloudbreak doesn't validate the database connection, so wrong connection parameters will cause the cluster installation to fail.\n\n\nYour database must be available to the Ambari server. Note that:\n\n\nThe database must be located in the same region as the Ambari cluster. Slow database connection will cause cluster installation fail.\n\n\nThe database could be on a public server with firewall protection, but for security reasons we suggest that you use a private virtual network with subnet, and configure the Cloudbreak network to use existing resources.\n\n\n\n\n\n\nFor the supported out of the box databases, Cloudbreak creates the tables and upgrades Ambari if neccessary, but performing any other operations on the database is your responsibility.\n\n\nIf you selected PostgreSQL, Ambari must use the \npublic\n schema. It is not possible to configure a different schema.\n\n\nDatabase name, username, and password should not contain the \n'\n character. Other special characters are allowed.\n\n\n\n\nConfigure Database with the Web UI\n\n\nYou can find database configuration in the \nConfigure Ambari Database\n tab, under \nAdvanced options\n:\n\n\n\n\nFull size \nhere\n.\n\n\nConfigure Database with the Shell\n\n\nTo configure a remote database for Ambari with Cloudbreak shell, use \ndatabase configure\n command before \ncluster create\n command. The syntax is:\n\n\ndatabase configure --vendor [vendor] --host [host-or-ip] --port [port] --name [database-name] --username [user-name] --password [password]\n\n\n\n\nAccepted \nvendor\n values are:\n\n\n\n\nMARIADB\n\n\nMSSQL\n\n\nMYSQL\n\n\nORACLE\n\n\nPOSTGRES\n\n\nSQLANYWHERE\n\n\n\n\nUpgrade the JDBC Driver\n\n\nDuring installation, Cloudbreak distributes the JDBC driver for Ambari to different locations. If you want to upgrade the driver or use a different one, you have to perform these steps:\n\n\n\n\nCopy the driver to the \n/var/lib/ambari-server/jdbc-drivers\n directory.\n\n\nSymlink the driver to \n/usr/share/java\n, \n/usr/lib/jvm/java/jre/lib/ext\n directories.\n\n\nReconfigure Ambari by executing the \nambari-server setup --jdbc-db=[db-vendor] --jdbc-driver=[driver-location]\n command.", 
            "title": "Ambari Database (TP)"
        }, 
        {
            "location": "/ambari_database/#ambari-database", 
            "text": "Ambari Database support is part of  TECHNICAL PREVIEW . It may not be suitable for production use.   By default, Ambari uses an embedded database to store data. However, Ambari and Cloudbreak don't perform backups of this database, so although this database is sufficient for ephemeral or test clusters, it is not be sufficient for long-running production clusters. Therefore, you may need to configure a remote database for Ambari in Cloudbreak.    You have two options for configuring a remote database: you can set up a supported database on your own or use a cloud provider's database service. Next, you need to pass the details to Cloudbreak during cluster creation, and Cloudbreak will configure Ambari to connect to that remote database.   Cloudbreak supports out of the box PostgreSQL, MariaDB and MySQL. This means that if you are using any of these databases, you only need to create the database itself and configure user permissions to create the cluster. Cloudbreak will initialize database tables, relations, default values, and will download JDBC driver for Ambari. For other databases, you have to execute create SQL on your database and deliver JDBC driver to  /opt/jdbc-drivers  directory on Ambari server node.", 
            "title": "Ambari Database"
        }, 
        {
            "location": "/ambari_database/#important-considerations", 
            "text": "Consider these constraints when setting up your remote datatabse:      Cloudbreak doesn't validate the database connection, so wrong connection parameters will cause the cluster installation to fail.  Your database must be available to the Ambari server. Note that:  The database must be located in the same region as the Ambari cluster. Slow database connection will cause cluster installation fail.  The database could be on a public server with firewall protection, but for security reasons we suggest that you use a private virtual network with subnet, and configure the Cloudbreak network to use existing resources.    For the supported out of the box databases, Cloudbreak creates the tables and upgrades Ambari if neccessary, but performing any other operations on the database is your responsibility.  If you selected PostgreSQL, Ambari must use the  public  schema. It is not possible to configure a different schema.  Database name, username, and password should not contain the  '  character. Other special characters are allowed.", 
            "title": "Important Considerations"
        }, 
        {
            "location": "/ambari_database/#configure-database-with-the-web-ui", 
            "text": "You can find database configuration in the  Configure Ambari Database  tab, under  Advanced options :   Full size  here .", 
            "title": "Configure Database with the Web UI"
        }, 
        {
            "location": "/ambari_database/#configure-database-with-the-shell", 
            "text": "To configure a remote database for Ambari with Cloudbreak shell, use  database configure  command before  cluster create  command. The syntax is:  database configure --vendor [vendor] --host [host-or-ip] --port [port] --name [database-name] --username [user-name] --password [password]  Accepted  vendor  values are:   MARIADB  MSSQL  MYSQL  ORACLE  POSTGRES  SQLANYWHERE", 
            "title": "Configure Database with the Shell"
        }, 
        {
            "location": "/ambari_database/#upgrade-the-jdbc-driver", 
            "text": "During installation, Cloudbreak distributes the JDBC driver for Ambari to different locations. If you want to upgrade the driver or use a different one, you have to perform these steps:   Copy the driver to the  /var/lib/ambari-server/jdbc-drivers  directory.  Symlink the driver to  /usr/share/java ,  /usr/lib/jvm/java/jre/lib/ext  directories.  Reconfigure Ambari by executing the  ambari-server setup --jdbc-db=[db-vendor] --jdbc-driver=[driver-location]  command.", 
            "title": "Upgrade the JDBC Driver"
        }, 
        {
            "location": "/flow/", 
            "text": "svg {\n        border: 1px solid #999;\n        overflow: hidden;\n    }\n    .node {\n        white-space: nowrap;\n    }\n    .node rect,\n    .node circle,\n    .node ellipse {\n        stroke: #333;\n        fill: #fff;\n        stroke-width: 1.5px;\n    }\n    .cluster rect {\n        stroke: #333;\n        fill: #000;\n        fill-opacity: 0.1;\n        stroke-width: 1.5px;\n    }\n    .edgePath path.path {\n        stroke: #333;\n        stroke-width: 1.5px;\n        fill: none;\n    }\n\n\n\n\n\n    \nFlows\n\n    \n\n        Cloudbreak has an asynchron mechanism to manage clusters in the background. Each operation like \nstack creation\n is encapsulated into a flow, and triggered if neccessary.", 
            "title": "Flows"
        }, 
        {
            "location": "/help/", 
            "text": "Get Help\n\n\nOptions for Getting Help\n\n\nIf you need help with Cloudbreak, you have two options:\n\n\n\n\n\n\n\n\nOption\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nHortonworks Community Connection\n\n\nThis is free optional support via Hortonworks Community Connection (HCC).\n\n\n\n\n\n\nHortonworks Flex Support Subscription\n\n\nThis is paid Hortonworks enterprise support.\n\n\n\n\n\n\n\n\nHCC\n\n\nYou can optionally register for optional free community support at \nHortonworks Community Connection\n where you can browse articles and previously answered questions, and ask questions of your own. When posting questions related to Cloudbreak, make sure to use the \"Cloudbreak\" tag.\n\n\nFlex Subscription\n\n\nYou can optionally use your existing Hortonworks \nFlex subscription(s)\n to cover the Cloudbreak node and all clusters created. \n\n\nPrerequisites\n: You must have an existing SmartSense ID and a Flex subscription. For general information about the Hortonworks Flex Support Subscription, visit the Hortonworks Support page at \nhttps://hortonworks.com/services/support/enterprise/\n.\n\n\nThe general steps are:\n\n\n\n\nConfigure Smart Sense in your \nProfile\n file.   \n\n\nRegister your Flex subscription in the Cloudbreak web UI in the the \nmanage flex subscriptions\n pane. You can register and manage multiple Flex subscriptions.  \n\n\n\n\nOnce you've performed these steps: \n\n\n\n\nIn the the \nmanage flex subscriptions\n pane, you can assign your registered Flex subscription to the Cloudbreak node and set it as default for newly created clusters.  \n\n\nWhen creating a cluster using the advanced options, you can select the Flex subscription that you want to use.\n\nThis option is available in the \nCONFIGURE CLUSTER\n \n \nFlex Subscriptions\n section of the create cluster form.  \n\n\n\n\nAlternatively, you can perform these steps using the Cloudbreak Shell. \n\n\nConfiguring SmartSense\n\n\nTo configure SmartSense in Cloudbreak, enable SmartSense and add your SmartSense ID to the \nProfile\n by adding the following variables:\n\n\nexport CB_SMARTSENSE_CONFIGURE=true\nexport CB_SMARTSENSE_ID=YOUR-SMARTSENSE-ID\n\n\n\nFor example:\n\n\nexport CB_SMARTSENSE_CONFIGURE=true\nexport CB_SMARTSENSE_ID=A-00000000-C-00000000\n\n\n\nYou can do this in one of the two ways:\n\n\n\n\nWhen initiating Cloudbreak Deployer  \n\n\nAfter you've already initiated Cloudbreak Deployer. If you choose this option, you must restart Cloudbreak using \ncbd restart\n.\n\n\n\n\n\n\nSmartSense ID defined in the \nProfile\n file always overrides the ID registered via Cloudbreak Shell.\n\n\n\n\nManaging Flex Subscriptions\n\n\nOnce you log in to the Cloudbreak web UI, you can manage your Flex subscriptions from the \nmanage flex subscriptions\n pane. You can:\n\n\n\n\nRegister a new Flex subscription.  \n\n\nSet a default Flex subscription.  \n\n\nSelect a Flex subscription to be used for cloud controller.  \n\n\nDelete a Flex subscription.  \n\n\nCheck which clusters are connected to a specific subscription.  \n\n\n\n\nWhen creating a cluster using the advanced options, in the \nCONFIGURE CLUSTER\n \n \nFlex Subscriptions\n, you can select the Flex subscription that you want to use.\n\n\nManaging SmartSense and Flex Subscriptions via Cloudbreak Shell\n\n\nConfiguring SmartSense via Cloudbreak Shell\n\n\n\n\n\n\nEnable SmartSense in the \nProfile\n by adding the following variable: \n\n\nexport CB_SMARTSENSE_CONFIGURE=true\n\n\n\n\n\n\nYou can use Cloudbreak Shell to configure SmartSense subscription on the fly. For example, to register a SmartSense ID \nA-00000000-C-00000000\n use:\n\n\nsmartsense register --subscriptionId A-00000000-C-00000000\n\n\n\n\nSmartSense ID defined in the \nProfile\n file always overrides the ID registered via Cloudbreak Shell.\n\n\n\n\n\n\n\n\nManaging SmartSense via Cloudbreak Shell\n\n\nRegister SmartSense subscription:\n\n\nsmartsense register --subscriptionId A-00000000-C-00000000\n\n\n\n\nDescribe already registered SmartSense subscription:\n\n\nsmartsense describe\n\n\n\n\nDelete SmartSense subscription:\n\n\nsmartsense delete --subscriptionId A-00000000-C-00000000\n\n\n\n\nManaging Flex Subscriptions via Cloudbreak Shell\n\n\nRegister Flex subscription:\n\n\nflex register --name my-flex-subscription --subscriptionId FLEX-0123456789\n\n\n\n\nList already registered Flex subscriptions:\n\n\nflex list\n\n\n\n\nDescribe an existing Flex subscription:\n\n\nflex show --name my-flex-subscription\n\n\n\n\nSet Flex subscription as default:\n\n\nflex set-default --name my-flex-subscription\n\n\n\n\nUse Flex subscription for Cloudbreak instance:\n\n\nflex use-for-controller --name my-flex-subscription\n\n\n\n\nDelete Flex subscription:\n\n\nflex delete --name my-flex-subscription", 
            "title": "Get Help"
        }, 
        {
            "location": "/help/#get-help", 
            "text": "", 
            "title": "Get Help"
        }, 
        {
            "location": "/help/#options-for-getting-help", 
            "text": "If you need help with Cloudbreak, you have two options:     Option  Description      Hortonworks Community Connection  This is free optional support via Hortonworks Community Connection (HCC).    Hortonworks Flex Support Subscription  This is paid Hortonworks enterprise support.", 
            "title": "Options for Getting Help"
        }, 
        {
            "location": "/help/#hcc", 
            "text": "You can optionally register for optional free community support at  Hortonworks Community Connection  where you can browse articles and previously answered questions, and ask questions of your own. When posting questions related to Cloudbreak, make sure to use the \"Cloudbreak\" tag.", 
            "title": "HCC"
        }, 
        {
            "location": "/help/#flex-subscription", 
            "text": "You can optionally use your existing Hortonworks  Flex subscription(s)  to cover the Cloudbreak node and all clusters created.   Prerequisites : You must have an existing SmartSense ID and a Flex subscription. For general information about the Hortonworks Flex Support Subscription, visit the Hortonworks Support page at  https://hortonworks.com/services/support/enterprise/ .  The general steps are:   Configure Smart Sense in your  Profile  file.     Register your Flex subscription in the Cloudbreak web UI in the the  manage flex subscriptions  pane. You can register and manage multiple Flex subscriptions.     Once you've performed these steps:    In the the  manage flex subscriptions  pane, you can assign your registered Flex subscription to the Cloudbreak node and set it as default for newly created clusters.    When creating a cluster using the advanced options, you can select the Flex subscription that you want to use. \nThis option is available in the  CONFIGURE CLUSTER     Flex Subscriptions  section of the create cluster form.     Alternatively, you can perform these steps using the Cloudbreak Shell.", 
            "title": "Flex Subscription"
        }, 
        {
            "location": "/help/#configuring-smartsense", 
            "text": "To configure SmartSense in Cloudbreak, enable SmartSense and add your SmartSense ID to the  Profile  by adding the following variables:  export CB_SMARTSENSE_CONFIGURE=true\nexport CB_SMARTSENSE_ID=YOUR-SMARTSENSE-ID  For example:  export CB_SMARTSENSE_CONFIGURE=true\nexport CB_SMARTSENSE_ID=A-00000000-C-00000000  You can do this in one of the two ways:   When initiating Cloudbreak Deployer    After you've already initiated Cloudbreak Deployer. If you choose this option, you must restart Cloudbreak using  cbd restart .    SmartSense ID defined in the  Profile  file always overrides the ID registered via Cloudbreak Shell.", 
            "title": "Configuring SmartSense"
        }, 
        {
            "location": "/help/#managing-flex-subscriptions", 
            "text": "Once you log in to the Cloudbreak web UI, you can manage your Flex subscriptions from the  manage flex subscriptions  pane. You can:   Register a new Flex subscription.    Set a default Flex subscription.    Select a Flex subscription to be used for cloud controller.    Delete a Flex subscription.    Check which clusters are connected to a specific subscription.     When creating a cluster using the advanced options, in the  CONFIGURE CLUSTER     Flex Subscriptions , you can select the Flex subscription that you want to use.", 
            "title": "Managing Flex Subscriptions"
        }, 
        {
            "location": "/help/#managing-smartsense-and-flex-subscriptions-via-cloudbreak-shell", 
            "text": "", 
            "title": "Managing SmartSense and Flex Subscriptions via Cloudbreak Shell"
        }, 
        {
            "location": "/help/#configuring-smartsense-via-cloudbreak-shell", 
            "text": "Enable SmartSense in the  Profile  by adding the following variable:   export CB_SMARTSENSE_CONFIGURE=true    You can use Cloudbreak Shell to configure SmartSense subscription on the fly. For example, to register a SmartSense ID  A-00000000-C-00000000  use:  smartsense register --subscriptionId A-00000000-C-00000000   SmartSense ID defined in the  Profile  file always overrides the ID registered via Cloudbreak Shell.", 
            "title": "Configuring SmartSense via Cloudbreak Shell"
        }, 
        {
            "location": "/help/#managing-smartsense-via-cloudbreak-shell", 
            "text": "Register SmartSense subscription:  smartsense register --subscriptionId A-00000000-C-00000000  Describe already registered SmartSense subscription:  smartsense describe  Delete SmartSense subscription:  smartsense delete --subscriptionId A-00000000-C-00000000", 
            "title": "Managing SmartSense via Cloudbreak Shell"
        }, 
        {
            "location": "/help/#managing-flex-subscriptions-via-cloudbreak-shell", 
            "text": "Register Flex subscription:  flex register --name my-flex-subscription --subscriptionId FLEX-0123456789  List already registered Flex subscriptions:  flex list  Describe an existing Flex subscription:  flex show --name my-flex-subscription  Set Flex subscription as default:  flex set-default --name my-flex-subscription  Use Flex subscription for Cloudbreak instance:  flex use-for-controller --name my-flex-subscription  Delete Flex subscription:  flex delete --name my-flex-subscription", 
            "title": "Managing Flex Subscriptions via Cloudbreak Shell"
        }
    ]
}